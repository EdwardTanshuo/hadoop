hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e4596923b767eb163e141e41d5058c983e95f885:
    CLOUDERA-BUILD. Fixing reactor repo specification.
    
 -- Andrew Bayer <andrew.bayer@gmail.com>  Wed, 23 Feb 2011 09:53:00 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 80e7cd19dd23f552efd0bdf1f8b0509aa6b4b3d3:
    CLOUDERA-BUILD. Using local Maven repo as primary first in chain.
    
    Tweaks to pre-fetch dependencies into ~/.m2/repository before ant
    build is run, with Ivy configured to get from there before trying
    Maven Central.
    
 -- Andrew Bayer <andrew.bayer@gmail.com>  Mon, 21 Feb 2011 10:32:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit af111808a1edd957a56fe77d1ba2fdc4233cafda:
    CLOUDERA-BUILD. Preparing for cdh3u0 development.
    
 -- Jenkins <dev-kitchen@cloudera.com>  Sat, 19 Feb 2011 00:28:02 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3aa7c91592ea1c53f3a913a581dbfcdfebe98bfe:
    CLOUDERA-BUILD. Preparing for CDH3B4 release.
    
 -- Jenkins <dev-kitchen@cloudera.com>  Sat, 19 Feb 2011 00:27:52 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit dd51c56ab63cb12bc207647f314ab99e1e8da32b:
    Amend HADOOP-7070. Fix spurious warning message when running on machine with no krb5.conf
    
    The issue is that UGI.initialize would call KerberosName.setConfiguration before setting
    its own flag to indicate it was initialized. Then, if there was no krb5.conf,
    the class initializer of KerberosName would call back into UGI.isSecurityEnabled,
    causing initialize() to be run a second time.
    
    This bug doesn't exist upstream.
    
    Reason: spurious warnings
    Author: Todd Lipcon
    Ref: CDH-2688
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 17 Feb 2011 16:37:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1ff4b594c6f9926cf49842672740a229bf06491d:
    Amend MAPREDUCE-2178. Add log message when task JVM fails to fork
    
    Author: Todd Lipcon
    Ref: CDH-2671
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:40 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f57c22b8ec079abc5a051551bce9b1209fa3e6a3:
    MAPREDUCE-2332. Improve error message when userlogs dir has bad ownership
    
    Patch differs from trunk patch on account of MR-2178
    
    Reason: common souce of user error
    Author: Todd Lipcon
    Ref: CDH-2670
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 211e7bb1ea1fecc5894d53815c70be8b68c46643:
    MAPREDUCE-2331. Cover task graph servlet in fair scheduler system test
    
    Reason: improve jcarder coverage
    Author: Todd Lipcon
    Ref: CDH-2660
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4e93ef108e3ea798f22ef901f090999fe44a8888:
    MAPREDUCE-2180. Add coverage of Fair Scheduler servlet to system test
    
    Reason: improve jcarder coverage for possible deadlocks
    Author: Todd Lipcon
    Ref: CDH-2660
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 279a018f693a5721d7228e7c801327dda0aecb81:
    CLOUDERA-BUILD. Installation script needs to be adapted for the new naming scheme.
    
    Reason: Our mavenization effort changes our artifacts names
    Author: Bruno Mahé
    Ref: KITCHEN-833
    
  
  Author: Bruno Mahé <bruno@gnoll.org>  Tue, 15 Feb 2011 15:25:19 -0800
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cbada181614e3a32c9bbc2bc5e274798aa94217e:
    CLOUDERA-BUILD. TestLocalMRNotification times out in CDH3.
    
  
  Author: Tom White <tom@cloudera.com>  Mon, 14 Feb 2011 14:57:21 -0800
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2ac40e32af497c4c0d69c5921bd1504356b11086:
    Amend MAPREDUCE-1441. Reapply trimming of whitespace in mapred.local.dir configurations
    
    Reason: User bug report - regression from b2 to b3
    Author: Todd Lipcon
    Ref: CDH-2662
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 061eb38e4b442cf3f97fcb45a3059384fd74d036:
    CLOUDERA-BUILD. Fix a bug where HADOOP_DAEMON_DETACHED leaked into the environment of children
    
    This fixes a problem reported on the cdh-user list where tasks that forked out to
    call bin/hadoop ended up only catching the first 10 lines of output.
    
    Tested by writing a streaming script that catted a large text file off HDFS - verified
    bug is fixed.
    
    Author: Todd Lipcon
    Ref: CDH-2661
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 88e89c048d8f6f346667e64b782b7daf91d8a019:
    Amend HADOOP-7093. Revert incompatible change in semantics of HttpServer
    
    The original backport pulled in part of HADOOP-6461, which changed the way the
    "webapps" directory is located on the classpath. This broke HBase's ability
    to locate its UIs. In order to avoid having to patch HBase in CDH, this
    patch reverts that part of the change and works around the issue in the tests
    a different way.
    
    Reason: Should work with upstream HBase
    Author: Todd Lipcon
    Ref: CDH-2635
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e0934a30d7f6a3adb2b9b2f534eefda9a4ece41d:
    HADOOP-7140. IPC Reader threads should stop when server stops
    
    Reason: bug preventing TT from shutting down when build version is incompatible
    Author: Todd Lipcon
    Ref: CDH-2634
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3ad9f29cdcc14fbf41c6642b746ee04afaa92ff5:
    MAPREDUCE-2323. Add metrics to the fair scheduler
    
    Reason: Necessary for CMON, useful for monitoring
    Author: Todd Lipcon
    Ref: OPSAPS-2076
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:38 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3f5313383362c86a2df8be55d2c524d82f9fac85:
    Amend MAPREDUCE-2242. Reapply after MAPREDUCE-2178.
    
    Reason: fix environment escaping
    Author: Todd Lipcon
    Ref: CDH-2572
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:38 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 541407b9f144228f2b7934decc114c59b769e481:
    Amend MAPREDUCE-2178. Revert incompatible API change to FileUtil.chmod
    
    Reverts a change which removed InterruptedException from FileUtil.chmod's signature.
    Though the function never throws InterruptedException, this removal causes
    compilation failures for any clients who try to catch this exception (incl Pig)
    
    Reason: fix Pig build failure
    Author: Todd Lipcon
    Ref: CDH-2633
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:38 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a4778bbf1c461b56828f9810ea44c5893f929150:
    CLOUDERA-BUILD. Re-bootstrap native builds with maintainer mode
    
    Also includes bootstrap.sh where missing
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:38 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b329fa59501af3bef287aa0bdaa4c517cd41ad04:
    CLOUDERA-BUILD. Add AM_MAINTAINER_MODE to all configure.ac
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:38 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 50329213ff9f712bc07922a212c0931d20a31de6:
    HADOOP-6879. Provide SSH based (Jsch) remote execution API for system tests
    
    Reason: missing dependency breaks system tests build
    Author: Konstantin Boudnik
    Ref: CDH-2622
    
  
  Author: Konstantin Boudnik <cos@apache.org>  Fri, 11 Feb 2011 17:59:15 -0800
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4b44138e14ad63a6b54a962e16c8f1fd922b3a80:
    CLOUDERA-BUILD. task-controller configuration directory should be inferred from task-controller location
    
    Searches at ../../conf/ for task-controller.cfg
    
    Author: Todd Lipcon
    Ref: CDH-2623
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a6f5e7109f538e2b9374c6518c80b0575e2dfa9f:
    Amend HADOOP-5489. hdfsproxy-env.sh.template was updated but not hdfsproxy-env.sh
    
    Reason: avoid local modifications to src tree on build
    Author: Todd Lipcon
    Ref: CDH-2588
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cc3ba6c2c33ea827e6a54cda2759d03e7e2da4c1:
    HADOOP-7114. FsShell should dump errors at debug level
    
    Reason: easier to debug exceptions thrown in FsShell
    Author: Todd Lipcon
    Ref: CDH-2624
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5a57891c772488d8b02bcf54f4247f8fffa81d1f:
    Amend MAPREDUCE-2178. Remove AC_SYS_LARGEFILE from configure.ac
    
    This flag allows opening of files >2GB, but the task-controller doesn't need
    to do this. The removal is important because some RHEL5 systems have an
    fts.h which is incompatible with the resultant CFLAG when building 32-bit.
    
    Reason: RHEL5 32-bit build
    Author: Todd Lipcon
    Ref: CDH-2623
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit df540fdaa94d96a2a1bc2685774ae44b145bfa98:
    Amend MAPREDUCE-1493. Fix a typo in HTML markup on jobdetailshistory
    
    (typo made in original backport, not upstream)
    
    Reason: fix invalid HTML
    Author: Todd Lipcon
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e70a9985960b7ac9e2f6bf3826e93f6f8c44e46a:
    HADOOP-5913. Add support for starting/stopping queues.
    
    Author: Rahul K Singh
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1da8cc2964b488a55091e7b8b8f3a494ba4c1772:
    MAPREDUCE-2321. Check for NativeIO at TT startup
    
    Reason: Easier failure diagnosis for secure TT
    Author: Todd Lipcon
    Ref: CDH-2623
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4b1697b297d13990e17c3b3eaaf508686a2e78a5:
    MAPREDUCE-2289. Fix job staging directory to get automatically chmodded to correct permissions if incorrect
    
    Reason: fixes failures in TestFairSchedulerSystem
    Author: Todd Lipcon
    Ref: CDH-2626
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5d44075f3ac224bf9a259b0731035734d9c152a2:
    Ammend MAPREDUCE-2234. TaskTracker should fail on startup if log dir isn't writable
    
    Reapply after MAPREDUCE-2178 backport.
    
    Reason: Easier diagnosis of misconfigured TT permissions
    Author: Todd Lipcon
    Ref: CDH-2500
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:36 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a2b4149afd53d59fd9a279117c6917e4c83583a3:
    HDFS-1318, MAPREDUCE-2330. Add MXBeans for JT, TT, DN, NN
    
    Author: Tanping Wang, Luke Lu
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:37:03 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ee5c73991b43fd49a1a4eed599d2d52065054209:
    Amend MAPREDUCE-2178. Check result of chdir
    
    Reason: necessary to pass -Werror on more recent gcc
    Author: Todd Lipcon
    Ref: CDH-2623
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 717544d462bc56188d165008bc1d841bc1c03904:
    Amend MAPREDUCE-2178. Check argc *after* checks for perms, etc
    
    Reason: Fix error messages during taskcontroller setup
    Author: Todd Lipcon
    Ref: CDH-2623
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b8f3851b9604b8c1156c4a9df5c6a8b532676104:
    Amend MAPREDUCE-2178. Fix racy check for config file perms
    
    Reason: Security fix
    Author: Todd Lipcon
    Ref: CDH-2623
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit fa6aca09466301c65d8d8e5d92c43e50f46683ad:
    Amend MAPREDUCE-2103. Reapply "task-controller permissions checks too stringent" after MAPREDUCE-2173
    
    Reason: match documentation
    Author: Todd Lipcon
    Ref: CDH-2623
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7361ea92c13d6ca986e332acef70c2d8983c2f4c:
    Amend MAPREDUCE-2265. Restore sbin location for task controller install
    
    Reason: reapply after YDH 0.20.100 merge
    Author: Todd Lipcon
    Ref: CDH-2623
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0ed0d5e311f4f0c57ab6bafa39d324e19dd15b53:
    Amend MAPREDUCE-967. Reapply behavior which was clobbered by MAPREDUCE-2178
    
    (TT should not unpack job jars unnecessarily)
    
    Author: Todd Lipcon
    Ref: CDH-2623
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c2b050e2e466b4e43a8458fd05c72e289ed2d563:
    CLOUDERA-BUILD. Integrate task-controller changes from MAPREDUCE-2178 into Cloudera build
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ac1fd5519d4cd7ddc5cf740d4b4459232523fb12:
    MAPREDUCE-2178. Write task initialization to avoid race conditions leading to privilege escalation and resource leakage by performing more actions as the user.
    
    Author: Owen O'Malley, Devaraj Das, Chris Douglas
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bb004aae8abc4f7e772adda6a75f433cf7cb198d:
    HDFS-1597. Fix assertion in TestEditLogRace
    
    Reason: Sporadic test failure
    Author: Todd Lipcon
    Ref: CDH-2559
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit dbaa8cd7a1a81de7700dcec4517dbf2012906641:
    HDFS-1601. Pipeline ACKs are sent as lots of tiny TCP packets
    
    Reason: HBase performance
    Author: Todd Lipcon
    Ref: CDH-2627
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0d086cde04450cbb5a5f6d39a345aafcdadaa511:
    HDFS-1114. Reduce NameNode memory usage by an alternate hash table
    
    Author: Tsz Wo (Nicholas) Sze
    Reason: reduce memory usage in the NameNode
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 921d337cfa66dcc22207f3fb42e385aff4e229d0:
    HDFS-1119. Introduce a GSet interface to BlocksMap.
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 216d29555d3fb62aca7362a5611bbc5ec7846b6a:
    HDFS-599. Allow NameNode to have a separate port for service requests from client requests.
    
    Reason: Allows port-based QoS to prioritize DN RPCs over client RPCs, also increases fairness
    Author: Dmytro Molkov
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 53c9961d5b350c96200a3b85c2302a2b569e6fa8:
    HDFS-1298. Add support in HDFS for new statistics added in FileSystem to track the file system operations.
    
    Author: Suresh Srinivas
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f1625663dc6008b89af3ff80e19d64f4717f1a9b:
    HDFS-1315. Add fsck event to audit log and remove other audit log events corresponding to FSCK listStatus
    
    Author: Suresh Srinivas
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3d026b0a1706483a4860ad80fc17b103448ac1b0:
    HDFS-1383. Better error messages in HFTP
    
    Author: Tsz Wo (Nicholas) Sze
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f148732a5c983877fb62ecfe5815eb445a192573:
    HDFS-1061. Memory footprint optimization for INodeFile object.
    
    Author: Bharath Mundlapudi
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit edda8a863002796aa282fa26d74f8843eac4b728:
    HDFS-1307 Add start time, end time and total time taken for FSCK to FSCK report.
    
    Author: Suresh Srinivas
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b2cfa8caaa27a75a4452d9e26d3f3a169e13730e:
    HDFS-1085. HFTP read may fail silently on the client side if there is an exception on the server side.
    
    Author: Tsz Wo (Nicholas) Sze
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 66beb0bfe053b9c0fa02f7ac82310081fa6da2cd:
    HADOOP-6713. The RPC server Listener thread is a scalability bottleneck.
    
    Author: Dmytro Molkov
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 807e918943e9f17d4ab7912bdb9cc90970c02ef6:
    HADOOP-6859. Introduce additional statistics to FileSystem to track file system operations.
    
    Author: Suresh Srinivas
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8dd45e436896108d8806e5a555621ea6b346912f:
    HADOOP-6899. RawLocalFileSystem#setWorkingDir() does not work for relative names
    
    Author: Sanjay Radia
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7a31be4853d46090c7bd7798bdb7cd41915b421c:
    HADOOP-6669. Respect compression configuration when creating DefaultCodec
    
    Author: Koji Noguchi
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b2586915b911182f60e949de3dd340ae8e8099ca:
    CLOUDERA-BUILD. Re-bootstrap native
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1fb15b9ee1b9edd5961b5972da4062117b4709e5:
    CLOUDERA-BUILD. Native build for JNI group mapping code
    
    Original JNI patch is against Yahoo's distro which has divergent build files.
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bb55a89bf7a3decd9846989f31d93cb4ed8588b5:
    HADOOP-6864. Provide a JNI-based implementation of ShellBasedUnixGroupsNetgroupMapping
    
    Author: Boris Shkolnik
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2780f0d352553b1a5c177fe20afdea223bd1e405:
    HADOOP-6818. Provides a JNI implementation of group resolution.
    
    Author: Devaraj Das
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 562d6a6d79943f4c132e9db773898db533b4dbfd:
    MAPREDUCE-1545. Add 'first-task-launched' to job-summary
    
    Author: Luke Lu
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4595403c6e7b1e594ea5759784aaa65eb6d46786:
    MAPREDUCE-2023 TestDFSIO read test may not read specified bytes.
    
    Author: Hong Tang
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4cbfcd923d102ce6bcccb5dcddc1ed124f42bb8f:
    MAPREDUCE-2005. Improvements to TestDelegationTokenRenewal
    
    Reason: improve test printouts
    Author: Boris Shkolnik
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6cceb85a5f8743aaef4a98957e31f6930a013cdd:
    MAPREDUCE-1961. ConcurrentModificationException when shutting down Gridmix
    
    Author: Hong Tang
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 16d9cf021a1989467b1372d3c2a050e6c4606230:
    MAPREDUCE-339. JobTracker should give preference to failed tasks over virgin tasks so as to terminate the job ASAP if it is
    
    Author: Devaraj Das
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 81bd8d5735c682d69d59712a7333a70d081a4216:
    MAPREDUCE-1936. Make Gridmix3 more customizable.
    
    Author: Hong Tang
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1b9bc9af319325bd26e1530ce18527ca8f74dafd:
    MAPREDUCE-1778 CompletedJobStatusStore initialization should fail if {mapred.job.tracker.persist.jobstatus.dir} is unwritable
    
    Author: Krishna Ramachandran
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e0104169bfac10c2760fcf133b01fd2b710208cb:
    MAPREDUCE-1868 Add read timeout on userlog pull
    
    Author: Krishna Ramachandran
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a6b1ad67cf903e1e56963dcc64d7d7599321d386:
    MAPREDUCE-1850. Include job submit host information (name and ip) in jobconf and jobdetails display
    
    Author: Krishna Ramachandran
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:47 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4098a214be838238a9879f7f978e34e89b736986:
    HDFS-1626. Make block invalidate limit configurable
    
    Author: Tsz Wo (Nicholas) Sze
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:36:35 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f1b4799fad93b4f02ee29ce5ef5fc217ff72e377:
    MAPREDUCE-2328. Add configs for memory-related configurations to mapred-default.xml
    
    Author: Yahoo Eng
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:24 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f879e570e2fe88776d15de04a8597898d06f3f77:
    HDFS-1364. Makes long running HFTP-based applications do relogins if necessary.
    
    Author: Jitendra Pandey
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:24 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ce9aa5ef9dfc5c4fb8e85f9e9e47e67a4b724296:
    CLOUDERA-BUILD. Increase Xmx for compiling fault injection tests
    
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:24 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f19b644c987305988a36e7d6038b16a9768cb084:
    Amend MAPREDUCE-2096. MapTask SpillRecord usage doesn't need username.
    
    Author: Yahoo Eng
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:24 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c76f57dcd993063cf960fb42e65219edd5230432:
    Amend MAPREDUCE-1100. Change log messages in ReduceTask from info to debug level
    
    Reason: reduces log size for large reduce tasks
    Author: Yahoo Eng
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:24 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 674795fc9a60d06dbea41bd9d5a133439822a62b:
    Amend HADOOP-6706. Improve retry behavior for RPC clients
    
    Author: Kan Zhang
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bfa0b28baad26de8315ec1f9282728913863c3e7:
    Partial HADOOP-6965. Refactor getTGT and getRefreshTime out of anonymous class, add synchronized block around relogin
    
    Author: Jitendra Pandey
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e8b759460ab487e98093292be7fa90afa65f47ec:
    Partial HADOOP-6471. Use StringBuilder in StringUtils.join
    
    Author: Yahoo Eng
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3ef31bcc86610d496976b4de9ada82e73f47f162:
    HADOOP-7115. Reduces the number of calls to getpwuid_r and getpwgid_r, by implementing a cache in NativeIO.
    
    Author: Devaraj Das
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d2032071037eb33c562d97b16e0cd291f4e3f23b:
    MAPREDUCE-1521. Protection against incorrectly configured reduces
    
    Author: Mahadev Konar
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6bc623041a1c0d511250bcfdcae85a7b084b0d5f:
    HDFS-1153. Verify dfsnodelist input for correctness
    
    Author: Ravi Phulari
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bf655f10661132486cb40ee098fdedbbb5937892:
    Partial MAPREDUCE-2055. Cache counters in retired job info
    
    Does not apply entirety of upstream JIRA as described. Simply caches
    Counters in the retired job info.
    
    Author: Krishna Ramachandran
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3ae2cde7b036603b8aa19e2ab31994dd3209eded:
    MAPREDUCE-1960. Add ability to limit size of jobconf
    
    Author: Mahadev Konar
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7429b6597999c1a867926b61d5075bdf85a1be6d:
    Amend HDFS-457. Include new test TestDataNodeVolumeFailure
    
    Ref: CDH-2622
    Author: Boris Shkolnik
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit af1598cf2f8ce26c43f74b0be684662287e34095:
    HDFS-1101. TestDiskError should check all nodes in cluster for test case
    
    Reason: Test failure
    Author: Chris Douglas
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2c5115af8426e44b9de804b80fcc9502d64efadd:
    MAPREDUCE-1118. Enhance the JobTracker web-ui to ensure tabular columns are sortable, also added a /scheduler servlet to CapacityScheduler for enhanced UI for queue information.
    
    Author: Krishna Ramachandran
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:33:22 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ba185a27aa4bb1bd965e6aa32a9b5bf3e8388f91:
    MAPREDUCE-1872, MAPREDUCE-517. Capacity scheduler improvements plus minor framework changes to support
    
    - JobInProgress changes to support locality decisions
    - JobQueueJobInProgressListener.JobSchedulingInfo now has equals() method for
    
    Author: Arun Murthy
    Ref: CDH-2622
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 16 Feb 2011 15:32:30 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 83a6619c2656f543e046521f515d97fd70d647bb:
    MAPREDUCE-1774. Additions to Herriot Testing to test Gridmix, Streaming, Task Controllers
    
    Includes:
      MAPREDUCE-1758 Building blocks for the herriot test cases
      MAPREDUCE-1827 [Herriot] Task Killing/Failing tests for a streaming job.
      MAPREDUCE-2053 [Herriot] Test Gridmix file pool for different input file sizes based on pool minimum size
      MAPREDUCE-2033 [Herriot] Gridmix generate data tests with various submission policies and different user resolvers.
      ... and others from YDH
    
    Reason: QA / YDH merge
    Ref: CDH-2622
    
  
  Author: Todd Lipcon <todd@cloudera.com>  Wed, 02 Feb 2011 17:37:15 -0800
 -- Andrew Bayer <andrew.bayer@gmail.com>  Mon, 14 Feb 2011 08:58:46 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5dcc0777f30ae030e20e5e1e3512a0ed6a90e7fc:
    DISTRO-90. FUSE can pick up the wrong libjvm.so.
    
    Reason: Bug
    Author: Eli Collins
    Ref: DISTRO-90
    
  
  Author: Eli Collins <eli@cloudera.com>  Sun, 06 Feb 2011 13:22:31 -0800
 -- Andrew Bayer <andrew.bayer@gmail.com>  Mon, 14 Feb 2011 08:58:46 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f8e6600fbdc454600990e4f3732462e9b56e0b1b:
    MAPREDUCE-2256. FairScheduler fairshare preemption from multiple pools may
    preempt all tasks from one pool causing that pool to go below fairshare.
    
    You have a cluster with 600 map slots and 3 pools. Fairshare for each pool is
    200 to start with. Fairsharepreemption timeout is 5 mins.
    
    1) Pool1 schedules 300 map tasks first
    2) Pool2 then schedules another 300 map tasks
    3) Pool3 demands 300 map tasks but doesn't get any slot as all slots are taken.
    4) After 5 mins pool3 should preempt 200 map-slots. Instead of peempting 100
    slots each from pool1 and pool2, the bug would cause it to preempt all 200
    slots from pool2 (last started) causing it to go below fairshare. This is
    happening because the preemptTask method is not reducing the tasks left from a
    pool while preempting the tasks.
    
    The above scenario could be an extreme case but some amount of excess
    preemption would happen because of this bug.
    
    Reason: Bug
    Author: Priyo Mustafi
    Ref: CDH-2593
    
  
  Author: Eli Collins <eli@cloudera.com>  Sun, 06 Feb 2011 13:37:24 -0800
 -- Andrew Bayer <andrew.bayer@gmail.com>  Mon, 14 Feb 2011 08:58:45 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cce41bfecdffd8f37b5a9ae571a827e8042b39c4:
    CLOUDERA-BUILD. tar file has incorrect permissions for jsvc and task-controller.
    
    Reason: Bug
    Author: Eli Collins
    Ref: CDH-2553
    
  
  Author: Eli Collins <eli@cloudera.com>  Sun, 06 Feb 2011 13:12:41 -0800
 -- Andrew Bayer <andrew.bayer@gmail.com>  Mon, 14 Feb 2011 08:58:45 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit fa3b91e008607ff69bd2796f025680aacc97bd11:
    DISTRO-44. Hadoop core POM missing jackson dependency.
    
    Reason: Bug
    Author: Eli Collins
    Ref: DISTRO-44
    
  
  Author: Eli Collins <eli@cloudera.com>  Sat, 05 Feb 2011 16:21:19 -0800
 -- Andrew Bayer <andrew.bayer@gmail.com>  Mon, 14 Feb 2011 08:58:45 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f40f6bef0808d34b0632bd759b7916946b6a500c:
    HADOOP-5489. hadoop-env.sh still refers to java1.5.
    
    Reason: Bug
    Author: Steve Loughran
    Ref: CDH-2588
    
  
  Author: Eli Collins <eli@cloudera.com>  Sun, 06 Feb 2011 14:01:28 -0800
 -- Andrew Bayer <andrew.bayer@gmail.com>  Mon, 14 Feb 2011 08:58:45 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e3356ca6f8a2ee616f610da19fc141d7578a905d:
    CLOUDERA-BUILD. Changes to support CDH Mavenization.
    
 -- Andrew Bayer <andrew.bayer@gmail.com>  Mon, 14 Feb 2011 08:58:44 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7e7c0e2d4fe19559a728d2c0860f406124c578e3:
    Amend MAPREDUCE-1716. Fix test case to wait for up to 20 seconds to verify truncation
    
    Reason: truncation is done in a separate thread at JVM finish time, which may come
      after the job is complete
    Author: Todd Lipcon
    Ref: CDH-2579
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 01 Feb 2011 14:36:11 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f6ffedb4441ec43ef7d81fe483807115e98aca41:
    HADOOP-6882. Update the patch level of Jetty to 6.1.26
    
    Reason: Address XSS and many other upstream bugs
    Author: Owen O'Malley
    Ref: CDH-2564
    
 -- Todd Lipcon <todd@cloudera.com>  Mon, 31 Jan 2011 13:22:47 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 545bcc1060833f76eab19fa0425f890cb3f9d2cb:
    MAPREDUCE-2242. Fix environment escaping in LinuxTaskController
    
    Reason: Support env variables with "s
    Author: Todd Lipcon
    Ref: CDH-2572
    
 -- Todd Lipcon <todd@cloudera.com>  Mon, 31 Jan 2011 13:06:08 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c5df4748c04337af74ca80a84a03e15ba2de2f0e:
    HDFS-1353. Remove getBlockLocations optimization that blew out LocatedBlocks response size
    
    Reason: Address OOME found by QA
    Author: Jakob Homan
    Ref: CDH-2573
    
 -- Todd Lipcon <todd@cloudera.com>  Mon, 31 Jan 2011 11:59:44 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8bc90cb06955b191c5d4370ca75b3b14aabc9657:
    HADOOP-5050. TestDFSShell.testFilePermissions should not assume umask setting.
    
    Reason: test failure on machines with different umask
    Author: Jakob Homan
    Ref: CDH-2574
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 28 Jan 2011 16:20:15 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0d4eb1a867620813affdfd3291cb618d6fce63ca:
    HADOOP-7122. Shell commands leak Timers when timeout expires
    
    Reason: Thread leak seen on JT
    Author: Todd Lipcon
    Ref: CDH-2568
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 28 Jan 2011 12:17:55 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2ad8c54fecae73213da7c74da9f90ba953f9f9c5:
    MAPREDUCE-2253. Servlets should specify content type
    
    Reason: Fix display in browsers
    Author: Todd Lipcon
    Ref: DISTRO-72
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 27 Jan 2011 10:34:33 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 51399a0f149292ee18138646488a8070c8b7f34c:
    HADOOP-7118. Fix NullPointerException in Configuration.writeXml
    
    Reason: Bug fix
    Author: Todd Lipcon
    Ref: CDH-2558
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 26 Jan 2011 11:39:28 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit be89980babbc50eb7e1ccce9b583fff0ae24cf80:
    MAPREDUCE-2082. Race condition in writing the jobtoken password file when launching pipes jobs
    
    Reason: security
    Author: Jitendra Nath Pandey
    Ref: CDH-2562
    
 -- Tom White <tom@cloudera.com>  Wed, 26 Jan 2011 10:26:09 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c5645ced5c2b32c0657ba3ca60643165c28173ff:
    MAPREDUCE-1085. For tasks, "ulimit -v -1" is being run when user doesn't specify mapred.child.ulimit
    
    Reason: spurious errors in logs
    Author: Todd Lipcon
    Ref: CDH-2560
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 25 Jan 2011 17:43:36 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b02ac3f86f9d929316edd10855721b67459192ba:
    MAPREDUCE-2277. Fix TestCapacitySchedulerWithJobTracker intermittent failure
    
    Reason: test failure
    Author: Todd Lipcon
    Ref: CDH-2547
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 25 Jan 2011 15:04:56 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6b63d73a1917a6c0529158c3bb78ec2ec16ad7ce:
    HDFS-1589. Dont start secure cluster with insecure ports
    
    Reason: security
    Author: Todd Lipcon
    Ref: CDH-2557
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 25 Jan 2011 13:44:06 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8b4374bfa12b1a1ed8cc8e0ab209ad763becf791:
    HADOOP-3953. Implement sticky bit for directories in HDFS.
    
    Reason: security on /tmp
    Author: Jakob Homan
    Ref: CDH-2091
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 25 Jan 2011 13:09:33 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2bec46c2f46e42a35a69fdbd6f37f8979599e83d:
    Amend HADOOP-5643. Remove PermissionChecker class accidentally left around
    
    This class was supposed to be removed by HADOOP-5643 but accidentally was
    left in the tree. Unreferenced except in one place - now updated to refer
    to the new implementation.
    
    Reason: clean up - noticed during sticky bit backport
    Author: Todd Lipcon
    Ref: CDH-2091
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 25 Jan 2011 13:09:33 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 562be1407b9e3c2d8907daaa9500ac96364c9fa2:
    MAPREDUCE-2238. Avoid racy permissions handling
    
    Reason: leaving undeletable dirs in userlogs directory
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 25 Jan 2011 13:09:33 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2df0683fe8b9a6f1c7dc9f9ec49697960b473add:
    HADOOP-7110. Use JNI to implement chmod for performance
    
    Reason: fork can be rather slow, chmod is common
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 25 Jan 2011 13:09:32 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit efda213ca9682c9ee555b6c9582eb039cfefc122:
    Revert "HADOOP-6304. Use java.io.File.set{Readable|Writable|Executable} where possible in RawLocalFileSystem"
    
    This reverts commit 13e93cafe8d4b1e8b741c1873118cdba0313a564.
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 25 Jan 2011 13:09:32 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b715fdffb59ad674e16d31db09b75884ddd2e0fa:
    HADOOP-5836. Bug in S3N handling of directory markers using an object with a trailing "/" causes jobs to fail
    
    Reason: Bug fix
    Author: Ian Nowland
    Ref: DISTRO-76
    
 -- Tom White <tom@cloudera.com>  Tue, 25 Jan 2011 09:21:54 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 516adbfc45e739130bdbb047e45f068a38e72988:
    HDFS-1330. Make RPCs to DataNodes timeout.
    
    Reason: Customer request
    Author: Hairong Kuang
    Ref: CDH-2044
    
 -- Todd Lipcon <todd@cloudera.com>  Mon, 24 Jan 2011 17:02:12 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1e3ffff9722ebd775b870a4c914f202930bb525e:
    HADOOP-6889. Make RPC to have an option to timeout.
    
    Reason: Customer request
    Author: Hairong Kuang
    Ref: CDH-2044
    
 -- Todd Lipcon <todd@cloudera.com>  Mon, 24 Jan 2011 17:02:12 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit fadd26e431dc879d9611f22f2974d4eab30d7efa:
    MAPREDUCE-1382. MRAsyncDiscService should tolerate missing local.dir
    
    Reason: Makes it possible for jobtracker and tasktracker to share config file and have different volumes.
    Author: Zheng Shao
    Ref: CDH-2395, DISTRO-36
    
 -- Tom White <tom@cloudera.com>  Mon, 24 Jan 2011 15:35:41 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit eb118d65f792dd3947b886ea7f2c971556d496cf:
    MAPREDUCE-787. -files, -archives should honor user given symlink path
    
    Reason: bug fix
    Author: Amareshwari Sriramadasu
    Ref: CDH-2538
    
 -- Tom White <tom@cloudera.com>  Thu, 20 Jan 2011 11:23:08 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2b0e1289ccbdb9c6837e4ab11fdf73fa8980571c:
    MAPREDUCE-572. If #link is missing from uri format of -cacheArchive then streaming does not throw error.
    
    Reason: bug fix
    Author: Amareshwari Sriramadasu
    Ref: CDH-2538
    
 -- Tom White <tom@cloudera.com>  Thu, 20 Jan 2011 11:23:01 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a144f415c0e14d1b4d42c72ccf5c97dc8f8423e8:
    Amend HADOOP-6539. Roll back some doc changes that snuck in from trunk
    
    Reason: referenced features not backported into CDH3
    Author: Todd Lipcon
    Ref: CDH-2541
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 18 Jan 2011 14:17:56 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5ebec5b74ea0b6fe9270cc40f770bf4cf4f7d4a7:
    HADOOP-7093. Servlets should default to text/plain.
    
    Reason: fix /stacks and /metrics to be usable again
    Author: Todd Lipcon
    Ref: DISTRO-72
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 14 Jan 2011 18:47:59 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 185d654adfa40db3978a2f552feec95748589c89:
    HDFS-1560. DataNode should set permissions on its data dirs rather than failing to start. Also, should default to 700
    
    Reason: Easier setup, better security
    Author: Todd Lipcon
    Ref: CDH-2530
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 14 Jan 2011 18:43:38 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 390cedb3ba0ec9bf7e4859f89c3e10dd40be2763:
    Amend MAPREDUCE-1092. Enable asserts for tests by default
    
    Reason: reapply patch accidentally reverted by Herriot merge
    Author: Todd Lipcon
    Ref: CDH-520
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 14 Jan 2011 17:45:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 61bf38c1c0b31ef18b93ed225c8367ab4d5d7f96:
    DISTRO-73. Fix filesystem leak when userlog location has different FS URI than JT
    
    No upstream JIRA since this was fixed upstream by MAPREDUCE-157
    
    Reason: Thread leak reported on cdh-user
    Author: Todd Lipcon
    Ref: DISTRO-73
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 14 Jan 2011 17:42:33 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5c54c0cae529a17fe30d17642b868f2609c0731b:
    Amend MAPREDUCE-1784. Include TestIFile unit test
    
    Reason: missed in prior commit
    Author: Eli Collins
    Ref: CDH-862
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 14 Jan 2011 15:46:09 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b48ee52a2c451a673765c67141448fa9cdc7e37a:
    HADOOP-7101. UserGroupInformation.getCurrentUser() fails when called from non-Hadoop JAAS context
    
    Reason: Hadoop access fails running from within JMX-created JAAS context
    Author: Todd Lipcon
    Ref: CDH-2525
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 14 Jan 2011 15:43:43 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 329ae61a7987d576c0d73a395f773fa820594ea4:
    HADOOP-7089. Fix link resolution logic in hadoop-config.sh.
    
    The link resolution logic in bin/hadoop-config.sh fails when when
    executed via a symlink, from the root directory. We can replace this
    logic with cd -P and pwd -P, which should be portable across Linux,
    Solaris, BSD, and OSX.
    
    Reason: Bug
    Author: Eli Collins
    Ref: DISTRO-9
    
 -- Eli Collins <eli@cloudera.com>  Fri, 14 Jan 2011 00:18:24 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0f0f7b996033179d70f3750b3d1d0ff4a1b1aef3:
    CLOUDERA-BUILD. Fix documentation urls that use "current".
    
    Reason: Bug
    Author: Eli Collins
    Ref: CDH-2405
    
 -- Eli Collins <eli@cloudera.com>  Wed, 12 Jan 2011 19:06:33 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bd69ffce6f04c6d4f3685f55403b5d57191057d9:
    MAPREDUCE-1178. Fix ClassCastException in MultipleInputs by adding a DelegatingRecordReader.
    
    Reason: bug fix
    Author: Amareshwari Sriramadasu and Jay Booth.
    Ref: CDH-2513
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 12 Jan 2011 15:56:10 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6ff69b095f390fba1e8ba3c315a93889a94de481:
    MAPREDUCE-655. Change KeyValueLineRecordReader and KeyValueTextInputFormat to use new mapreduce api.
    
    Reason: Required for MultipleInputs
    Author: Amareshwari Sriramadasu
    Ref: CDH-2513
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 12 Jan 2011 15:56:10 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c1ec4018591d3e2bbb6fa8f664f9355a76e94ad5:
    MAPREDUCE-369. Change org.apache.hadoop.mapred.lib.MultipleInputs to use new mapreduce API.
    
    Amended to not deprecate the old API.
    
    Reason: Customer request, low risk
    Author: Amareshwari Sriramadasu.
    Ref: CDH-2513
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 12 Jan 2011 15:56:10 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit de6b20455e53435d6079b0ed9b0a005bc0c435ff:
    HADOOP-7072 Remove java5 dependencies from build
    
    Description:
    Reason: test is affected.
    Author: cos
    Ref: CDH-2485
    
 -- Konstantin Boudnik <cos@apache.org>  Tue, 11 Jan 2011 14:30:08 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5b2e26fd1cfa592931dc9606d6cb81aaf9a5712d:
    HADOOP-5170. Reverted: "Set max map/reduce tasks on a per-job basis, either per-node or cluster-wide"
    
    Reason: Patch not accepted upstream. See MAPREDUCE-698 and MAPREDUCE-704.
    Author: Tom White
    Ref: CDH-789
    
 -- Tom White <tom@cloudera.com>  Tue, 11 Jan 2011 14:13:53 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 51a15afdd3f2b33e9c6573bfa9d002034edaaaf7:
    HADOOP-5476. calling new SequenceFile.Reader(...) leaves an InputStream open, if the given sequence file is broken
    
    Reason: Fix file handle leak, as requested on Hive list.
    Author: Michael Tamm
    Ref: DISTRO-28
    
 -- Tom White <tom@cloudera.com>  Tue, 11 Jan 2011 14:01:44 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bda05051c5ad4c56d210427bbe6445c3db66573e:
    MAPREDUCE-2234. If Localizer can't create task log directory, it should fail on the spot.
    
    Reason: Make common source of support tickets easier to diagnose
    Author: Todd Lipcon
    Ref: CDH-2500
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 07 Jan 2011 14:20:01 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b57d9d0a60f8d871511750465ad94dd18a103656:
    MAPREDUCE-2219. Fix JT startup to not require mapred.system.dir inside a dir that it owns
    
    Reason: Easier permissions
    Author: Todd Lipcon
    Ref: CDH-2499
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 07 Jan 2011 14:11:34 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b5f1e39c0561d262829ae4cce546773a418db96e:
    HADOOP-7070. Delegate calls up to parent UserGroupInformation
    
    Reason: Fix login behavior underneath glassfish or other JAAS-using containers
    Author: Todd Lipcon
    Ref: DISTRO-66
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 07 Jan 2011 14:07:54 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a3421bf550672c6615541e1f73a5e0add9fcc158:
    HDFS-1542. Add test for HADOOP-7082, a deadlock writing Configuration to HDFS.
    
    Author: Todd Lipcon
    Ref: CDH-2498
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 07 Jan 2011 13:59:13 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d0fcd663498ab6af0ae550ea6ace527ac7f7eae3:
    HADOOP-7082. Configuration.writeXML should not hold lock while outputting.
    
    Reason: Avoid deadlock submitting jobs
    Author: Todd Lipcon
    Ref: CDH-2498
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 07 Jan 2011 13:56:43 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5d85605d7f324d9bb5751bf9e1733170dd97a911:
    CLOUDERA-BUILD. Part of MAPREDUCE-157 to fix doubly-escaped job history links
    
    Reason: Bug fix
    Author: Tom White
    Ref: CDH-2283
    
 -- Tom White <tom@cloudera.com>  Thu, 06 Jan 2011 13:07:11 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 73c38ae4211b732cae575d7f52f233e2cf6f909e:
    MAPREDUCE-1734. Un-deprecate the old MapReduce API in the 0.20 branch.
    
    Reason: Old APIs will remain through at least 0.23
    Author: Todd Lipcon
    Ref: CDH-2494
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 05 Jan 2011 14:46:59 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4882770efb2a9eb52ae51d5b35e6ba3a2737c44e:
    MAPREDUCE-1906. Allow heartbeat interval minimum to be configured
    
    Author: Todd Lipcon
    Ref: CDH-2319
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 05 Jan 2011 13:21:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f9f9182ecf6d208fd28b23941b5e851e1efedec7:
    HADOOP-6578. Configuration should trim whitespace around a lot of value types.
    
    Reason: Improvement
    Author: Michele Catasta
    Ref: CDH-2266
    
 -- Eli Collins <eli@cloudera.com>  Mon, 03 Jan 2011 21:35:29 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4214d3e60326a9b41e84f85895aca325d634c304:
    CDH-2381. org.apache.hadoop.cli.TestCLI.testAll (from TestCLI) failing in golden CDH3-Hadoop Hudson job
    
    Description:
    Reason: test is affected.
    Author: cos
    Ref: CDH-2381
    
 -- Konstantin Boudnik <cos@apache.org>  Mon, 20 Dec 2010 12:41:24 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4ad53f3de801a1a670d658d4d933d9576b99445c:
    MAPREDUCE-1938. Ability for having user's classes take precedence over
    the system classes for tasks' classpath.
    
    It would be nice to have the ability in MapReduce to allow users to
    specify for their jobs alternate implementations of classes that are
    already defined in the MapReduce libraries. For example, an alternate
    implementation for CombineFileInputFormat.
    
    Reason: New feature
    Author: Devaraj Das
    Ref: DISTRO-64
    
 -- Eli Collins <eli@cloudera.com>  Fri, 17 Dec 2010 18:52:54 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b0ed02a3d621bbf994f8fb5dc1d86a451afe490d:
    MAPREDUCE-1699. JobHistory shouldn't be disabled for any reason
    
    Reason: Bug
    Author: Arun C Murthy
    Ref: CDH-1691
    
 -- Tom White <tom@cloudera.com>  Thu, 16 Dec 2010 12:46:59 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ba2c7a5b99915ca1431e3024dd80ac359c8005a1:
    MAPREDUCE-1853. MultipleOutputs does not cache TaskAttemptContext
    
    Reason: Bug
    Author: Torsten Curdt
    Ref: CDH-2010
    
 -- Tom White <tom@cloudera.com>  Thu, 16 Dec 2010 12:35:41 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 43fb37a6b9693003cc9ea1161bc080e5309b1973:
    MAPREDUCE-1621. Streaming's TextOutputReader.getLastOutput throws NPE if it has
    never read any output.
    
    If TextOutputReader.readKeyValue() has never successfully read a line,
    then its bytes member will be left null. Thus when logging a task
    failure, PipeMapRed.getContext() can trigger an NPE when it calls
    outReader_.getLastOutput().
    
    Reason: Bug
    Author: Amareshwari Sriramadasu
    Ref: CDH-855
    
 -- Eli Collins <eli@cloudera.com>  Thu, 09 Dec 2010 09:08:13 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit af9ef1fcde9aa7ed6d84481837dd5c3e6e4ecc14:
    MAPREDUCE-1784. IFile should check for null compressor.
    
    Reason: Avoid NPE
    Author: Eli Collins
    Ref: CDH-862
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 07 Dec 2010 18:29:42 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 50796a1b13f77ef5c2e098f6a651bf52c05cd2f7:
    CDH-2234 adding Oozie needed config to Hadoop config example-confs/
    
    Description: adding Oozie needed config to Hadoop config example-confs/
    Reason: to enable zero config for Oozie out of the box
    Author: Alejandro
    Ref: CDH-2234
    
 -- Alejandro Abdelnur <tucu00@gmail.com>  Mon, 29 Nov 2010 22:05:08 +0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 39b1d616bd1d7cf88cb057d1fd70b0d9b17a9992:
    Amend HADOOP-6978. Add AC_SYS_LARGEFILE to native build to fix issue with large files
    
    Author: Owen O'Malley
    Ref: CDH-2009
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 24 Nov 2010 14:21:16 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 552ebe400b6d94b02d8a3ffebb61b433f7e13aa1:
    HDFS-1250. Namenode accepts block report from dead datanodes.
    
    Reason: Bug
    Author: Suresh Srinivas
    Ref: CDH-2277
    
 -- Eli Collins <eli@cloudera.com>  Fri, 12 Nov 2010 23:18:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit fa4ca629131059ade47618d0ed201c4ddc3abe72:
    HADOOP-6813. Add a new newInstance method in FileSystem that takes a "user" as argument.
    
    Reason: Improvement
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Eli Collins <eli@cloudera.com>  Fri, 12 Nov 2010 19:46:24 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f8b9f2f2e062b33c752c53e5aa3f871f08fa359c:
    HADOOP-6985. Suggest that HADOOP_OPTS be preserved in hadoop-env.sh.template.
    
    Reason: Improvement
    Author: Ramkumar Vadali
    Ref: CDH-2271
    
 -- Eli Collins <eli@cloudera.com>  Wed, 10 Nov 2010 15:51:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 78b9e608a82c69e59950d4be585fc17e79c8eeca:
    CLOUDERA-BUILD. Remove the MySQL Connector/J library. See SQOOP-97.
    
 -- Eli Collins <eli@cloudera.com>  Wed, 03 Nov 2010 16:32:40 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 835e4b2f8d5f5b8de9eaaf6b2585a62224574323:
    HDFS-1464. Fix reporting of 2NN address when dfs.secondary.http.address is default
    
    Reason: regression due to HDFS-1080
    Author: Todd Lipcon
    Ref: CDH-2226
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 19 Oct 2010 15:20:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 62a9a1327165a1a363639c2f21b79be61616f7b3:
    HADOOP-6663. Fix decompression of empty compressed files
    
    Author: Kang Xiao
    Ref: CDH-2215
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 14 Oct 2010 13:21:34 -0400


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 98c55c28258aa6f42250569bd7fa431ac657bdbd:
    CLOUDERA-BUILD. Fix ownership of .out files when starting daemons as root
    
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 08 Oct 2010 17:07:56 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 16ba98db9791a1a24aff066ae884c64abb4b589a:
    CLOUDERA-BUILD. Use su instead of sudo for dropping root privileges.
    
    This fixes an issue on EC2, where some AMIs don't properly support
    sudo.
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 08 Oct 2010 14:18:57 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9616bfbd1f2dd2686a29f47c62fff08d955a7ac8:
    HADOOP-6995. Allow wildcards to be used in ProxyUsers configurations
    
    Author: Todd Lipcon
    Ref: CDH-648
    
 -- Todd Lipcon <todd@lipcon.org>  Fri, 08 Oct 2010 14:14:49 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 374e10963329ec08d861774d056d1c5ee673f4c8:
    Amend MAPREDUCE-2096. Fix IndexOutOfBoundsException truncating logs when tasks produced no log output
    
    Author: Todd Lipcon
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 08 Oct 2010 12:43:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 49e808c8751615fe154061d456f171f8bb582504:
    CLOUDERA-BUILD. Add symlinks to built HADOOP_HOME like hadoop-core.jar -> hadoop-core-0.20.2+NNN.jar
    
    This helps other projects create symlinks into the installed hadoop-home without
    having to declare a dependency on a particular patchlevel of the jar.
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 07 Oct 2010 18:10:47 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4904e0fbd60c5f043bb1451ca4e3be012be8cf59:
    Amend HDFS-1260. Add some sanity checking on FSDataset
    
    Reason: Help debug errors seen in the wild
    Author: Todd Lipcon
    Ref: CDH-913
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 07 Oct 2010 16:52:38 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b919f0a99b2ac3b48a32b0906d19c2b306f7a554:
    CLOUDERA-BUILD. Don't use HADOOP_IDENT_STRING to set user
    
    This was a misuse of this variable - it should only determine the name of the log/pid files
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 06 Oct 2010 18:38:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit eed3bc71002f4cbf3fd0aaeef7016cb80cf61a4a:
    CLOUDERA-BUILD. Amend bin/hadoop changes to properly start tasktracker and jobtracker with sudo
    
 -- Todd Lipcon <todd@lipcon.org>  Wed, 06 Oct 2010 18:05:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8bb561e0dc46995cca059b5de334b3b790b8ae17:
    Amend MAPREDUCE-2096. fsError() when called from within MR should not do authorization
    
    Reason: Fix incorrect authorization exception
    Author: Todd Lipcon / Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@lipcon.org>  Wed, 06 Oct 2010 17:39:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ce67cd87f21543348ca5c137dee3ff0dc7f338dd:
    HADOOP-6988. Add support for reading multiple hadoop delegation token files
    
    Author: Aaron T. Myers
    Reason: So Hue can submit jobs authenticated against both the JT and NN.
    Ref: CDH-648
    
 -- Aaron T. Myers <atm@cloudera.com>  Tue, 05 Oct 2010 21:03:50 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ca36717c2b3bc9d610ba2a049b98f798b9d8c1c1:
    CLOUDERA-BUILD. No need to restrict jsvc usage to secure clusters
    
    Reason: It is simpler to always start the DN as root and let it drop privileges
            when jsvc is available. This is OK even if kerberos auth is off.
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 05 Oct 2010 15:33:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 60a6eece06bde26516649bdcbed4096dd734503e:
    CLOUDERA-BUILD. Send SecurityAudit logs to the console unless running through hadoop-daemon.sh
    
    Reason: Fixes issue where clients would try to write SecurityAuth.audit logs
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 05 Oct 2010 00:31:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit dccf120c3796312b1a67481daaa0366b13d471fe:
    CLOUDERA-BUILD. Amend Task Controller for sbin-located task-controller
    
    Reason: earlier commit moved task-controller to an sbin directory, this updates
    	the java side
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 05 Oct 2010 00:31:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c7f9a8ece8b63fa571420b0c1e40044177b8e42d:
    CLOUDERA-BUILD. Redo hadoop and hadoop-daemon.sh scripts to be more compatible with packaging
    
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 05 Oct 2010 00:31:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d56be41bb9648f721ba6714827ccfbf503af7d84:
    Amend MAPREDUCE-2103. task-controller does not require setgid permissions
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 05 Oct 2010 00:31:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7689035d99d720f374c543697016ef23fec7f4f8:
    CLOUDERA-BUILD. Update example secure config
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 05 Oct 2010 00:31:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit eebf85c655d085b5cc49860d5ac59078a99e2349:
    DISTRO-29. Switch Hue thrift plugin port to 10090 to avoid conflicting with HBase.
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-1815.
    
 -- Eli Collins <eli@cloudera.com>  Mon, 04 Oct 2010 14:14:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a93572183d61bcc9523206450a017c8908795009:
    Amend MAPREDUCE-2096. Fix issue where JVM authorization was incorrectly triggered
    
    Reason: TaskRunner calls TaskTracker.reportDiagonsticInfo directly at one point,
            so the current user is the MR user, rather than the Job. This patch
            changes the TaskRunner to call to an unauthorized version of the function.
    Author: Todd Lipcon
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Sun, 03 Oct 2010 23:15:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7fb2c9a498db04a93aeee6fe7f2beb4abdf7489f:
    MAPREDUCE-2103. task-controller shouldn't require o-r permissions
    
    Author: Todd Lipcon
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Sun, 03 Oct 2010 23:14:43 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9a17aaf708514474dff8be5706c798b4c1d5199f:
    CLOUDERA-BUILD. jsvc and task-controller should install into a platform-specific dir
    
 -- Todd Lipcon <todd@cloudera.com>  Sun, 03 Oct 2010 23:14:43 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 766c6c6e77514164afbd5f14ca171419106d93de:
    CLOUDERA-BUILD. do-release-build should build task controller
    
 -- Todd Lipcon <todd@cloudera.com>  Sun, 03 Oct 2010 23:14:39 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 81762d84ddc11fb5268c2ae92feb47d9e1197f1a:
    HDFS-1377. Quota bug for partial blocks allows quotas to be violated.
    
    There may be a delta in FSDirectory#replaceNode even with identical
    blocks because INode#diskspaceConsumed rounds up the size of the last
    block if newnode is under construction. This causes us to incorrectly
    reduce the space consumed for quota accounting. Looking at uses of
    this functions oldnode and newnode should always have the same blocks,
    therefore we should not expect a delta here.
    
    Reason: Bug
    Author: Eli Collins
    Ref: CDH-2092
    
 -- Eli Collins <eli@cloudera.com>  Sun, 03 Oct 2010 15:41:50 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 78625c0dfb4e0f819f79ce29d215097e87790012:
    HADOOP-6408. Add a servlet at /conf to display running configuration
    
    Reason: Easier debugging and support
    Author: Todd Lipcon
    Ref: CDH-2175
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 29 Sep 2010 22:49:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 91fa1dfdd74ebac1e88da1d3adb644cf5fe84e7a:
    HADOOP-6496. HttpServer sends wrong content-type for CSS files (and others)
    
    Author: Todd Lipcon
    Reason: Fixes styling on web UIs
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 29 Sep 2010 22:49:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9309cf6f1851cc1b379028235b79cc2cf9fe1774:
    DISTRO-38. Autotools cannot find libssl on fedora
    
    Description: Some GNU/Linux distribution have changed the DSO-linking semantics of the gcc compiler.
    Previously ld would attempt to implicitly satisfy link requirements and therefore implictely add libcrypto when linking to libssl.
    The dependency on libcrypto must now be explicitely stated on these platform when linking to libssl.
    See https://fedoraproject.org/wiki/Features/ChangeInImplicitDSOLinking and https://fedoraproject.org/wiki/UnderstandingDSOLinkChange
    Reason: Bug
    Author: Bruno Mahé
    Ref: DISTRO-38
    
 -- Bruno Mahé <bruno@cloudera.com>  Wed, 29 Sep 2010 17:28:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit daa2fd5e76c63c9d9efa11225383fd5496442862:
    CDH-2137. Jsvc requires to set the architecture flag to the link command
    
    Reason: Bug
    Author: Bruno Mahé
    
 -- Bruno Mahé <bruno@cloudera.com>  Wed, 29 Sep 2010 17:14:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 66e1ba8787ef26f68cc3ec125efd85a776748c36:
    Amend MAPREDUCE-2096. Rebootstrap native
    
    Reason: Previous libtoolize wasn't run with --copy, so broken link was in repo
    Author: Todd Lipcon
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 29 Sep 2010 13:17:56 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 90167ef041f15f351ac6357212c477c682373e05:
    HADOOP-6907, HADOOP-6938, HADOOP-6905. Fix RPC client behavior to use a per-connection configuration.
    
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 28 Sep 2010 13:20:49 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3f2759c884c496ef71a75db9d436ebfe61e04111:
    MAPREDUCE-1288. DistributedCache may localize a private file for multiple users
    
    Reason: bug fix when multiple users add the same "private" file to their distributed caches
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 28 Sep 2010 13:20:49 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c109efb9579e830587e5f7c1762c816d5d241b71:
    HDFS-1301. TestHDFSProxy needs to use the server side conf for ProxyUser settings.
    
    Reason: Fix failing unit test after HADOOP-6815 application
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 28 Sep 2010 13:20:49 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a1cdd7b028bfd5aaf6bdbfe18122b9a0fb44ed12:
    CLOUDERA-BUILD. Upgrade Jackson to 1.5.2 to avoid conflicts with Avro and HBase
    
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 28 Sep 2010 13:20:49 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 11d842c61eb63c156e1c3f753d795868bbd2fa0a:
    HADOOP-6815. refreshSuperUserGroupsConfiguration should use server side configuration for the refresh
    
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 28 Sep 2010 13:20:49 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6b3856a94ca4748cc8e891cdd11473c03f821ee4:
    MAPREDUCE-2096. Secure local filesystem IO from symlink vulnerabilities
    
    Reason: security vulnerability that could be exploited to gain access to
            other user's job credentials, task output, etc.
    Author: Todd Lipcon
    Ref: CDH-2009
    
 -- Todd Lipcon <todd@cloudera.com>  Tue, 28 Sep 2010 13:19:35 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0b213def5dbb9dc7a90009a3446a913ea15f5ee7:
    HADOOP-6951. Distinct minicluster services (e.g. NN and JT) overwrite each other's service policies
    
    Description: Make ServiceAuthorizationManager's map of service ACLs instance-specific, instead of static.
    Reason: To make HUE's tests work against CDH3.
    Author: Aaron T. Myers
    Ref: CDH-648
    
 -- Aaron T. Myers <atm@cloudera.com>  Fri, 24 Sep 2010 12:02:29 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 85565602b4cebbd91829a0d434e86edd8990fcbc:
    DISTRO-32. Make the default example configuration support Hue.
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-1815
    
 -- Eli Collins <eli@cloudera.com>  Tue, 21 Sep 2010 19:22:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0248b41179a0baf9dd7e4120137f0c24b7251e95:
    DISTRO-1. Add /usr/lib/jvm/default-java to HADOOP_HOME detection.
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-1979
    
 -- Eli Collins <eli@cloudera.com>  Tue, 21 Sep 2010 19:22:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 55958019974d56fb1b66e209b49c22efe4a4aa95:
    CLOUDERA-BUILD. Change pom templates to use com.cloudera.hadoop groupId
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 16 Sep 2010 16:52:39 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6931d93bec73254f13ba08cbe49589a747eb399d:
    HADOOP-6946. SecurityUtil's ticket-fetching should call UGI.getCurrentUser rather than directly accessing JAAS
    
    This fixes a bug where a daemon could call login() and thus set the loginUser(),
    and then still have a null Subject, leading to an inability to fetch TGTs.
    This impacted, for example, the "-checkpoint force" start-up option of the 2NN.
    
    Reason: Fix 2NN startup with forced checkpoint
    Author: Todd Lipcon
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 16 Sep 2010 15:09:31 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5fe725b1a48326bf606dadfc636586904aa861c4:
    HDFS-1378. Track and report file offsets in cases of edit log replay failure.
    
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 16 Sep 2010 15:09:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c3b6e1fadf01e1955fff7361cb7872ff4fd997ab:
    Amend HADOOP-6656. Renewal thread should shut down if it fails to renew
    
    Reason: fixes tight infinite loop that heavily loads KDC
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 16 Sep 2010 15:09:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 593f3831671202afef2555243f37ca8f7ac2c46c:
    Amend HDFS-895. Fix races between close() and sync()
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 16 Sep 2010 15:09:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a9adf89fd17aa3199c4c4f26d7a2d5f8ccffc84d:
    Amend HADOOP-6539. Fix docs to remove mention of sticky bit feature not backported
    
    Author: Todd Lipcon
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 16 Sep 2010 15:09:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4da1b0da8e176f6d7cf5bdc13786f37e254b6eda:
    HDFS-1387. Update HDFS permissions guide to reflect security
    
    Reason: documentation
    Ref: CDH-648
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 16 Sep 2010 15:09:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 10db8fc860cd1c5de28d204b0efecb37476f0483:
    HDFS-1404. Incorrect logic in TestNodeCount causes test failures
    
    Reason: Fix occasional red build
    Author: Todd Lipcon
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 16 Sep 2010 15:09:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 283d6b8d3d1c0ffece93bdf4046b09972b0f44a3:
    HADOOP-6950. Suggest that HADOOP_CLASSPATH should be preserved in hadoop-env.sh.template.
    
    Reason: Improvement
    Author: Philip Zeyliger
    Ref: CDH-2135
    
 -- Eli Collins <eli@cloudera.com>  Thu, 16 Sep 2010 00:05:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b7679d80577d1d3625f520fc01787b4f75faab1d:
    MAPREDUCE-2073. TestTrackerDistributedCacheManager should be explicit about test environment requirements
    
    Reason: Assist testing
    Author: Todd Lipcon
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 15 Sep 2010 22:43:18 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 892b49d1fd8725323dfbbb19269ec16debe05c57:
    HDFS-1267. fuse-dfs does not compile.
    
    Reason: Bug
    Author: Devaraj Das
    Ref: CDH-2134
    
 -- Eli Collins <eli@cloudera.com>  Wed, 15 Sep 2010 20:08:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 98f1914cc0c6f91f8c0e3aa8cea8e7609b49c901:
    HDFS-1000. Updates libhdfs to the new API for UGI.
    
    Reason: Bug
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Eli Collins <eli@cloudera.com>  Wed, 15 Sep 2010 20:02:53 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5966f146fdb0202c0ffd66d3ec3f0c7c4def6afe:
    Revert "HDFS-1000. libhdfs needs to be updated to use the new UGI"
    
    Description: This is being reverted to apply a newer version of the patch.
    Author: Devaraj Das
    Ref: UNKNOWN
    
 -- Eli Collins <eli@cloudera.com>  Wed, 15 Sep 2010 20:01:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d0b28bf2a7ebeff419c7226310aaff7de290af22:
    HADOOP-6881. The efficient comparators aren't always used except for BytesWritable and Text.
    
    Reason: Bug
    Author: Owen O'Malley
    Ref: CDH-2112
    
 -- Eli Collins <eli@cloudera.com>  Fri, 10 Sep 2010 09:45:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cdb501c28dcdeec73ccf92a886bf943f665a5693:
    HDFS-446. Improvements to Offline Image Viewer.
    
    Author: Jakob Homan
    Ref: CDH-2106
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 03 Sep 2010 17:09:58 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 83da6170d68e29c1ae7881c2606af59a2145a8aa:
    HDFS-461. Tool to analyze file size distribution in HDFS.
    
    Author: Konstantin Shvachko
    Ref: CDH-2106
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 03 Sep 2010 17:09:41 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit dc0e28f08c2df37a6b99614a5c764fc4037032a0:
    HADOOP-5752. Add a new hdfs image processor, Delimited, to oiv.
    
    Author: Jakob Homan
    Reason: Hue Headlamp app
    Ref: CDH-2106
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 03 Sep 2010 17:03:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7362cada95bd07ff3b034f5c7fb15b42365c2d06:
    HADOOP-5467. Add offline image viewer tool for HDFS filesystem images
    
    Author: Jakob Homan
    Reason: Necessary for Hue Headlamp application
    Ref: CDH-2106
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 03 Sep 2010 16:55:59 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b94821f874983e64c78fc93d95539a4f262dca78:
    HADOOP-6939. Fix inconsistent lock ordering in AbstractDelegationTokenSecretManager
    
    Reason: Fix potential deadlock
    Author: Todd Lipcon
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 03 Sep 2010 16:22:58 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ae58865f3d65faa78707c79536c16e5b7ce40c16:
    MAPREDUCE-2051. Add a fair share scheduler system test
    
    Reason: Helps identify deadlocks or races in fair scheduler
    Author: Todd Lipcon
    Ref: CDH-1823
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 03 Sep 2010 16:22:35 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b839ebbb2f517eb57930dbe8ed40afc5307dbe3a:
    MAPREDUCE-1280. Eclipse Plugin does not work with Eclipse Ganymede (3.4).
    
    Reason: Bug
    Author: Alex Kozlov
    Ref: CDH-537
    
 -- Eli Collins <eli@cloudera.com>  Fri, 03 Sep 2010 12:45:07 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 62661841b0687c431f4a066323b8ebb959b90612:
    DISTRO-27. Fix CombineFileInputFormat incompatible API change
    
    - Revert CombineFileInputFormat to branch-0.20 r990003
    - Reapply following patches to old-API CombineFileInputFormat:
     - MAPREDUCE-1480. Apply more correct progress indication to old-API CombineFileRecordReader
     - MAPREDUCE-1423. Improve performance of CombineFileInputFormat when multiple pools are configured
    - Resuscitate old-API test for CombineFileInputFormat
    
    Author: Todd Lipcon et al
    Reason: Fix hive integration issue
    Ref: DISTRO-27
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 01 Sep 2010 22:26:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e8d93d35b92d602d8095657bb08a949bfb5aeea8:
    HADOOP-5861. s3n files are not getting split by default.
    
    Reason: Bug
    Author: Tom White
    Ref: CDH-2011
    
 -- Eli Collins <eli@cloudera.com>  Mon, 30 Aug 2010 17:53:54 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 527b0ee624e8a02b357f2a2a1a31fa798f832d35:
    HADOOP-6925. BZip2Codec incorrectly implements read().
    
    Description: HADOOP-4012 added an implementation of read() in BZip2InputStream
    that doesn't work correctly when reading bytes > 0x80. This causes
    EOFExceptions when working with BZip2 compressed data inside of sequence files
    in some datasets.
    
    Reason: Bug
    Author: Todd Lipcon
    Ref: CDH-2068
    
 -- Eli Collins <eli@cloudera.com>  Fri, 27 Aug 2010 16:55:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8f374b1eff2a54fd05590b935c3179c9b686fc0b:
    HADOOP-6928. Fix BooleanWritable comparator in 0.20.
    
    Description: The RawComparator for BooleanWritable was fixed as part of
    HADOOP-5699 in 0.21 and trunk. The fix should be pushed back into 0.20.
    
    Reason: Bug
    Author: Owen O'Malley
    Ref: CDH-2063
    
 -- Eli Collins <eli@cloudera.com>  Fri, 27 Aug 2010 15:12:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0dee7a8262a12b12e448a4342b636842646c16d0:
    HADOOP-6833. IPC leaks call parameters when exceptions thrown.
    
    Reason: Bug
    Author: Todd Lipcon
    Ref: CDH-2063
    
 -- Eli Collins <eli@cloudera.com>  Thu, 26 Aug 2010 20:17:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e7c81789d095a30fb8abf93557d10b84ea66eaea:
    CLOUDERA-BUILD. Add sample configuration for a secure cluster based on YDH's sample
    
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:40 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit fc5270e00c648eb20737918eb689a0d4c4200e98:
    Amend HDFS-1260. Fix case where FSDataset's volume map could become inconsistent with disk storage
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:40 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5e76abac366a112c5d221750332ba2c272f319d0:
    MAPREDUCE-2034. Fix TestSubmitJob to verify actual IOException text
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ab1f3a96c00e2eb53569c1ba682d73ed10bfb4b5:
    Amend HADOOP-6762. Fix gridmix test failures when JobMonitor RPC is interrupted
    
    Reason: HADOOP-6762 added a new exception cause when outbound RPCs are Interrupted.
            This patch fixes gridmix to be aware of InterruptedExceptions.
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ecc1a3b745384b0f925cb6efc7b6775240ad9195:
    HDFS-1164. Fix problem in TestHdfsProxy when user running tests doesn't belong to 'users' group
    
    Author: Todd Lipcon
    Reason: fix broken unit test
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bef7c171a5fd2663b5d16bdbba4477ee54947df6:
    HDFS-1313. HdfsProxy changes from HDFS-481 missed in y20.1xx
    
    Author: Rohini Palaniswamy
    Reason: Changes accidentally ommitted from HDFS-481 YDH backport, fixes hdfsproxy
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 67048e890eff6c9cd548dcdc980f5ff3072234cc:
    MAPREDUCE-1682. Fix speculative execution to ensure tasks are not scheduled after job failure.
    
    Author: Arun C Murthy
    Reason: Fixes potential wasted task slots
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d9b7bd0ff1b74a579761d1bd8d9130c7adb9e80c:
    MAPREDUCE-1914. Ensure unique sub-directories for artifacts in the DistributedCache are cleaned up.
    
    Author: Dick King
    Reason: Without patch, distributed cache accumulates directories until reaching dirent limit (32K)
            after which the TT fails.
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit eb44564b61a0467aa2891fd3a434eda20ac30d7b:
    MAPREDUCE-1538. Add a limit on the number of artifacts in the DistributedCache to ensure we cleanup aggressively.
    
    Author: Scott Chen
    Reason: Without patch, subdirectory count in cache grows without bound.
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f9051921efb8d76b0dcd0eed27fd15600635caf0:
    MAPREDUCE-2035. Fix task controller build to use -Wall, fix warnings
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9d3d402301267201d771becef005864e48ea5b82:
    MAPREDUCE-1900. MapReduce daemons should close FileSystems that are not needed anymore
    
    Patch: https://issues.apache.org/jira/secure/attachment/12448230/mapred-fs-close.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12448509/fs-close-delta.patch
    Author: Kan Zhang
    Reason: Secured MR daemons often open DFS instances on behalf of a given user, which then
            end up stored in the FS Cache data structure. This patch allows those cache
            entries to be collected, preventing possible OOME scenario.
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 945dc2bdacb99855b66ce70b3024a6f0f8b9f2d6:
    HADOOP-6832. Add a static user plugin for web auth for external users.
    
    Author: Owen O'Malley
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 00b53896f9de47f36fe8ea5a4ffaa13a85877a3c:
    HDFS-1007. Update HFTPFileSystem to use delegation tokens to support security.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443223/1007-bugfix.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12446280/hdfs-1007-long-running-hftp-client.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12446362/hdfs-1007-securityutil-fix.patch
    Author: Devaraj Das
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 221b3e83ec620bb4903946574fe0b250db58fc8a:
    HDFS-1178. The NameNode servlets should not use RPC to connect to the NameNode.
    
    Author: Owen O'Malley
    Reason: Cleanup
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8de996f7fac526c605e1931744e7937f90471e88:
    MAPREDUCE-1807. Re-factor TestQueueManager to not timeout
    
    Author: Dick King
    Reason: Fix failing unit test
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f831304f9adfd7668283310e73ea66185674adc6:
    HADOOP-6781. Security audit log shouldn't have exceptions in it.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12445092/HADOOP-6781-BP20.patch
    Author: Boris Shkolnik
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5459775249f78827a23863322002f5b0695a04d7:
    HADOOP-6776. UserGroupInformation.createProxyUser's javadoc is broken
    
    Patch: https://issues.apache.org/jira/secure/attachment/12444980/6776.patch
    Author: Devaraj Das
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 07b56fcda093c41a142668171cf7bc953c9e4db8:
    Amend MAPREDUCE-1664. Bug fix to enable queue admins to view jobs.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12444782/1664.qAdminsJobView.20S.v1.6.patch.
    Author: Ravi Gummadi
    Reason: bug fix to prior patch
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e81e1a34349a1d6a35faddeed4d7ff2087a6a48c:
    HDFS-1157. Modifications introduced by HDFS-1150 are breaking aspect's bindings
    
    Patch: https://issues.apache.org/jira/secure/attachment/12444716/hdfs-1157.patch
    Author: Konstantin Boudnik
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a8b230d68070e829a2717805c8d3f7c995bf0ae0:
    HDFS-1130. Authorize access to default HDFS servlets with a DFS administrator ACL
    
    Patch: https://issues.apache.org/jira/secure/attachment/12444565/hdfs-1130.3.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:08:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f87ec798d3f48c701cdb24372ad15e7d269e580f:
    Amend HDFS-1150. Allow the requirement of DNs on low ports to be relaxed by a config
    
    Reason: simplifies testing, and allows running with other security methods
    Author: Todd Lipcon
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 18:07:18 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8ad787821eaf906170fc913c5030b147b0bd6e80:
    HDFS-1150. Let DataNodes bind to privileged ports in order to verify their identity better to clients
    
    Patch: https://issues.apache.org/jira/secure/attachment/12444541/HDFS-1150-Y20S-ready-8.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12444811/hdfs-1150-bugfix-1.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12444864/hdfs-1150-bugfix-1.2.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12445111/HDFS-1150-BF-Y20-LOG-DIRS-2.patch
    Author: Jakob Homan
    Reason: The DataXceiverProtocol does not provide mutual authentication. Binding the DNs to a low port
            number makes it harder for an attacker to impersonate a DN.
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:32 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 20f55449358f96fd20f74f3f92c24dce763158e1:
    MAPREDUCE-1716. Truncate logs of finished tasks to prevent node thrash due to excessive logging
    
    Patch: https://issues.apache.org/jira/secure/attachment/12444476/patch-log-truncation-bugs-20100514.txt
    Author: Vinod K V
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:32 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 055c06d1fba4cead09fe70e1cc56873f51927dfb:
    MAPREDUCE-1442. Fixed regex in job-history related to parsing Counter values.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12444349/mr-1442-y20s-v1.patch
    Author: Luke Lu
    Reason: Avoid StackOverflowError when JobHistory parses a really long line
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:32 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 24a779aa3f4ee27c596f26c0a524433422c91689:
    HADOOP-6760. WebServer shouldn't increase port number in case of negative port setting caused by Jetty's race
    
    Patch: https://issues.apache.org/jira/secure/attachment/12444455/HADOOP-6760.0.20.patch
    Author: Konstantin Boudnik
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:31 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a1bd71986a43df303166c7a6a3bf6d3e38d2f908:
    HDFS-1146. Add Javadoc for getDelegationTokenSecretManager in FSNamesystem
    
    Patch: https://issues.apache.org/jira/secure/attachment/12444261/HDFS-1146-y20.1.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:31 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7a38053228f4b8368c183a6658d93df2a216d4ab:
    MAPREDUCE-1744. Fixed DistributedCache apis to take a user-supplied FileSystem to allow for better proxy behaviour for Oozie.
    
    Amended to not deprecate any methods, since their future in the next major release has not been decided yet.
    Patch: https://issues.apache.org/jira/secure/attachment/12444060/MAPREDUCE-1744.patch
    Author: Dick King
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:31 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a696ed00e06ec9cac5b0f0e53a7fc6bcafb6c69f:
    MAPREDUCE-1733. Authentication between pipes processes and java counterparts.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12444054/MR-1733-y20.3.patch
    Author: Jitendra Nath Pandey
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:31 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 37bbc27c772ba033670be8d6323ca1a9191d34a7:
    HADOOP-6756. Clean up and document configuration keys in CommonConfigurationKeys.java
    
    Patch: https://issues.apache.org/jira/secure/attachment/12444008/jira.HADOOP-6756-0.20-1.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12444017/jira.HADOOP-6756-0.20-1-FS_DEFAULT_NAME_KEY.patch
    Author: Erik Steffl
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:31 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5127aafd818ec2c57d02481f221bff3534e12d14:
    HDFS-1136. FileChecksumServlets.RedirectServlet doesn't carry forward the delegation token
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443986/HDFS-1136-BP20-2.patch
    Author: Boris Shkolnik
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:31 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6951f1e5bbac61b1a1cc3587b712598ed993c729:
    MAPREDUCE-1759. Improve exception message for unauthorized user doing killJob, killTask, setJobPriority
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443983/1759.20S.1.patch.
    Author: Ravi Gummadi
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:31 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8a02b7518c90634ec256fa836757919f600fa0e9:
    HADOOP-6715. Fix AccessControlList.toString behavior when ACL is set to "*"
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443982/6715.20S.6.patch
    Author: Ravi Gummadi
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 057e7fc4942d0aa9a36f5b0ae2dd73d516fcf8ba:
    HADOOP-6757. Fix NPE when streaming jobs launch further Hadoop clients
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443934/BZ-3620565-v1.0.patch
    Author: Amar Kamat
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b24898d75d8239697d215475dfe1b305ada90e5f:
    HADOOP-6631. FileUtil.fullyDelete should continue deleting after partial failure
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443931/HADOOP-6631-20100506-ydist.final.txt
    Author: Ravi Gummadi
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2b0d6bb28d3733a2c42ebbbb4bfc294044c8e619:
    MAPREDUCE-1754, HADOOP-6748. Replace mapred.permissions.supergroup with an ACL instead of single group
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443928/patch-1754-ydist.txt.
    Author: Amareshwari Sriramadasu
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cf50e5a91e7159f7f06518162a7400cc681c7f08:
    HADOOP-6701. Incorrect exit codes for "dfs -chown", "dfs -chgrp"
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442987/HADOOP-6701-v20.patch
    Author: Ravi Phulari
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 463557b922ac3579aa130d01f780ab3c2e32b70f:
    HADOOP-6640. FileSystem.get() does RPC retries within a static synchronized block
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443759/getFS_yahoo20s.patch
    Author: Hairong Kuang
    Reason: Fixes potential performance issue in multithreaded environment
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 781ae842245a6fb948de72d39658b28eab7c2cfe:
    HDFS-1006. Secure image transfer between NN and 2NN
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443766/hdfs-1006-bugfix-1.patch
    Author: Boris Shkolnik
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 497fefb3b9132b912a569577bc643c20a273707e:
    HADOOP-6745. Add JavaDoc to Server.RpcMetrics, UGI
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443726/HADOOP-6745-BP20-2.patch
    Author: Boris Shkolnik
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 51d7be14f892334ea1ad399a34d91ea1bd10e804:
    MAPREDUCE-1707. Fix potential NPE in TaskRunner
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443680/MAPREDUCE-1707-20100504-ydist.txt
    Author: Vinod K V
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2647aae4985ca29e222567d8bfc77e2569fde81c:
    HDFS-1104. Change fsck to not update block access times
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443523/fsckATime_Yahoo0.20.patch
    Author: Hairong Kuang
    Reason: prevents a possible NN OOME during fsck
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 392bd0e68be1621406d3556303c30f00d6dfd019:
    Amend HADOOP-6332. Add large-scale test framework "Herriot" that runs against real clusters.
    
    Reason: Phase two of Herriot framework
    Patch: https://issues.apache.org/jira/secure/attachment/12443539/6332-phase2.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12443668/6332-phase2.fix1.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12443788/6332-phase2.fix2.patch
    Author: Konstantin Boudnik
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:29 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c04645dd48af89b8191e090efd15f8520946a606:
    HADOOP-6693. Add metrics to track kerberos login activity
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443326/HADOOP-6693.rel20.1.patch
    Author: Suresh Srinivas
    Reason: Security
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:29 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4bce823b6ae54b527cfa25e7802e9a1c83f5b5d2:
    HADOOP-6710. Symbolic umask for file creation is not consistent with posix
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443134/hadoop-6710.rel20.patch
    Author: Suresh Srinivas
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:29 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e34d5e43768d0f91c0eb847071de7f9b8ec5b323:
    MAPREDUCE-670 and HDFS-1022. Add a fast "commit test" target
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436553/mapreduce-670-y20.patch
    Author: Jothi Padmanabhan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:29 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 60b22e764e8d44570f900632b30b37df22855d0d:
    MAPREDUCE-1711. Gridmix should provide an option to submit jobs to the same queues as specified in the trace.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12443040/MR-1711-yhadoop-20-1xx-7.patch.
    Author: rahul k singh
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:29 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 24093ee575601dc3cfbb67ac63d742fab1f40f2f:
    MAPREDUCE-1687. Stress submission policy does not always stress the cluster. (htang)
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442692/mr-1687-yhadoop-20.1xx-20100423-2.patch.
    Author: rahul k singh
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:29 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 41079a8480984ef8ac84dfe8c97930f0631afc07:
    MAPREDUCE-1641. Fix DistributedCache to ensure same files cannot be put in both the archives and files sections.
    
    Author: Dick King
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:29 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 13c09b6981b1f5bd8e58b3586d67e4652ab716c8:
    MAPREDUCE-1664. Fix job and queue ACLs to interact in a more useful manner.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442697/1664.20S.3.4.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12443139/M1664y20s-testfix.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12444043/mr-1664-20-bugfix.patch
    
    Author: Ravi Gummadi
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:29 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2d09f15358560a61169e64c488f5e6fa7aff1d7f:
    MAPREDUCE-1397. Fix a possible NPE when a killTask command races with a JVM exit
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442657/patch-1397-ydist.txt
    Author: Amareshwari Sriramadasu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:29 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7c0d1d3221c5558979942f8aaba3f14f29c5f7b4:
    HADOOP-6670. Use the UserGroupInformation's Subject as the criteria for equals and hashCode.
    
    Author: Owen O'Malley
    Reason: Security bug fix
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 82b157a5b805c10485712ddb108aa8248ad0df0c:
    HADOOP-6716. System won't start in non-secure mode when kerb5.conf (edu.mit.kerberos on Mac) is not present
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442487/HADOOP-6716-BP20-3.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d8b98cd21187c2d012f022f5fbd3511281f4adbf:
    MAPREDUCE-1607. Fix possible cleanup task failure in LinuxTaskController
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442538/patch-1607-ydist.txt
    Author: Amareshwari Sriramadasu
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d8fe4d58aa93d151e55cd3e427a4b90ce470e7c9:
    MAPREDUCE-1533. JobTracker performance improvements.
    
    Author: Dick King
    Reason: Simple CPU usage optimizations in JT and Capacity Scheduler
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1b1896055e04da90194893c90ac7e2a3787e5077:
    MAPREDUCE-1701. Fix a problem with exception handling in delegation token renewals.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442239/MAPREDUCE-1701-BP20-1.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ea5f8c7922fc5a66e26deb4da55c6088b006e1f0:
    HDFS-1096. Allow refresh of superuser proxy group mappings
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442244/HDFS-1096-BP20-7.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 877288c5ab55849a08a89ce342a8d5984f18a6df:
    HDFS-1012. HDFSProxy support for fully qualified HDFS path in addition to simple unqualified path
    
    Patch: https://issues.apache.org/jira/secure/attachment/12441034/HDFS-1012-bp-y20s.patch
    Author: Srikanth Sundarrajan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4aa8da2788a0794be5469227140509cc87d29c47:
    HDFS-1011. Improve Logging in HDFSProxy to include cluster name associated with the request
    
    Patch: https://issues.apache.org/jira/secure/attachment/12441031/HDFS-1011-bp-y20s.patch
    Author: Ramesh Sekaran
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 689eb75cdd88b4b7a080ab3883f2a317cfb2c664:
    HDFS-1010. HDFSProxy: Retrieve group information from UnixUserGroupInformation instead of LdapEntry
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439437/HDFS-1010-bp-y20s.patch
    Author: Srikanth Sundarrajan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cb39a8280712bb507e159151de5e62895d79268d:
    HDFS-481. Allow HdfsProxy to securely impersonate the real user
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442210/HDFS-481-NEW.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12442280/HDFS-481-bp-y20s.patch
    Author: Srikanth Sundarrajan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:28 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0bb2bf837469bdafa5df1b14ed1fb2991070c9d0:
    MAPREDUCE-1657. Fix incorrect error message when trying to view already-deleted logs of a task.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442135/MR1657.20S.1.patch
    Author: Ravi Gummadi
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1beeed7552f5e83ef24f8926450bb81d7be02b8d:
    MAPREDUCE-1692.  Remove TestStreamedMerge from the streaming tests
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442134/patch-1692-ydist.txt.
    Author: Amareshwari Sriramadasu
    Reason: Test no longer applicable
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit eb456ec5bc5a3afca9a854e9f4708892c8a6e2f5:
    HDFS-1081. Improve performance of block access token implementation
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442023/HADOOP-1081-Y20-2.patch
    Reason: Reduce number of calls to expensive HMAC functions to reduce NN CPU usage
    Author: Jakob Homan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 457cf14f7168bacd185c03c9afc8527210e06410:
    MAPREDUCE-1656. JobStory should provide queue info.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12441905/mr-1656-yhadoop-20.1xx.patch.
    Author: Hong Tang
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c2b68855b127c7dc532ce836fa60dc5c1836f6ec:
    MAPREDUCE-1317. Reducing memory consumption of rumen objects. Contributed by Hong Tang.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442004/mapreduce-1317-yhadoo-20.1xx.patch.
    Patch: https://issues.apache.org/jira/secure/attachment/12443927/3623945-yahoo-20-1xx.patch
    
    Author: Hong Tang
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cbc852fdeccf007260c6e81a15280272a6f90def:
    HADOOP-6706. Improve relogin behavior for RPC clients
    
    Patch: https://issues.apache.org/jira/secure/attachment/12441782/6706.bp20.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12442253/6706.bp20.1.patch
    Author: Devaraj Das
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1444a9469340822ed0af92ee9ac780c7b9835c26:
    HADOOP-6718. Client does not close connection when an exception happens during SASL negotiation
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442614/6718-bp20.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 12bcbba89226fdce99733f366e8eaacd09d95ab7:
    MAPREDUCE-1617. Fix unit test failures due to IPv6-related issues
    
    Patch: https://issues.apache.org/jira/secure/attachment/12441951/mr-1617-v1.3.patch.
    Author: Luke Lu
    Reason: fix unit test
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d60df2ded7690aed311726e6493ca88d578b882b:
    HADOOP-6545. Cached FileSystem objects can lead to wrong token being used in setting up connections
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436456/6545-bp20.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 110cd5235ba960e003ac94824a29a8b0ac36a031:
    MAPREDUCE-1718. Fix a bug in HFTPFileSystem so that delegation tokens function correctly
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442726/MAPREDUCE-1718-BP20-2.patch
    Author: Boris Shkolnik
    Reason: Security
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f37d58671d0e9d601cfd446e6966b3a906d95029:
    MAPREDUCE-587. Fix TestStreamingExitStatus failure case on OSX
    
    Patch: https://issues.apache.org/jira/secure/attachment/12414990/MAPREDUCE-587-v1.0.patch.
    Author: Amar Kamat
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:27 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit eb3c35987b4434c85fb0203c866a7f8fd56674aa:
    MAPREDUCE-1985. Fix for java.lang.ArrayIndexOutOfBoundsException in analysejobhistory.jsp of jobs with 0 maps
    
    Author: Vinod Kumar
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5bebf947cd534ee350844c3626d11dac315372ed:
    MAPREDUCE-1680. Add a metric to track number of heartbeats processed by the JobTracker
    
    Patch: https://issues.apache.org/jira/secure/attachment/12441621/mapreduce-1680--2010-04-08.patch.
    Author: Dick King
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 87c3e693adb3912b5c2755cf7e31f9c1b9973273:
    MAPREDUCE-1683. Removes JNI calls to get jvm current/max heap usage in ClusterStatus by default.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12441563/MAPREDUCE-1683_yhadoop_20_S.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12441978/MAPREDUCE-1683_part2_yhadoop_20_10.patch
    Reason: Performance improvement
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6ddae27ba50b6895509839bb89a7a8e2a0550284:
    HADOOP-6687. User object in the subject in UGI  should be reused in case of a relogin.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12440979/HADOOP-6687-y20.2.patch
    Author: Jitendra Nath Pandey
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f0f38e93276cd5ca8a12c26a0cf138c65fef1951:
    MAPREDUCE-1635. Fix ResourceEstimator after MAPREDUCE-842
    
    Patch: https://issues.apache.org/jira/secure/attachment/12441448/patch-1635-ydist.txt
    Author: Amareshwari Sriramadasu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 56acf64d1453e7de0c87d58bb4565dc1748de5a8:
    MAPREDUCE-1526. Gridmix: Cache the job related information while submitting the job to avoid many RPC calls to JobTracker.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12440983/1594-yhadoop-20-1xx-1-5.patc://issues.apache.org/jira/secure/attachment/12441333/1526-yhadoop-20-101-4.patch
    Author: rahul k singh
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 14c524cb4f78e52ee1d916fa92dfd2665a3a2527:
    HADOOP-6674. Turn off SASL checksums for RPCs. (jitendra via omalley)
    
    Patch: https://issues.apache.org/jira/secure/attachment/12442640/HADOOP-6674-y20.1.bugfix.patch
    Author: Jitendra Nath Pandey
    Reason: Performance Improvement in Secure RPC
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c145357a86dcabe072a3f93775c8f45161452841:
    HADOOP-5958. Replace fork of DF with library call.
    
    Author: Aaron Kimball
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2de11fbbf173eef5b35a3ae10777c87728492355:
    HDFS-999. Secondary namenode should login using kerberos if security is configured.
    
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9d2cc8f9f81c8a39f4c8e1d7e00765ee29808145:
    MAPREDUCE-1594. Support sleep jobs in gridmix
    
    Patch: https://issues.apache.org/jira/secure/attachment/12440983/1594-yhadoop-20-1xx-1-5.patch
    Author: rahul k singh
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit af4ddb7f8866cf5fdcee45a91a7f10cb2e70c51a:
    HDFS-955. Fix bug where FSImage.saveFSImage could lose edits
    
    Patch: https://issues.apache.org/jira/secure/attachment/12440925/saveNamespace-0.20.patch
    Author: Konstantin Shvachko
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d229a5fc83e4722162912a60eae40121f2e504e6:
    HDFS-1007. Update HFTP to use delegation tokens
    
    Patch: https://issues.apache.org/jira/secure/attachment/12440931/HDFS-1007-BP20-fix-3.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:25 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 46bb5af895747384e2698de9a628b8bea86093d0:
    HDFS-1080. SecondaryNameNode image transfer should use the defined http address rather than local ip address
    
    Patch: https://issues.apache.org/jira/secure/attachment/12440810/HDFS-1080-Y20.patch
    Author: Jakob Homan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:25 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 46683a5902d3c698e08dde2b1e2464da7636b809:
    HADOOP-6539. Update various pieces of documentation
    
    Patch: https://issues.apache.org/jira/secure/attachment/12440665/C6539-2-y20s.patch
    Author: Corinne Chandel
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:25 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9637fcdf4f49a8a6f8674f9ca047b33ab34dba0d:
    HADOOP-6682. Fix incorrect hostname normalization for hostnames starting with [a-f]
    
    Author: Jakob Homan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:25 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 976302c14eeebc784e85d4af4746d45d39803a70:
    HADOOP-6661. Add documentation on how to securely impersonate other users
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439897/HADOOP-6661-y20.2.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:25 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 25c7e968255a8fdacaaaca0358ce8894d7d925a3:
    MAPREDUCE-1624. Document job credentials and delegation tokens
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439738/job-creds.2.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:25 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c0dbf7361b383dd2e179eb33a5beeb7d6e52fc10:
    HADOOP-6656. Renew Kerberos TGT when 80% of the renew lifetime has been used up. (omalley)
    
    Author: Devaraj Das
    Reason: Security framework needs to renew Kerberos tickets while the process is running
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:25 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9ecece0b50dbc523a1b9a7c48bb6330ae6e8c93e:
    HADOOP-6653. Protect against NPE in setupSaslConnection when the real user is NULL.
    
    Author: Owen O'Malley
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:25 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a1871a06d05bcaa41c68673b68339a10c5f5e183:
    HADOOP-6652. Remove redundant cache in ShellBasedUnixGroupsMapping
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439372/groups.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:25 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ba1b824bfccac3386041eab7dbf29f5c7d4b8662:
    HADOOP-6649. The login object should be moved to the subject in the UGI.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439344/HADOOP-6649-y20.1.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12439391/HADOOP-6649-y20.1.1.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:25 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 68b5ce77348d26ed4c694a505e7ad00f4ebfc650:
    HADOOP-6637. Add benchmark for overhead of RPC session establishment
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439348/miniRPCBenchmark-20-100.patch
    
    Author: Konstantin Shvachko
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5f84248c0faa67eddf505c5afa7b9f320b23e35c:
    HADOOP-6648. Credentials must ignore null tokens that can be generated when using HFTP to talk to insecure clusters.
    
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 635b88303ce6ef229308b9787469cc5b04b4fe3c:
    HADOOP-6647. Service authorization should compare short names, not full names.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439325/HADOOP-6647-BP20.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ea78340db1b2eb3333a5f79fad076285f82917e7:
    MAPREDUCE-1612. job conf file is not accessible from job history web page
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439310/jobconf_history_jsp.fix.20S.patch
    Author: Ravi Gummadi
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 94abbf7bee9701230cff703aac7d740ff0333176:
    MAPREDUCE-1611. Add service authorization to the AdminOperationsProtocol
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439295/MAPREDUCE-1611-20100319-ydist.txt.
    Author: Amar Kamat
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 51c966ff9e07ff017eb1960cac87d8035e4549c6:
    HADOOP-6644. Fix incorrect code style in util.Shell
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439243/HADOOP-6644-BP20.patch
    Author: Boris Shkolnik
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ef89b9ba5cacecaf5fd292b8cf2e6ebe347e85b7:
    MAPREDUCE-1609. TaskTracker.localizeJob should not set permissions on job log directory recursively
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439278/MAPREDUCE-1609-20-1.patch
    Author: Amareshwari Sriramadasu
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9d3a600899712a637109816b5f50b99257ceb79c:
    MAPREDUCE-1610. Forrest documentation should be updated to reflect the changes in MAPREDUCE-856
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439252/MAPREDUCE-1610-20.patch
    Author: Ravi Gummadi
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit aa3c9671cd7cfa6818c913f293d2605b87431e60:
    Amend MAPREDUCE-1532. Add more informative logging messages for configuration-authentication mismatch
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439248/1532-bp20.4.2.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8f3777a09e9cc3e260e68c1a177908204b0dad8c:
    MAPREDUCE-1417. Forrest documentation should be updated to reflect the changes in MAPREDUCE-744
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439247/MAPREDUCE-1417-20.patch
    Author: Ravi Gummadi
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit adbf650d942aff9d372289110672916fcb4574a7:
    HADOOP-6634. AccessControlList uses full-principal names to verify acls causing queue-acls to fail
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439238/HADOOP-6634-20100317-ydist.1.txt
    Author: Vinod K V
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 89e10647b3c733c16124b648a6bfe187670390da:
    HADOOP-6642. Fix javac, javadoc, findbugs warnings
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439225/C6642-1y20.patch
    Author: Chris Douglas
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5abf4f644d7fc869858f896708b49f211ddf17d4:
    HDFS-1044. Cannot submit mapreduce job from secure client to unsecure sever
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439220/HDFS-1044-BP20-6.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0f77b062de438f4d138da08d4028a7afe7a233bd:
    HADOOP-6638. Try to relogin in a case of  failed RPC connection (expired tgt) only in case the subject is loginUser or proxyUgi.realUser.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439080/HADOOP-6638-BP20.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cfbc26a6211204e5e87d9986019fc97110662127:
    HADOOP-6632. Support for using different Kerberos keys for different instances of Hadoop services
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439144/HADOOP-6632-Y20S-22.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12439307/6632.mr.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5b6834d2f255fec50d44ec50bec38b0004055c7d:
    HADOOP-6526. Need mapping from long principal names to local OS user names
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439139/HADOOP-6526-y20.4.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12442917/3595485.patch
    Author: Owen O'Malley
    Reason: Security
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 87c00a2594f42c8d96479ba339800e5224136902:
    MAPREDUCE-1604. Document Job ACLs in forrest
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439114/patch-1604-ydist.txt
    Author: Amareshwari Sriramadasu
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c69f8f7977591ac297cf5501374c4f40acfea7ee:
    HDFS-1045. In secure clusters, re-login is necessary for https clients before opening connections
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439110/HDFS-1045-Y20.patch
    Author: Jakob Homan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0f37bc72df436c30fbb3a1c826b2040f8118570b:
    HDFS-6603. Clarify a comment in SecurityUtil
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439078/fix_comment_y20.patch
    Author: Jakob Homan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b10afd0f9b75e7deb5045e19a9a954769c0925e6:
    HDFS-985. HDFS should issue multiple RPCs for listing a large directory
    
    Patch: http://issues.apache.org/jira/secure/attachment/12437088/iterativeLS_yahoo1.patc
    Patch: http://issues.apache.org/jira/secure/attachment/12437499/testFileStatus.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12439066/directoryBrowse_0.20yahoo_2.patch.
    Reason: Performance of large directory access
    Author: Hairong Kuang
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 353f15176ed481f268f37e33d4fc9f1745f44afe:
    MAPREDUCE-1543. Log messages of JobACLsManager should use security logging of HADOOP-6586
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439057/mapreduce-1543-y20s-3.patch
    Author: Luke Lu
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 02d4404d39e60322ea13a2ce0160635df4ef3155:
    MAPREDUCE-1606. TestJobACLs may timeout as there are no slots for launching JOB_CLEANUP task
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439054/MR1606.20S.1.patch
    Author: Ravi Gummadi
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit aa56ca096e5bba16a873600c57d29586896432ce:
    HADOOP-6633. Normalize property names for JT/NN kerberos principal names in configuration
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438949/HADOOP-6633-BP20-2.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ec983446e7a1600a95fcf60bd92205f5b9318d99:
    HADOOP-6613. RPC server should check for version mismatch before authentication method
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437831/HADOOP-6613-Y20S-1.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d8de7f9dbe8b94d380849f2f5f4ff357ce50e1a6:
    HADOOP-5592. Fix typo in streaming documentation
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436671/patch-5592-ydist.txt
    Author: Corinne Chandel
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3a91217a9802a4abe89a50dc0dcb8425cd42c060:
    MAPREDUCE-813. Address errors in streaming docs.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436672/patch-813-ydist.txt
    Author: Corinne Chandel
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d170cf2c73554beec3dbc43d79cd3d15f7b4d99c:
    MAPREDUCE-927. Cleanup of task-logs should happen in TaskTracker instead of the Child
    
    Patch: https://issues.apache.org/jira/secure/attachment/12439009/patch-927-5-dist.txt
    Author: Amareshwari Sriramadasu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2acd7103481363aeadb4593738cc8e6f8f11f483:
    HDFS-1039. Service should be set in the token in JspHelper.getUGI
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438896/HDFS-1039-y20.2.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12439603/HDFS-1039-y20.2.1.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d31d5e1b2eef3d92c60781087aba2857900d2273:
    MAPREDUCE-1599. MRBench reuses jobConf and credentials therein.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438844/MR-1599-y20.1.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f4ad3c7d410bfb5d86053fcbc91b4275fe0fd74c:
    HDFS-1036. in DelegationTokenFetch dfs.getURI returns no port
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438549/HDFS-1036-BP20.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12438585/HDFS-1036-BP20-1.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12438856/fetchdt_doc.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e4974cce6a221e1e4b8206145746e26c83fd9253:
    HDFS-1038. Fix bug causing NPE in nn_browsedfscontent.jsp when security is disabled
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438570/HDFS-1038-y20.1.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 596d28594c9bd32116c6510e6607308bc1a762e8:
    HADOOP-6627. "Bad Connection to FS" message in FSShell should print message from the exception
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438455/HADOOP-6627-BP20.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6d83d8407d13f0e4b8b26f74bfbbd592b4c906ee:
    HDFS-1033. In secure clusters, NN and SNN should verify that the remote principal during image and edits transfer
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438477/HDFS-1033-Y20.patch
    Author: Jakob Homan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3d43a9035ebaf0c449647c5f35fbd37444708d9f:
    MAPREDUCE-1522. FileInputFormat may change the file system of an input path
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437994/M1522-1v20.patch
    Author: Tsz Wo (Nicholas), SZE
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 897cd8d3d578c3cee70f039050f3cdd800daafb1:
    MAPREDUCE-1100. User's task-logs filling up local disks on the TaskTrackers
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438394/patch-1100-fix-ydist.2.txt
    Author: Vinod K V
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6cbba23fe597ada4f109fc92ecbffc3d01dcc8ac:
    MAPREDUCE-1422. Changing permissions of files/dirs under job-work-dir may be needed sothat cleaning up of job-dir in all mapred-local-directories succeeds always
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438393/mapreduce-1422-y20s.patch
    Author: Amar Kamat
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1cb57487f49bd7fd14c7575a1e8f5842b3f24e35:
    HDFS-992. Re-factor block access token implementation to conform to the generic Token interface in Common
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438371/h992-BK-0.20-07.1.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 543dcb4cdef6028146e5f8104123c8ac84e11e6b:
    MAPREDUCE-890. After HADOOP-4491, the user who started mapred system is not able to run job.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438369/MR890.20S.patch
    Author: Ravi Gummadi
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7b32dc80001de8b93c52041e15ab29bc52d5a68d:
    HADOOP-6598. Remove verbose logging from the Groups class
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438059/HADOOP-6598-BP20.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12438562/HADOOP-6598-BP20-Fix.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8c19066cdc5f6605e65d07127649a77309f2943a:
    HADOOP-6620. NPE if renewer is passed as null in getDelegationToken
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438072/HADOOP-6620-y20.1.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 447441ec4a592225dca7d3bf42a6c6c2f977b2dc:
    Amend MAPREDUCE-1435. symlinks in cwd of the task are not handled properly after MAPREDUCE-896
    
    Reason: fixes chmod during cleanup to not make private files group-readable, adds tests
    Patch: https://issues.apache.org/jira/secure/attachment/12438172/MR-1435-y20s-1.txt
    Author: Ravi Gummadi
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:21 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit eb5a68ab5a10bd85527cd4495a17687a826af698:
    HADOOP-6612. Protocols RefreshUserToGroupMappingsProtocol and RefreshAuthorizationPolicyProtocol will fail with security enabled
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437809/HADOOP-6612-BP20.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c62d6f0ed1c6d9e48db909acade2683830ebf37c:
    MAPREDUCE-1566. Mechanism to import tokens and secrets from a file in to the submitted job.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12438122/mr-1566-1.patch (bugfixes for testcases on top of the patch committed earlier)
    Patch: https://issues.apache.org/jira/secure/attachment/12438376/mr-1566-1.1.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1c42a6fc1ed560fd31c0622ecb272e48a56d70a1:
    HADOOP-6603. Provide workaround for issue with Kerberos not resolving cross-realm principal
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437826/HADOOP-6603-Y20S-4.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 072d68d2af1235eaacb49975f78d3457cec60938:
    MAPREDUCE-1421. LinuxTaskController tests failing on trunk after the commit of MAPREDUCE-1385
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437985/patch-1421-1-ydist.txt
    Author: Amareshwari Sriramadasu
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 69059680d9e0df4004ac7199c2c54ea658c35173:
    HDFS-814. Add an api to get the visible length of a DFSDataInputStream.
    
    Patch: http://issues.apache.org/jira/secure/attachment/12437934/getLength-yahoo-0.20.patch
    Patch: http://issues.apache.org/jira/secure/attachment/12438026/privateInputStream.patch
    Author: Tsz Wo (Nicholas), SZE
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e5a03085722a84a8ee0419ba8d91cd022023c0a0:
    HDFS-1023. Allow http server to start as regular principal if https principal not defined.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437962/HADOOP-1023-Y20-1.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12437962/HADOOP-1023-Y20-1.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12438241/HDFS-1023-Y20-Update-2.patch
    Author: Jakob Homan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5dcd47a711f530fb989350569dd5553b93e62490:
    HDFS-1015. Intermittent failure in TestSecurityTokenEditLog
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437830/HDFS-1015-y20.1.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 23cdcc2b187566333ae2201cd9706655f55ebf15:
    HDFS-1020. The canceller and renewer for delegation tokens should be long names.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437838/HDFS-1020-y20.2.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 522fd421225fbab7258a2977e4d40c0c13179376:
    HDFS-1019. Incorrect default values for delegation tokens in hdfs-default.xml
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437832/HDFS-1019-y20.1.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7187e0d7a8367e5e072b5e589db5becae0e6eb1d:
    Amend MAPREDUCE-1430. JobTracker should be able to renew delegation tokens for the jobs
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437822/1430-bp20-bugfix.patch
    Author: Devaraj Das
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 52f7ba19fcd24172f1576b7c19db1c45427fe85d:
    MAPREDUCE-1559. The DelegationTokenRenewal timer task should use the jobtracker's credentials to create the filesystem
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437821/mr-1559.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cab178d48ab27c74a44009b9d37e686580172794:
    MAPREDUCE-1550. UGI.doAs should not be used for getting the history file of jobs
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437835/1550-2.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12437870/1550-2.1.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4fd9491b5aeaea1f598f4314203aa5047576f137:
    HADOOP-6609. Fix UTF8 to use a thread local DataOutputBuffer instead of
    a static that was causing a deadlock in RPC. (omalley)
    
    Author: Owen O'Malley
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a4c9f34046770120a47ba864eaaaab0ecc952d86:
    HDFS-1017. browsedfs jsp should call JspHelper.getUGI rather than using createRemoteUser()
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437683/HDFS-1017-Y20-2.patch
    Author: Jakob Homan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5802343b91fc15ee719c2cffabf6a3f9f01f4007:
    MAPREDUCE-899. When using LinuxTaskController, localized files may become accessible to unintended users if permissions are misconfigured.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437670/mr-899-20.patch
    Author: Amareshwari Sriramadasu
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d763323e21122018c746515655c9fdff00547635:
    HDFS-204. Revive number of files listed metrics
    
    Patch: http://issues.apache.org/jira/secure/attachment/12437576/getFileNum-yahoo20.patch
    Author: Jitendra Nath Pandey
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ba0fc48b0d49ba1c03ef50ddb289580e61e0d689:
    HADOOP-6569. FsShell#cat should avoid calling unecessary getFileStatus before opening a file to read
    
    Patch: http://issues.apache.org/jira/secure/attachment/12437633/optimizeCat-yahoo2.patch
    Author: Hairong Kuang
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ebc7ac47eb93eeab3f8b8987ac74a56b0e40a982:
    HDFS-1014. Error in reading delegation tokens from edit logs.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437547/HDFS-1014-y20.1.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e5ec38e7ece3c2e9d7c64ae8bad4fe60e2a75088:
    HDFS-1006. getImage/putImage http requests should be https for the case of security enabled.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437467/HDFS-1006-Y20.1.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0c9d8c2dd9693f0a7317a139b5911a32c85aab61:
    HDFS-1005. Fsck security
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437435/HDFS-1005-BP20.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12438474/HDFS-1005-BP20-1.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5a1ea2b0a3050a0a8fdae64902067504d6f8c8eb:
    HDFS-1007. HFTP needs to be updated to use delegation tokens
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437458/distcp-hftp.2.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12437464/distcp-hftp.2.1.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12438384/distcp-hftp-2.1.1.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4bcd449f60c72fb3058a6b3ff1316b7bc10514e8:
    HDFS-992. Re-factor block access token implementation to conform to the generic Token interface in Common
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437340/h992-BK-0.20-07.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 039917c679539092585e96f590fae59052a3cae6:
    MAPREDUCE-1528. TokenStorage should not be static
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437339/MAPREDUCE-1528_yhadoop20.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:18 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 40c1a9177db24c0fd589ad8312a31a715f4cf8ad:
    HADOOP-6584. Provide Kerberized SSL encryption for webservices
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437337/HADOOP-6584-Y20-4.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12437337/HADOOP-6584-Y20-4.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12437768/HADOOP-6584-FixJavadoc-Y20.patch
    Author: Jakob Homan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:18 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ee57d93dde68a072985a44e025594bbb8c9340b0:
    MAPREDUCE-1493. Authorization for job-history pages
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437336/MAPREDUCE-1493-20100227.3-ydist.txt
    Author: Vinod K V
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:18 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e6e5a1bd6943f228f5271627a200350bff525cba:
    MAPREDUCE-1455. Authorization for servlets
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437322/1455.20S.2.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12437379/1455.20S.2.fix.patch
    Author: Ravi Gummadi
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:18 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3ad925fb44f4e98e986b5648e2c593d1feabafd4:
    MAPREDUCE-1307. Introduce the concept of Job Permissions
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437331/MAPREDUCE-1307-20100227-ydist.txt
    Author: Vinod K V
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:18 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 06b43c680556c94120774e2c22279086654f50ee:
    HADOOP-6568. Authorization for default servlets
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437323/HADOOP-6568-20100226.1-ydist.patch
    Author: Vinod K V
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:18 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cf43306ef9d6a7b1a3d3287a898c05cbd51361b6:
    HADOOP-6589. A framework to enable better error messages when rpc connections
    fail to authenticate. (Kan Zhang via omalley)
    
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:18 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ea1922be01c027410bdfdb3776b79cbb2328162d:
    HADOOP-6600. mechanism for authorization check for inter-server protocols
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437320/HADOOP-6600-4-BP20.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12437534/HADOOP-6600-BP20-fix.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:18 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 877787c7557f3c2bb824f526d5b036c734bfc5e1:
    HADOOP-6580,HDFS-993,MR-1516. UGI should contain authentication method.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437317/HADOOP-6580-0_20.5.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2a717fe40d0a2514647f25457e6a8f344dff7941:
    HADOOP-6573, HDFS-984, MR-1537. Delegation Tokens should be persisted.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437292/HDFS-984-0_20.4.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5ba4559365dec19e119d041ddf7f6f65b7fc0c56:
    HDFS-994, HADOOP-6594. Provide methods for obtaining delegation token from Namenode for hftp and other uses
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436748/HADOOP-6594.patch
    Author: Jakob Homan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c697b870f3d87e17438115a037e9fd831e757e3f:
    HADOOP-6586. Log authentication and authorization failures and successes
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437302/HADOOP-6586-8-BP20-1.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ac2d2869ecccd91fdacab7544eca00767f8d64a1:
    HDFS-991. Use delegation token to authenticate to the hdfs servlets.
    
    Author: Owen O'Malley
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8b1175a8139fc28041c67f095212d7224ac44b2e:
    HADOOP-6599. Split RPC metrics into summary and detailed metrics
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437251/hadoop-6599.rel20.patch
    Author: Suresh Srinivas
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 12f51ccde0651d7ed7e2458dfd498f0b8856d70a:
    HDFS-998. The servlets should quote server generated strings sent in the response
    
    Patch: http://issues.apache.org/jira/secure/attachment/12436835/H998-0y20.patch
    Author: Chris Douglas
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0d1bfe678e356b154d237e34d4e4379a84614158:
    MAPREDUCE-1454. The servlets should quote server generated strings sent in the response
    
    Patch: http://issues.apache.org/jira/secure/attachment/12436834/M1454-0y20.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12437591/M1454-1y20.patch
    Author: Chris Douglas
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 36710ad2bc76df6df01ef540df21fedb9b702160:
    HDFS-1000. libhdfs needs to be updated to use the new UGI
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437071/hdfs-1000-bp20.4.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a9847d0ea9f695dca2d3dca6e81a8cd1f29665fc:
    MAPREDUCE-1532. Delegation token is obtained as the superuser
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437096/1532-bp20.4.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c44edf05330198b89ec994b2543e1fe459dd30bd:
    MAPREDUCE-1430. JobTracker should be able to renew delegation tokens for the jobs
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436542/1430-dd4-BP20.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:16 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6e62f0d9c2d57096e4dfa937ebeab8c76b354e63:
    HADOOP-6596. Add a version field to the serialization of the AbstractDelegationTokenIdentifier.
    
    Author: Owen O'Malley
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:16 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 74cc8e6e9836a9daab24553b41efca110f50411a:
    HADOOP-5561. Add javadoc.maxmemory to build.xml to allow larger memory.
    
    Author: Jakob Homan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:16 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 03e35485989da9f5d60dacdcfc67e8566b8590f8:
    HADOOP-6579. Add a mechanism for encoding and decoding Tokens in to
    url-safe strings. Also change commons-codec library to 1.4.
    
    Author: Owen O'Malley
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:16 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a04e3abfd58010fd99877910c0f15bbbebb1b45a:
    MAPREDUCE-1354. Incremental enhancements to the JobTracker for better scalability
    
    Patch: https://issues.apache.org/jira/secure/attachment/12437010/mr-1354-y20.patch
    Author: Dick King
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:16 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 69ec78a2c5d4faa8700cf45f7560fe1d10517ddf:
    HDFS-999. Secondary namenode should login using kerberos if security is configured
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436938/HDFS-999-BP20.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:16 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ac14a11d60fcbd9cc660fc8b48a894cd6774b102:
    MAPREDUCE-1466. FileInputFormat should save #input-files in JobConf
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436886/MAPREDUCE-1466_yhadoop20-3.patch
    Author: Luke Lu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:16 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 50ddfaab96c196a2342e7807423d31f5bd10a18e:
    MAPREDUCE-1403. Save file-sizes of each of the artifacts in DistributedCache in the JobConf
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436842/MAPREDUCE-1403_yhadoop20-2.patch
    Author: Arun C Murthy
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:16 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 645b54a053bf565ef2a0f36be8c5a02f80a2775a:
    HADOOP-6566. Hadoop daemons should not start up if the ownership/permissions on the directories used at runtime are misconfigured
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436814/HADOOP-6566_yhadoop20.patch
    Author: Arun C Murthy
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:16 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2943513d74b4a8c1763eccab854b96a57caec7f4:
    MAPREDUCE-1520. TestMiniMRLocalFS fails on trunk
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436695/patch-1520-20S.txt
    Author: Amareshwari Sriramadasu
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:16 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e82c781785f284d926591a91df837021f5c68fcc:
    HADOOP-6543. Allow authentication-enabled RPC clients to connect to authentication-disabled RPC servers
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436797/6543-bp20.0.patch.
    Patch: https://issues.apache.org/jira/secure/attachment/12436807/6543-bp20.1.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 48788d6ab1852ee1f47b56ee6f097022c30ec409:
    MAPREDUCE-1505. Cluster class should create the rpc client only when needed
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436628/MAPREDUCE-1505_yhadoop20.patch
    Author: Dick King
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8a4f25cf0d3631d190ecfa81e17a80bfbb019c69:
    HADOOP-6549. TestDoAsEffectiveUser should use ip address of the host for superuser ip check
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436794/HADOOP-6549-0_20.1.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7bc77f6677512242d19b75c643f21a457087d29a:
    HDFS-786. Implement getContentSummary(..) in HftpFileSystem
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436792/h786_20100223_0.20.patch
    Author: Tsz Wo (Nicholas), SZE
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ff8f5ea311eb73564805f083a379147fd5aa6d47:
    HDFS-946. NameNode should not return full path name when lisitng a directory or getting the status of a file
    
    Patch: http://issues.apache.org/jira/secure/attachment/12436753/HdfsFileStatus-yahoo20.patch.
    Patch: http://issues.apache.org/jira/secure/attachment/12436769/HdfsFileStatusProxy-Yahoo20.patch
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a3fe5640d9cdab14cc7080093b2dbb7933d640d9:
    MAPREDUCE-1398. TaskLauncher remains stuck on tasks waiting for free nodes even if task is killed.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436724/mr-1398-y20.patch
    Author: Amareshwari Sriramadasu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ab177895085d9b5fcfcb1fc695bbd94b753b9160:
    MAPREDUCE-1476. committer.needsTaskCommit should not be called for a task cleanup attempt
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436722/mr-1476-y20.patch
    Author: Amareshwari Sriramadasu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit eb3c54506da655c486c06560877a2e30dd3aec3f:
    HADOOP-6467. Performance improvement for liststatus on directories in hadoop archives.
    
    Patch: http://issues.apache.org/jira/secure/attachment/12436653/HADOOP-6467-y.0.20-branch-v2.patch
    Author: Mahadev konar
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1ee8f38881d450a818754c889038ef2ea8de865d:
    HADOOP-6558. archive does not work with distcp -update
    
    Patch: http://issues.apache.org/jira/secure/attachment/12436264/c6558_20100216b_y0.20.patch
    Author: Tsz Wo (Nicholas), SZE
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5792ec1c6229c000b34fd2cb1f3447ae71ad9949:
    HADOOP-6583. Capture metrics for authentication/authorization at the RPC layer
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436643/6583-bp20.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f370a6f8f27d6bc813872a89d9dac122dd357b53:
    HADOOP-6577. IPC server response buffer reset threshold should be configurable
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436399/hadoop-6577.2.rel20.patch) from yahoo-hadoop-0.20 into yahoo-hadoop-0.20.1xx
    Author: Suresh Srinivas
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 364fd3118df3fb08ec239306fcc3b1762cb803d0:
    MAPREDUCE-1316. JobTracker holds stale references to retired jobs via unreported tasks
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436563/mapreduce-1316-y20s.patch
    Author: Amar Kamat
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2471700c34dece87f611cceaf5b961647ab58700:
    HADOOP-6551, HDFS-986, MAPREDUCE-1503. Change API for tokens to throw
    exceptions instead of returning booleans.
    
    Author: Owen O'Malley
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5838b15e3232608c1358887b8910638b1497043f:
    HADOOP-6572. RPC responses may be out-of-order with respect to SASL
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436421/6572-bp20.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4719ab45ca9a8ae6d8289dddc024854683726b19:
    HDFS-965. Split the HDFS TestDelegationToken into two tests, of which
    one proxy users and the other normal users. (jitendra via omalley)
    
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a0380f3cae542769bd6861311d0fc709201e9dc3:
    HADOOP-6332, HDFS-1134, MAPREDUCE-1774. Herriot (system test framework)
    
    Author: Konstantin Boudnik
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 205a6b6697f7a8934f684e08c187682d0f1d3b2d:
    HADOOP-6560. HarFileSystem throws NPE for har://hdfs-/foo
    
    Patch: http://issues.apache.org/jira/secure/attachment/12436045/c6560_20100212_y0.20.patch
    Author: Tsz Wo (Nicholas), SZE
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f33ae6567528673de4c4b0de8f40cf2c9ff5741c:
    MAPREDUCE-686. Move TestSpeculativeExecution.Fake* into a separate class so that it can be used by other tests also
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436181/MAPREDUCE-686-y20.patch
    Author: Jothi Padmanabhan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit dd2ce99bb706ba8e7771b3382de7af687ae8467f:
    HDFS-111. UnderReplicationBlocks should use generic types
    
    Patch: https://issues.apache.org/jira/secure/attachment/12436027/1026-bp20-bugfix.patch
    Author: Devaraj Das
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 67e25d271e93cc035ed664f9bfa16705f6a45958:
    HADOOP-6559. The RPC client should try to re-login when it detects that the TGT expired
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435851/h-6559.6.bp20.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 176816d52d875d33877baba51294de5b1868d3aa:
    HADOOP-2141. speculative execution start up condition based on completion time
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435253/hadoop-2141-yahoo-v1.4.8.patch (only test related changes)
    Author: Andy Konwinski
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cd035a28f73f373b695b3704243d013508036346:
    MAPREDUCE-1425. archive throws OutOfMemoryError
    
    Patch: http://issues.apache.org/jira/secure/attachment/12435030/MAPREDUCE-1425_y_0.20.patch
    Author: Mahadev konar
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:13 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7260de34b087c442e5054410e038f7bc2214e077:
    MAPREDUCE-1399. The archive command shows a null error message
    
    Patch: http://issues.apache.org/jira/secure/attachment/12435380/m1399_20100205trunk2_y0.20.patch
    Author: Tsz Wo (Nicholas), SZE
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:13 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a60877ba994c36b0d81f7d1c47a81b1111906bd2:
    HADOOP-6552. KEYTAB_KERBEROS_OPTIONS in UserGroupInformation should have options for automatic renewal of keytab based tickets
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435369/6552.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:13 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b96008a997c4cf52f01a32daa103244a27190639:
    MAPREDUCE-1433. Create a Delegation token for MapReduce
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435412/1433.bp20.patch
    Author: Owen O'Malley
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:13 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 29b6749dfdd9038d9f54ef9f0669c5b1fc553463:
    HADOOP-6547, HDFS-949, MAPREDUCE-1470. Move the Delegation Token feature to common since both HDFS and MapReduce needs it
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435271/6547-949-1470-0_20.1.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:13 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 542f37d8c93b1cae42aec29789068d27bc2330fb:
    HADOOP-5879. GzipCodec should read compression level etc from configuration
    
    Patch: http://issues.apache.org/jira/secure/attachment/12435254/hadoop-5879-yahoo-0.20-v1.0.patch
    Author: He Yongqiang
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:13 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7d2d3c129e0c1358e490d09744ce1b448e430beb:
    HADOOP-6161. Add get/setEnum to Configuration
    
    Patch: http://issues.apache.org/jira/secure/attachment/12434928/hadoop-6161-yahoo-20-v1.patch
    Author: Chris Douglas
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:13 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ed87d9db29b9375d2c10047bbc3e7d136c76a581:
    HADOOP-6510, HDFS-935, MAPREDUCE-1464. Add support for a superuser authenticating on behalf of a proxy user.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435223/HADOOP-6510-0_20.4.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:13 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit df2da5d463d6a2b09f11c44d1eebbf85fa73ce81:
    MAPREDUCE-1435. symlinks in cwd of the task are not handled properly after MAPREDUCE-896
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435154/MR-1435-y20s.patch
    Author: Ravi Gummadi
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:13 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4fe06f63ca10d7cc5949615d2d41261782156653:
    MAPREDUCE-1457. For secure job execution, couple of more UserGroupInformation.doAs needs to be added
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435115/MAPREDUCE-1457-BPY20.patch.1
    Author: Jakob Homan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:13 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6b874f7d11e11f14450e882b670180daef48a76e:
    MAPREDUCE-1440. MapReduce should use the short form of the user names
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435087/1440.y20.patch
    Author: Owen O'Malley
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b14b570878b9262f1a77c668b5123345406f8374:
    HDFS-737. Improvement in metasave output
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435041/HDFS-737.3.rel20.patch
    Author: Jitendra Nath Pandey
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5141b5979120da19551385ff1ce13b545266b204:
    HADOOP-6419. Change RPC layer to support SASL based mutual authentication
    
    Patch: https://issues.apache.org/jira/secure/attachment/12434998/HADOOP-6419-0.20-15.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12435135/6419-bp20-jobsubmitprotocol.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d1f946ae7bfd5e619e8167ebad228be72668b0a9:
    HADOOP-6538. Set hadoop.security.authentication to "simple" by default
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435031/6538-bp20.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d012efa36429328941a04742bd6febd35d3875ef:
    HDFS-938. Replace calls to UGI.getUserName() with UGI.getShortUserName()
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435015/HDFS-938-BP20-2.patch
    Author: Jakob Homan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4f96064bf4bb838ce0c6d4e99152a02ad9737032:
    HADOOP-6521. FsPermission:SetUMask not updated to use new-style umask setting.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12434469/hadoop-6521.rel20.1.patch
    Author: Suresh Srinivas
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ee18c74b284b015975b0df13c750e135ff938fbe:
    HADOOP-6544. fix ivy settings to include JSON jackson.codehause.org libs for .20
    
    Patch: https://issues.apache.org/jira/secure/attachment/12435002/contrib.ivy.jackson.patch-3
    Author: Boris Shkolnik
    Reason: contrib build breaks because ivy is not configured to include jackson libs.
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 18b89be19183117cbe0a567ecb16e8012bc83c48:
    HDFS-907. Add tests for getBlockLocations and totalLoad metrics.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12434919/HDFS907s.patch
    Author: Ravi Phulari
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 77510480a8b45b2f9e605b720671d609d7bf4687:
    HADOOP-6204. Implementing aspects development and fault injection framework for Hadoop
    
    Patch: https://issues.apache.org/jira/secure/attachment/12434616/HADOOP-6204-ydist.patch
    Author: Konstantin Boudnik
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:12 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 993bc455b265d185f74c23ec7ccb272203190298:
    MAPREDUCE-1432. Add the hooks in JobTracker and TaskTracker to load tokens from the token cache into the user's UGI
    
    Patch: https://issues.apache.org/jira/secure/attachment/12434550/MAPREDUCE-1432-BP20-2.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 32957687aa59ef0d515682d87e521d8aba244e3b:
    MAPREDUCE-1383. Allow storage and caching of delegation token.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12434455/MAPREDUCE-1383-BP20-7.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ce7c3dc280b3d3ba0b176f0b7a9dc09d5ca163f5:
    HADOOP-6337. Update FilterInitializer class to be more visible and take a conf for further development
    
    Patch: https://issues.apache.org/jira/secure/attachment/12434503/HADOOP-6337-Y.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12434547/HADOOP-6337-Y.patch
    Author: Jakob Homan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6fa12363baff6e2e11650c0f395b52e9f47d6266:
    HADOOP-6520. UGI should load tokens from the environment
    
    Patch: https://issues.apache.org/jira/secure/attachment/12434423/HADOOP-6520-0_20.2.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 256f62f67d848260f25fca2e052fd878b93bfe17:
    HADOOP-6517, HADOOP-6518. Ability to add/get tokens from UserGroupInformation
    
    Patch: https://issues.apache.org/jira/secure/attachment/12434368/HADOOP-6518-0_20.1.patch
    Author: Owen O'Malley
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 34c6a146be045127f5e43828fd3c578ebb3c113c:
    MAPREDUCE-1376. Support for varied user submission in Gridmix
    
    Patch: https://issues.apache.org/jira/secure/attachment/12431174/M1376-4.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12440324/1376-5-yhadoop20-100.patch
    Author: Chris Douglas
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e02e4b0320d45fe401470e72d62b73d18a3dd579:
    HADOOP-6299. Use JAAS LoginContext for our login
    
    Patch: https://issues.apache.org/jira/secure/attachment/12434362/HADOOP-6299-Y20.patch
    Author: Owen O'Malley
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e1ab72fadf1fc48bb21a44c62edd39b3883a392a:
    Amend MAPREDUCE-842. Per-job local data on the TaskTracker node should have right access-control
    
    Reason: follow-up patch to fix a backport bug
    Patch: https://issues.apache.org/jira/secure/attachment/12431690/MR-842-follow-up.patch
    Author: Vinod K V
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:10 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 662c95fb0e8b2aaefb64362119aef66a04268eb1:
    MAPREDUCE-1186. While localizing a DistributedCache file, TT sets permissions recursively on the whole base-dir
    
    Patch: https://issues.apache.org/jira/secure/attachment/12431573/1186.20S-6.patch
    Author: Amareshwari Sriramadasu
    Reason: performance
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:10 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 137e608a13a26b47883cea6d03a48974b2f16c68:
    HDFS-899. Delegation Token Implementation
    
    Patch: https://issues.apache.org/jira/secure/attachment/12431529/HDFS-899-0_20.2.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:10 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit db6344ec8a93fb65830f7902e6566a96619ff7dd:
    MAPREDUCE-896. Users can set non-writable permissions on temporary files for TT and can abuse disk usage.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12431413/MR-896.v8-y20.patch
    Author: Ravi Gummadi
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:10 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2aff67e0291b9641d2e17a7288faa694efe16976:
    MAPREDUCE-744. Support in DistributedCache to share cache files with other users after HADOOP-4493
    
    Patch: https://issues.apache.org/jira/secure/attachment/12431313/744-6-y20.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:10 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d1b26621983f80167bf3af5b38ae48467c739f14:
    MAPREDUCE-1140. Per cache-file refcount can become negative when tasks release distributed-cache files
    
    Patch: https://issues.apache.org/jira/secure/attachment/12431213/patch-1140-3-y20.txt
    Author: Amareshwari Sriramadasu
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:10 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6804e20bd4d9ee5e0005b61d202ce7dd928b5b22:
    MAPREDUCE-1284. TestLocalizationWithLinuxTaskController fails
    
    Patch: https://issues.apache.org/jira/secure/attachment/12427577/MR-1284.patch
    Author: Ravi Gummadi
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:10 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9e3f0d458c0ac31bad77cc336b6fdf0206fbe0d6:
    MAPREDUCE-1098. Incorrect synchronization in DistributedCache causes TaskTrackers to freeze up during localization of Cache for tasks.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12431207/patch-1098-7-y20.txt
    Author: Amareshwari Sriramadasu
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:10 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d3131417c36e68cb59ad0833d271d10bd869b27c:
    MAPREDUCE-1338. Add ability to store and load security keys
    
    Patch: https://issues.apache.org/jira/secure/attachment/12431172/MAPREDUCE-1338-BP20-3.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:10 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 478ebff927c0a45f72c531952bcaf7632e990a12:
    HADOOP-6495. Identifier should be serialized after the password is created In Token constructor
    
    Patch: https://issues.apache.org/jira/secure/attachment/12431145/HADOOP-6495-0_20.2.patch
    Author: Jitendra Nath Pandey
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ef9e572a545e56b790000f16bf6d416b63083520:
    HADOOP-5457. Failing contrib tests should not stop the rest of the contrib tests
    
    Patch: https://issues.apache.org/jira/secure/attachment/12431103/Hadoop-5457-y20.patch
    Author: Giridharan Kesavan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6b6fdbe4b79d6e623fdbcc60f052749cf99b0c32:
    Amend HADOOP-4181. Add support for git revision in saveVersion.sh
    
    Author: Owen O'Malley
    Reason: Support git revisions without explicitly passing them in
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 71d9e9a5b3577937fe06b40cebc6656419324323:
    MAPREDUCE-856. Localized files from DistributedCache should have right access-control
    
    Patch: https://issues.apache.org/jira/secure/attachment/12431040/MAPREDUCE-856-20090908-y20.txt
    Author: Vinod K V
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c0826b2e0c43581aa90afff465ddd7401e12b1ee:
    MAPREDUCE-871. Job/Task local files have incorrect group ownership set by LinuxTaskController binary
    
    Patch: https://issues.apache.org/jira/secure/attachment/12430867/871.20S.patch
    Author: Vinod K V
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3ca7d8529bcb3cea9640dffaa296c508a07f89a4:
    MAPREDUCE-476. Extend DistributedCache to work locally (LocalJobRunner)
    
    Patch: https://issues.apache.org/jira/secure/attachment/12430866/476.20S-2.patch
    Author: Philip Zeyliger
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5d79da536f9811f47af0e073aa68ca776c24b0da:
    MAPREDUCE-711. Move Distributed Cache from Common to Map/Reduce
    
    Patch: https://issues.apache.org/jira/secure/attachment/12430713/711.20S.patch
    Author: Vinod K V
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit be2df477d6dc267f4a4b7c6602c8108ece1cb783:
    MAPREDUCE-478. separate jvm param for mapper and reducer
    
    Patch: https://issues.apache.org/jira/secure/attachment/12430705/478.20S-1.patch
    Author: Arun C Murthy
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 44df01f8009c02e7346b69389ee8a26ef824bba2:
    MAPREDUCE-842. Per-job local data on the TaskTracker node should have right access-control
    
    Patch: https://issues.apache.org/jira/secure/attachment/12430697/842.20S-4.patch
    Author: Vinod K V
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3b9ed4395593a6f67897126126e7c4c74a35c42c:
    MAPREDUCE-408. TestKillSubProcesses fails with assertion failure sometimes
    
    Patch: https://issues.apache.org/jira/secure/attachment/12430404/MR-408.v1.1.y20.patch
    Author: Ravi Gummadi
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:08 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit fc472723ed6f5ca78abd4bfca56584489c485ee1:
    HADOOP-4041. IsolationRunner does not work as documented
    
    Patch: https://issues.apache.org/jira/secure/attachment/12430398/HADOOP-4041-v4-y20.patch
    Author: Philip Zeyliger
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:08 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c759d3e421565c13c79d6091d1917ce57cbb6636:
    MAPREDUCE-1316. Fix jobs' retirement from the JobTracker to prevent memory leaks via stale references.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12430197/mapreduce-1316-v1.15-branch20-yahoo.patch
    Author: Amar Kamat
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:08 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 10024643cacf3d40faa870505c83dd344f8ff366:
    MAPREDUCE-1342. Fixed deadlock in global blacklisting of tasktrackers.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12430116/patch-1342-3-ydist.txt
    Author: Amareshwari Sriramadasu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:08 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 675d02da77a6db7b98e8a30afda2926fe768fe3e:
    MAPREDUCE-181. Secure job submission
    
    Patch: https://issues.apache.org/jira/secure/attachment/12430064/181.20.s.3.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12436083/jobclient.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12440358/181.20.s.3.fix.patch
    Author: Devaraj Das
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:08 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit fda013b025b050107afd17120270ec6e5cb99138:
    HADOOP-5737. UGI checks in testcases are broken
    
    Patch: https://issues.apache.org/jira/secure/attachment/12430029/HADOOP-5737-y20.patch
    Author: Amar Kamat
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:08 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 829bb385ecbde947eeacff39ea2f3f3af703fdbe:
    HADOOP-5771. Create unit test for LinuxTaskController
    
    Patch: https://issues.apache.org/jira/secure/attachment/12429998/5771.20S.patch
    Author: Sreekanth Ramakrishnan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:08 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0045482b56026f2858bdd983d09ab2a38e06bfa8:
    HADOOP-4656, HDFS-685, MAPREDUCE-1083. Add a user to groups mapping service
    
    Patch: https://issues.apache.org/jira/secure/attachment/12429805/MR-1083-0_20.2.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:08 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bff776eae3e576e29b3f48546d620469c7a65a6f:
    MAPREDUCE-1250. Refactor job token to use a common token interface
    
    Patch: https://issues.apache.org/jira/secure/attachment/12429629/MR-1250-0_20.2.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:07 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f9bf7f1aa9a663f09e3377671722e4bce0fa5f20:
    MAPREDUCE-1026. Shuffle should be secure
    
    Patch: https://issues.apache.org/jira/secure/attachment/12429584/MR-1026-0_20.2.patch
    Author: Boris Shkolnik
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:07 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8761586736722c1c6f2eb3c7ad7d1842383431b6:
    HADOOP-4268. Permission checking in fsck
    
    Patch: https://issues.apache.org/jira/secure/attachment/12428975/HADOOP-4268-0_20.2.patch
    Author: Tsz Wo (Nicholas), SZE
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:07 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ac18b1312c05f9d85b23686807c9b0120f99eac0:
    HADOOP-6415. Adding a common token interface for both job token and delegation token
    
    Patch: https://issues.apache.org/jira/secure/attachment/12429399/HADOOP-6415-0_20.2.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:07 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit dca4c3a73ff34fb37ff2b92c7d6ba2331cd1405d:
    HDFS-764 and HADOOP-6367. Moving Access Token implementation from Common to HDFS
    
    Patch: https://issues.apache.org/jira/secure/attachment/12428959/HADOOP-6367_HDFS-764-0_20.1.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:07 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6205b10e6bbd702cab014af83061791b35a2248a:
    HDFS-409. Add more access token tests
    
    Patch: https://issues.apache.org/jira/secure/attachment/12428924/HDFS-409-0_20.4.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:07 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c1c67ca1ab0d958c2258c8c1571adb89996f684a:
    HADOOP-6132. RPC client opens an extra connection for VersionedProtocol
    
    Patch: https://issues.apache.org/jira/secure/attachment/12428925/HADOOP-6132-0_20.1.patch
    Author: Kan Zhang
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:07 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 07ba75bcabd5beeecd41c0c9f54b850304ad9225:
    Amend HDFS-445. Bring DFSClient block caching code more up to date with trunk
    
    Patch: https://issues.apache.org/jira/secure/attachment/12428885/HDFS-445-0_20.2.patch
    Author: Kan Zhang
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:07 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ad1f19c5727c6457a4e37c26cc1ede0dae3b76ec:
    HDFS-195. Need to handle access token expiration when re-establishing the pipeline for dfs write
    
    Patch: https://issues.apache.org/jira/secure/attachment/12428788/HDFS-195-0_20.1.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:06 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 53782d128507af30429e8c697788aa14fa9849c8:
    HADOOP-6176. Adding a couple private methods to AccessTokenHandler for testing purposes
    
    Patch: https://issues.apache.org/jira/secure/attachment/12428771/HADOOP-6176-0_20.2.patch.
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:06 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 97b3aed79705201bfe0bea392ca19e3fc96cd81e:
    HADOOP-5824. Remove unused OP_READ_METADATA functionality from Datanode
    
    Patch: https://issues.apache.org/jira/secure/attachment/12428759/HADOOP-5824-0_20.1.patch
    Author: Kan Zhang
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:06 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 459d8d98b1ad0675b0e1525dfa23e445e1f82453:
    HADOOP-4359. Access Token: Support for data access authorization checking on DataNodes
    
    Patch: https://issues.apache.org/jira/secure/attachment/12428711/HADOOP-4359-0_20.2.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12435352/4359.patch
    Author: Kan Zhang
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:06 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b76311584ce48bdc06c6c1103e45cbc2e2cc9112:
    MAPREDUCE-1100. Truncate user logs to prevent TaskTrackers' disks from filling up.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12428200/MAPREDUCE-1100-20091216.2.txt
    Author: Vinod K V
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:06 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 444beac7f8610cd3ec9433c8fe5e006462a2d07c:
    HADOOP-6441. Prevent remote XSS attacks in Hostname and UTF-7.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12428133/h-6441.20.patch
    Author: Owen O'Malley
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:06 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 18ec4a074b50ad5a7d8b3148da40d58ed0baf768:
    MAPREDUCE-1063. Document Gridmix benchmark
    
    Patch: https://issues.apache.org/jira/secure/attachment/12427976/M1063-y20-0.patch
    Author: Chris Douglas
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:06 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2b04facf5a226b592874137356929aca62320648:
    MAPREDUCE-1124. TestGridmixSubmission fails sometimes
    
    Patch: https://issues.apache.org/jira/secure/attachment/12427971/M1124-y20-1.patch
    Author: Chris Douglas
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:06 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4e30197fdddc64b48c0a3fb4575cdea4e5eaaf9b:
    MAPREDUCE-1143. runningMapTasks counter is not properly decremented in case of failed Tasks.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12427898/MAPRED-1143-ydist-9.patch
    Author: rahul k singh
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:06 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e3a25294b2faf7d57fbf69b75060611362a35463:
    MAPREDUCE-676. Fix Hadoop Vaidya to ensure it works for map-only jobs.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12410257/vaidya-patch-06092009.patch
    Author: Suhas Gogate
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:06 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 600a35b4e22088859c7b12ece7fa67dbfe489c2b:
    HADOOP-5582. Fix Hadoop Vaidya to use new Counters in org.apache.hadoop.mapreduce package. Contributed by Suhas Gogate.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12407120/vaidya-0.21.0-5582-5764.patch
    Author: Suhas Gogate
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:05 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4ba755db0d9eae199355905193c424d1a8a78dae:
    HDFS-595. FsPermission tests need to be updated for new octal configuration parameter from HADOOP-6234
    
    Patch: https://issues.apache.org/jira/secure/attachment/12427977/HDFS-595-Y20.patch
    Author: Jakob Homan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:05 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0dbd09e5e1a6f3eaa76ad7a54815d03707da5a27:
    MAPREDUCE-1171. Allow the read-error notification in shuffle to be configurable.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12427571/patch-1171-1-ydist.txt
    Author: Amareshwari Sriramadasu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:05 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 29334f33eee06ef864f1fed490da870050e5c7ff:
    MAPREDUCE-353. Allow shuffle read and connection timeouts to be configurable.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12427566/patch-353-ydist.txt
    Author: Ravi Gummadi
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:05 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a529046a05bfd89965d08b1ec6d80c1a777a8136:
    MAPREDUCE-754. NPE in expiry thread when a TT is lost
    
    Patch: https://issues.apache.org/jira/secure/attachment/12427347/mapreduce-754-v2.2.1-yahoo.patch
    Author: Amar Kamat
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:05 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 96ee0a0a723e65ca3dbcbbdaece44e3a752256f0:
    MAPREDUCE-1185. URL to JT webconsole for running job and job history should be the same
    
    Patch: https://issues.apache.org/jira/secure/attachment/12426630/patch-1185-3-ydist.txt
    Author: Amareshwari Sriramadasu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:05 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 578be5dcfdece1f48aae8809648ae00f646bb040:
    HDFS-781. Metrics PendingDeletionBlocks is not decremented
    
    Patch: https://issues.apache.org/jira/secure/attachment/12426993/hdfs-781.rel20.1.patch.
    Author: Suresh Srinivas
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:05 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b350799d72e4a4bec1f76527eb8fe02590295785:
    HADOOP-4933. ConcurrentModificationException in JobHistory.java
    
    Patch: http://issues.apache.org/jira/secure/attachment/12397116/HADOOP-4933-v1.1.patch
    Author: Amar Kamat
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:05 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9fa324d4ff152e41e2afada5990d26b0ba296e17:
    MAPREDUCE-1231. Allow distcp checksumming to be skipped for faster startup time
    
    Patch: https://issues.apache.org/jira/secure/attachment/12426265/mapred-1231-y20-v4.patch
    Author: Jothi Padmanabhan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:05 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit becc6bade8b0d4ef4248cd82da7e7d337bc10cbc:
    HDFS-758. Changes to report decommissioning status on namenode web UI.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12426000/HDFS-758.5.0-20.patch
    Author: Jitendra Nath Pandey
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:05 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9d9e86678faa54e23c3ac41c1b8fdb6b379e9b5d:
    HADOOP-6234. Permission configuration files should use octal and symbolic
    
    Patch: https://issues.apache.org/jira/secure/attachment/12425635/COMMON-6234.rel20.1.patch
    Author: Jakob Homan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:05 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c446d2df912c744705ecc72bf98f424973eb0817:
    MAPREDUCE-1219. Fixed JobTracker to not collect per-job metrics, thus easing load on it.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12425302/patch-1219-ydist.txt
    Author: Amareshwari Sriramadasu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f6b78b61fda941b83973de1dceebf0549c9eaca9:
    HADOOP-6203. Improve error message when moving to trash fails due to quota issue
    
    Patch: https://issues.apache.org/jira/secure/attachment/12425243/c6203_20091116_0.20.patch
    Author: Boris Shkolnik
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ec1f09b887a729a7682047248c624a42584d7233:
    HADOOP-5675. DistCp should not launch a job if it is not necessary
    
    Patch: https://issues.apache.org/jira/secure/attachment/12406687/5675_20090428.patch
    Author: Tsz Wo (Nicholas), SZE
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f7e4f728e818e137066caaa1f0a277a5485a5080:
    MAPREDUCE-1196. MAPREDUCE-947 incompatibly changed FileOutputCommitter
    
    Patch: https://issues.apache.org/jira/secure/attachment/12424351/MAPREDUCE-1196_yhadoop20.patch
    Author: Arun C Murthy
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 03a613af4dafb3212cf52833898f00c2b1f6195d:
    HDFS-625. ListPathsServlet throws NullPointerException
    
    Patch: https://issues.apache.org/jira/secure/attachment/12424176/hdfs-625.0-20.patch
    Author: Suresh Srinivas
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6c2dc76b06cb9967d89e6ab94465e0668b921dfa:
    HADOOP-6343. Stack trace of any runtime exceptions should be recorded in the server logs.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12424150/HADOOP-6343.0-20.patch
    Author: Jitendra Nath Pandey
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3bd620eff0f312008d11e29dffea2fa62457a630:
    HADOOP-6344. rm and rmr fail to correctly move the user's files to the trash prior to deleting when they are over quota.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12423634/HDFS-740-for-Y20.patch
    Author: Jakob Homan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ef18bb354fc9cd2b0f99bc141e094d328f4f1f14:
    MAPREDUCE-1160. Two log statements at INFO level fill up jobtracker logs
    
    Patch: https://issues.apache.org/jira/secure/attachment/12423534/MAPREDUCE-1160-20.patch
    Author: Ravi Gummadi
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 93ea3b6b97dd23cc0a69eacd2438f11e8a64be54:
    MAPREDUCE-1158. running_maps metric is not decremented when the tasks of a job is killed/failed
    
    Patch: https://issues.apache.org/jira/secure/attachment/12423451/1158_yahoo.patch
    Author: Sharad Agarwal
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5165b65008a62a834903f46db18b991dfe2aeacf:
    MAPREDUCE-1062. MRReliability test does not work with retired jobs
    
    Patch: https://issues.apache.org/jira/secure/attachment/12422201/mapreduce-1062-3-ydist.patch
    Author: Sreekanth Ramakrishnan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6ae254e4aef44f833859bb060797bd3177085d4e:
    MAPREDUCE-1090. Modify log statement in Tasktracker log related to memory monitoring to include attempt id.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12423142/MAPREDUCE-1090-20.patch
    Author: Hemanth Yamijala
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 07d06691d3d22dc7055568b8ca574ff264faf6ac:
    MAPREDUCE-1048. Show total slot usage in cluster summary on jobtracker webui
    
    Patch: http://issues.apache.org/jira/secure/attachment/12423136/MAPREDUCE-1048-20.patch
    Author: Amareshwari Sriramadasu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:04 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2041bfbf1352a83f450b8fb6680e3899a3582f5f:
    MAPREDUCE-1103. Additional JobTracker metrics for slot usage
    
    Patch: https://issues.apache.org/jira/secure/attachment/12423030/1103_v5_yahoo_1.patch
    Author: Sharad Agarwal
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b68a6a3c45b48d7681f5e8dc51571b161a90daec:
    MAPREDUCE-947. OutputCommitter should have an abortJob method
    
    Patch: https://issues.apache.org/jira/secure/attachment/12422899/mr-947-y20.patch
    Patch: https://issues.apache.org/jira/secure/attachment/12423191/yhadoop20-bug-fix-947.patch
    Author: Amar Kamat
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a268e40988a356cb7d6912906b88c8752c226656:
    MAPREDUCE-1105. CapacityScheduler: It should be possible to set queue hard-limit beyond its actual capacity
    
    Patch: https://issues.apache.org/jira/secure/attachment/12422823/MAPREDUCE-1105-yahoo-version20-5.patch
    Author: rahul k singh
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e529fcd5080e89bc0e759164d7b7cc6fc19d8f69:
    MAPREDUCE-1086. hadoop commands in streaming tasks are trying to write to tasktracker's log
    
    Patch: https://issues.apache.org/jira/secure/attachment/12422677/MR-1086-yhadoop20.patch
    Author: Ravi Gummadi
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4d2f9fdf63f30f0149f60142796838e245e7d564:
    MAPREDUCE-1088. JobHistory files should have narrower 0600 perms
    
    Patch: https://issues.apache.org/jira/secure/attachment/12422526/MAPREDUCE-1088_yhadoop20.patch
    Author: Arun C Murthy
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 13e93cafe8d4b1e8b741c1873118cdba0313a564:
    HADOOP-6304. Use java.io.File.set{Readable|Writable|Executable} where possible in RawLocalFileSystem
    
    Patch: https://issues.apache.org/jira/secure/attachment/12422525/HADOOP-6304_yhadoop20.patch
    Author: Arun C Murthy
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e5b918e037e5a01a4098b43a20e3437b34022328:
    HADOOP-6284. Add new HADOOP_JAVA_PLATFORM_OPTS passed to the java PlatformName command
    
    Patch: http://issues.apache.org/jira/secure/attachment/12421342/HADOOP-6284-y0.20.1.patch
    Author: Koji Noguchi
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5b18d7b8a13873ca3b0cb3f5da074f3ee846e63c:
    MAPREDUCE-732. Node health check script should not log "UNHEALTHY" status for every heartbeat in INFO mode
    
    Patch: http://issues.apache.org/jira/secure/attachment/12413001/MAPRED-732-ydist.patch
    Author: Sreekanth Ramakrishnan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f2f02dce3f12d9fe445f62c6a28a7e89c1f33efa:
    MAPREDUCE-144. TaskMemoryManager should log process-tree's status while killing tasks.
    
    Patch: http://issues.apache.org/jira/secure/attachment/12418917/MAPREDUCE-144-20090907.internal.txt
    Author: Vinod K V
    Reason: This helps a lot in debugging why a particular task has gone beyond memory limits.
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a77ecd569495efc6bee0059eeafeebbfe6c797c4:
    MAPREDUCE-277. Job history counters should be available on the UI.
    
    Patch: https://issues.apache.org/jira/secure/attachment/12421419/patch-277-0.20.txt
    Author: Jothi Padmanabhan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ce8f674e1c1dc6ff24b33210f726ef4b006552b2:
    HDFS-587. Test programs support only default queue.
    
    Patch: http://issues.apache.org/jira/secure/attachment/12422760/jira.HDFS-587.branch-0.20-internal.1.patch
    Author: Erik Steffl
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5ef23c2c9af26024567584fb6308645c58db8088:
    MAPREDUCE-270. Fix the tasktracker to optionally send an out-of-band heartbeat on task-completion for better job-latency.
    
    Configuration changes: add mapreduce.tasktracker.outofband.heartbeat
    Patch: https://issues.apache.org/jira/secure/attachment/12420718/MAPREDUCE-270_yhadoop20.patch
    Author: Arun C Murthy
    Reason: increase scheduling throughput for short tasks
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bfa424ff3808e6dc20199ecc7d52f2592afdbd3a:
    MAPREDUCE-1030. Fix capacity-scheduler to assign a map and a reduce task per-heartbeat.
    
    Patch: http://issues.apache.org/jira/secure/attachment/12420549/MAPREDUCE-1030-2.patch.txt
    Author: rahul k singh
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 48bfdd9b2a6eac72ac42b0defe5e86501001a7ab:
    MAPREDUCE-1028. Fixed number of slots occupied by cleanup tasks to one irrespective of slot size for the job.
    
    Patch: http://issues.apache.org/jira/secure/attachment/12420581/yhadoop-0.20-MR1028.patch
    Author: Ravi Gummadi
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3ce342baafd3774e4d920a7fcb49a7e091a0cad1:
    MAPREDUCE-964. Fixed start and finish times of TaskStatus to be consistent, thereby fixing inconsistencies in metering tasks.
    
    Patch: http://issues.apache.org/jira/secure/attachment/12420539/mapreduce-964-ydist.patch
    Patch: http://issues.apache.org/jira/secure/attachment/12420893/mapreduce-964-ydist-1.patch
    Author: Sreekanth Ramakrishnan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2219e76392d0bf29d8c40bf2b60d23d7b188ac3d:
    HADOOP-5976. Add a new command, classpath, to the hadoop script. Contributed by Owen O'Malley
    
    Patch: http://issues.apache.org/jira/secure/attachment/12420325/script.patch
    Author: Owen O'Malley and Gary Murry
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1e8994a568a45a994ef7c2af354ac1ddc2c1586b:
    HADOOP-5784. Makes the number of heartbeats that should arrive a second at the JobTracker configurable.
    
    Patch: http://issues.apache.org/jira/secure/attachment/12420257/HADOOP-5784_yhadoop20.patch
    Author: Amareshwari Sriramadasu
    Reason: Improve job latency on small clusters
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit eac5f2a5d51414c8fea6ea9792e21cf85433d017:
    MAPREDUCE-945. Modifies MRBench and TestMapRed to use ToolRunner so that options such as queue name can be passed via command line.
    
    Patch: http://issues.apache.org/jira/secure/attachment/12418910/mapreduce-945-internal-3.8.patch.txt
    Author: Sreekanth Ramakrishnan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 073f548e560fd8de055d8d075ac7c5db0239f6cf:
    HADOOP-6227. Configuration does not lock parameters marked final if they have no value.
    
    Patch: http://issues.apache.org/jira/secure/attachment/12418242/patch-6227-ydist.txt
    Author: Amareshwari Sriramadasu
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit fe36ce2d38b60a1fe1541555e172cc05473debec:
    Amend HADOOP-5363. Removed pickOneAddress function.
    
    Author: zhiyong zhang
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e37a57a386abb6f03336097f2d7b0d54d4ec6a82:
    HADOOP-5780: Fix slightly confusing log from "-metaSave" on NameNode.
    
    Patch https://issues.apache.org/jira/secure/attachment/12417831/HADOOP-5780.hadoop-0.20.patch
    Author: Raghu Angadi
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b131d77cefee39b7296530b018d59ca4d1516b01:
    Amend MAPREDUCE-768. Improved version of JobTracker configuration dump that also dumps job queues
    
    Author: V.V.Chaitanya Krishna
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c602e3c58dab89470526d912f32ca05260a18e8c:
    MAPREDUCE-682. Reserved tasktrackers should be removed when a node is globally blacklisted
    
    Patch: http://issues.apache.org/jira/secure/attachment/12414313/mapreduce-682-ydist.patch
    Author: Sreekanth Ramakrishnan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 953a6498484ee51bf09691568ecb5e56cdb31034:
    HADOOP-5420.  Support killing of process groups in LinuxTaskController binary
    
    Author: Sreekanth Ramakrishnan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e2a79393fa3a9f88029f289e89831c5dcbd7274c:
    HADOOP-5488. HADOOP-2721 doesn't clean up descendant processes of a jvm
    that exits cleanly after running a task successfully
    
    Author: Ravi Gummadi
    Reason: Avoid zombie processes
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 000ab92d9544f483b3c59c0c100154badf8fd8a6:
    MAPREDUCE-467. Collect information about number of tasks succeeded / total per time unit for a tasktracker.
    
    Author: Sharad Agarwal
    Reason: Useful operational feature
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ef2406bed6475cd6665f3601e9d78972beed739f:
    MAPREDUCE-817. Add a cache for retired jobs with minimal job info and provide a way to access history file url
    
    Author: Sharad Agarwal
    Reason: Reduces memory usage of JT for completed jobs
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ff22ad890d9228399e36846f308dd42f96c49fde:
    MAPREDUCE-809. Job summary logs from MAPREDUCE-740 show status of completed jobs as RUNNING
    
    Author: Arun C Murthy
    Reason: Bug fix for MAPREDUCE-740
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9ed072be95517e09cbc78333abbc3d5129e2db7d:
    MAPREDUCE-740. Log a job-summary at the end of a job, while allowing it to be
    configured to use a custom appender if desired.
    
    Author: Arun C Murthy
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cdd93ee3bca2b400f7b193c5b6527705262c4769:
    MAPREDUCE-771. Setup and cleanup tasks remain in UNASSIGNED state for a long
    time on tasktrackers with long running high RAM tasks.
    
    Author: Hemanth Yamijala
    Reason: Bug fix
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e53741132f4e458382899f5181e4c3a45a199113:
    MAPREDUCE-733. When running ant test TestTrackerBlacklistAcrossJobs, losing task tracker heartbeat.
    
    Author: Arun C Murthy
    Reason: Bug fix
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ce660087bdc95831ee5d2d18621bbdafb2c7e3fb:
    MAPREDUCE-734. ConcurrentModificationException observed in unreserving slots for HiRam Jobs
    
    Author: Arun Murthy
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a44f3f66cbc30bf5493aa6a3d21c3b6ca42fbac6:
    MAPREDUCE-693. Conf files not moved to "done" subdirectory after JT restart
    
    Author: Amar Kamat
    Reason: Improves stability of JobTracker job recovery
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9e729a1e4afd7f691dfd86f38cb89788e8eeee00:
    MAPREDUCE-722. More slots are getting reserved for HiRAM job tasks then required
    
    Author: Vinod K V
    Reason: More slots were getting reserved for HiRAM job tasks then required
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 45605c6b29c206b9ed3ec2324f4f709c914ca1e3:
    MAPREDUCE-709. Node health check script does not display the correct message on timeout
    
    Author: Sreekanth Ramakrishnan
    Reason: Improve usefulness of health check feature
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5c24b7d50ba0960f694bce33332e61fe7c5abe68:
    MAPREDUCE-732. Removed spurious log statements in the node blacklisting logic.
    
    Author: Sreekanth Ramakrishnan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6b1a17e13ddaf20b519eba0b49d4b0e8717bd5b9:
    MAPREDUCE-522. Rewrite TestQueueCapacities to make it simpler and avoid timeout errors
    
    Author: Sreekanth Ramakrishnan
    Reason: Fix unit test failures
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 73597dcbf6f791bd6e01c3096d41fe65ddc2034c:
    MAPREDUCE-532. Allow admins of the Capacity Scheduler to set a hard-limit on the capacity of a queue
    
    Reason: There should be a mechanism to cap the capacity available for a queue/job.
    Author: Rahul K Singh
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit aea5743326793c6f5aa6dc7f7fc5baf5752528d9:
    MAPREDUCE-211. Provide a node health check script and run it periodically to check the node health status
    
    Reason: Adds ability to preemptively blacklist task-trackers when node health is bad
    Author: Sreekanth Ramakrishnan
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a89847e2c69619eff9ced8b86c81bfab321a9918:
    MAPREDUCE-516. Fix the 'cluster drain' problem in the Capacity Scheduler wrt High RAM Jobs
    
    Reason: When a HighRAMJob turns up at the head of the queue, the current implementation
            of support for HighRAMJobs in the Capacity Scheduler has a problem in that the
            scheduler stops assigning tasks to all TaskTrackers in the cluster until a
            HighRAMJob finds a suitable TaskTrackers for all its tasks.
    Author: Arun C Murthy
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:21:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7a6862110776544476ac1066e3dbade4d1456567:
    HADOOP-5980. LD_LIBRARY_PATH not passed to tasks spawned off by LinuxTaskController
    
    Reason: Security
    Author: Sreekanth Ramakrishnan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:20:59 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d37609510f33ad26bbe6bf3c3d235b34b804f93a:
    HADOOP-5420. Support killing of process groups in LinuxTaskController binary
    
    Reason: Security - prevent orphaning forked child processes
    Author: Sreekanth Ramakrishnan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:20:59 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4c3c667f54a058d0f2e746ceb2e744f56dd9515a:
    HADOOP-5801. JobTracker should refresh the hosts list upon recovery
    
    Reason: YDH
    Author: Amar Kamat
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:20:59 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 91d28f32f9db514661cc9bd755c8e85756c09cfc:
    HADOOP-5818. Revert the renaming from checkSuperuserPrivilege to checkAccess by HADOOP-5643
    
    Author: Amar Kamat
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:20:49 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b46f960ff5488b6d6ace47e127257eb1b0fbc330:
    HADOOP-5643. Add ability to blacklist a TaskTracker
    
    Author: Amar Kamat
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 17:20:30 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ebb508c5a286dc3939d960fbf44ca18b34f1c12f:
    HADOOP-5419. Provide a way for users to find out what operations they can do on which M/R queues
    
    Reason: Security
    Author: Rahul K Singh
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 16:24:32 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit feb0e489f3e9757db541ea1694fe49f902e93f8c:
    HADOOP-5739 / MAPREDUCE-521. After JobTracker restart Capacity Scheduler does not schedule pending tasks from already running tasks.
    
    Reason: YDH
    Author: Rahul K Singh
    Ref: YDH
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 16:24:32 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 32bac3250a29cc47985fc88edadf0844d2519045:
    HADOOP-5396. Queue ACLs should be refreshed without requiring a restart of the Job Tracker
    
    Reason: Security
    Author: Vinod K V
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 16:24:32 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cd043f04714cf1a9940fe4351d0919011f8e9f86:
    HADOOP-4490. Tasks should run as the user who submitted the jobe
    
    Reason: Security
    Author: Hemanth Yamijala
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 16:24:32 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c64b6a0deb1311e410f01e5d94b9498795cbbaef:
    HADOOP-4930. Implement setuid executable for Linux to launch tasks as job owners
    
    Reason: Security
    Author: Sreekanth Ramakrishnan
    Ref: CDH-648
    
 -- Todd Lipcon <todd@cloudera.com>  Thu, 26 Aug 2010 16:24:32 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5b5972174da804fb6dcb4d0723208bfa42366a31:
    CLOUDERA-BUILD. Revert scribe log4j.
    
    Ref: CDH-742
    
 -- Eli Collins <eli@cloudera.com>  Thu, 26 Aug 2010 16:09:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2a37b553b8f446f03cb3610b2f7a84f54064f812:
    CLOUDERA-BUILD. Revert scribe log4j.
    
    Revert "CLOUDERA-BUILD. Apply Scribe patches to Hadoop"
    
    This reverts commit cb7a3677942c1d2f9e0d2a75dbffa09fa6125e61.
    
    Conflicts:
    
    	src/contrib/scribe-log4j/ivy.xml
    
    Ref: CDH-742
    
 -- Eli Collins <eli@cloudera.com>  Thu, 26 Aug 2010 16:09:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ea2a876095da80eccebca35890f437307843eb2c:
    CLOUDERA-BUILD. Revert scribe log4j.
    
    Revert "CLOUDERA-BUILD. Add dependency libraries for Scribe/log4j"
    
    This reverts commit aaeb69f8dda72a2e7aecacd622e99c00bc961efa.
    
    Ref: CDH-742
    
 -- Eli Collins <eli@cloudera.com>  Thu, 26 Aug 2010 16:09:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e463bba27fcae3ea83a8d33a64a8c1c38c2a7578:
    CLOUDERA-BUILD. Revert scribe log4j.
    
    Revert "CLOUDERA-BUILD. Fix scribe-log4j's ivy.xml to properly get log4j on the compile classpath"
    
    This reverts commit 349281bfa0243f5adbbd459266f4a9ac7ac8c1cc.
    
    Ref: CDH-742
    
 -- Eli Collins <eli@cloudera.com>  Thu, 26 Aug 2010 16:09:19 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c912024353450a0fa2c53a95500b4ed653f76129:
    MAPREDUCE-118. Job.getJobID() will always return null.
    
    Reason: Bug
    Author: Amareshwari Sriramadasu
    Ref: DISTRO-20
    
 -- Eli Collins <eli@cloudera.com>  Wed, 25 Aug 2010 11:01:38 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit be7cd3b5cec66c22b58caa8053de4258826e7c08:
    CLOUDERA-BUILD. Update the default build version.
    
 -- Eli Collins <eli@cloudera.com>  Wed, 11 Aug 2010 15:07:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 506dc096fcc4a288fc853dfb527d7fa8888dd6f6:
    CDH-1085. $SYSTEM_LIB_DIR default value shouldn't contain $PREFIX.
    
    Description: $SYSTEM_LIB_DIR default value shouldn't contain $PREFIX.
    $PREFIX will be prepended later on
    Reason: Bug
    Author: Bruno Mahe
    Ref: CDH-1085
    
  
  Author: Bruno Mahé <bruno@cloudera.com>  Fri, 16 Jul 2010 19:51:45 -0700
 -- Eli Collins <eli@cloudera.com>  Mon, 19 Jul 2010 16:45:41 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b7cba5f7ab2cb9f2240b45dd90c34f4974c5757a:
    CDH-1085. Native libraries should be installed in /usr/lib64/ on 64bit redhat
    
    Description: On 64bit redhat, native libraries should be installed in /usr/lib64/ instead of
    /usr/lib/. This patch makes possible to override the destination of native libraries and will default to
    /usr/lib/.
    Reason: Bug
    Author: Bruno Mahe
    Ref: CDH-1085
    
  
  Author: Bruno Mahé <bruno@cloudera.com>  Mon, 12 Jul 2010 20:17:48 -0700
 -- Eli Collins <eli@cloudera.com>  Mon, 19 Jul 2010 16:45:34 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9b72d268a0b590b4fd7d13aca17c1c453f8bc957:
    CLOUDERA-BUILD. Make symlinks so old hadoop jar names are preserved (CDH-1543).
    
 -- Eli Collins <eli@cloudera.com>  Sun, 27 Jun 2010 18:42:45 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4c50269dda2038d202ddb890ffde38dc3fb2ead2:
    MAPREDUCE-1887. MRAsyncDiskService does not properly absolutize volume root paths.
    
    Description: In MRAsyncDiskService, volume names are sometimes specified as
    relative paths, which are not converted to absolute paths. This can cause
    errors of the form "cannot delete &lt;/full/path/to/foo&gt; since it is outside of
    &lt;relative/volume/root&gt;" even though the actual path is inside the root.
    Reason: Bug
    Author: Aaron Kimball
    Ref: CDH-1509
    
 -- Aaron Kimball <aaron@cloudera.com>  Thu, 24 Jun 2010 18:25:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 43ccf90369692c4d8b7d13a7f04b0864c55f615a:
    HDFS-1266. Add Apache License Notice to several places where it was missing
    
    Description: Adds license headers to source code
    Reason: Apache policy
    Author: Todd Lipcon
    Ref: CDH-1495
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 23 Jun 2010 18:13:10 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bf08bde983501e3ce8ebf6197049262518580611:
    HDFS-1260. tryUpdateBlock should do validation before renaming meta file
    
    Description: Solves bug where block became inaccessible in certain failure
                 conditions (particularly network partitions). Observed under
                 HBase workload at user site.
    Reason: Potential loss of synced data when write pipeline fails
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Wed, 23 Jun 2010 18:13:07 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7243001d5511922f293f0641cb8dbc0af4850dae:
    HDFS-1254. Enable append feature by default
    
    Description: Changes dfs.support.append to "true" in hdfs-default.xml
    Reason: Append/sync have been tested in CDH3b2 and are safe to use.
    Author: Dhruba Borthakur
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Mon, 21 Jun 2010 20:27:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0e1d71c08923bb4c4172ef043b0b2d82f95b92fa:
    HDFS-1252. Updates to TestDFSConcurrentFileOperations (test was previously broken)
    
    Description: Fixes TestDFSConcurrentFileOperations to test the correct
                 semantics for sync feature
    Reason: Test was previously flaky
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Mon, 21 Jun 2010 20:26:37 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 829497f4867a0e92da712faf02f83c7087df07ce:
    CLOUDERA-BUILD. Remove Sqoop from the build.
    
 -- Eli Collins <eli@cloudera.com>  Fri, 18 Jun 2010 19:32:11 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 298fda37c4c25434a15886ee9c261e566d595dff:
    HADOOP-5203. TT's version build is too restrictive.
    
    Description: Use the md5sum checksum of the source for determining version compatibility.
    Reason: Improvement
    Author: Rick Cox (0.20 backport by Bill Au)
    Ref: CDH-1139
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 18 Jun 2010 18:42:37 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f07b2df591b91c7de50e8dbb526cf11b27a32a6f:
    MAPREDUCE-679. XML-based metrics as JSP servlet for JobTracker
    
    Description: A simple XML translation of the existing JobTracker status page
    which provides the same metrics (including the tables of
    running/completed/failed jobs) as the human-readable page. This is a
    relatively lightweight addition to provide some machine-understandable metrics
    reporting.
    Reason: Improvement
    Author: Aaron Kimball
    Ref: CDH-651
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 18 Jun 2010 18:30:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d8dc8dad821a02619afdbfc3d1cb978b86cb071b:
    MAPREDUCE-1372. ConcurrentModificationException in JobInProgress
    
    Description: Fixes a ConcurrentModificationException in JobInProgress
    Reason: Bug
    Author: Dick King
    Ref: CDH-546
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 18 Jun 2010 18:30:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e212ca0b0abbd78cdea4596fe9f3c6dbbaa57258:
    MAPREDUCE-1378. Args in job details links on jobhistory.jsp are not URL encoded
    
    Description: The logFile argument in the job links on the JT jobhistory.jsp
    page is not properly URL encoded leading to links that result in 500 errors.
    Reason: Bug
    Author: Eric Sammer
    Ref: CDH-645
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 18 Jun 2010 18:30:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 23e68e669a118d34e265af5e8ffda3615c2666f9:
    MAPREDUCE-1570. Shuffle stage - Key and Group Comparators
    
    Description: Shuffle method in org.apache.hadoop.mrunit.MapReduceDriverBase
    doesn't currently allow the use of custom GroupingComparator and
    SortComparator. This patch adds these features.
    Reason: Improvement
    Author: Chris White
    Ref: CDH-958
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 18 Jun 2010 18:30:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4601521a9793255e8b5881d64ff1a921451bc951:
    MAPREDUCE-739. Allow relative paths to be created inside archives.
    
    Description: Allow creating archives with relative paths with a -p option on
    the command line.  Archives currently stores the full path from the input
    sources – since it allows multiple sources and regular expressions as inputs.
    So the created archives have the full path of the input sources.  This is un
    intuitive and a user hassle. We should get rid of it and allow users to say
    that the created archive should be relative to some absolute path and throw an
    exception if the input does not confirm to the relative absolute path.
    Reason: Improvement
    Author: Mahadev konar
    Ref: CDH-501
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 18 Jun 2010 18:30:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1d4e15f0f8b749981d62bfca9849e0d0493afdad:
    HDFS-1247. Improvements to HDFS-1204 test
    
    Reason: Fixes compile warnings
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1fab52d87c29bc7117eb7324d1a152d8d889f62b:
    HDFS-1246. Manual tool to test sync on a cluster
    
    Description: Tool for automated testing that sync maintains every edit after kill -9
    Reason: Cluster Testing of Sync support for CDH3
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b9259a145f516a01ba37a33b3803c88824fd55e5:
    HDFS-1240. Fix failing TestDFSShell due to HDFS-909 backport on branch-20
    
    Reason: Fix red build
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7276208c2789f2c3961c6dc9fa1d2757774971b1:
    HDFS-1243. Replication tests in TestFileAppend4 should wait for a second for replication to occur
    
    Reason: Test error - fix sporadic failure of TestFileAppend4
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit dc1797ec8380b07117bbc6d662e2f1f56b25e6bd:
    HDFS-1207. stallReplicationWork should be marked volatile in FSNamesystem
    
    Description: Small bug fix for code used by tests only
    Reason: Fix sporadic failure of TestFileAppend4
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a960eea40dbd6a4e87072bdf73ac3b62e772f70a:
    HDFS-1197. Received blocks should not be added to block map prematurely for under construction files
    
    Description: Fixes a possible dataloss scenario when using append() on
                 real-life clusters. Also augments unit tests to uncover
                 similar bugs in the future by simulating latency when
                 reporting blocks received by datanodes.
    Reason: Append support dataloss bug
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3cc1405289ac4ec6616a5ba9da18ff421a93678e:
    HDFS-1209. Add parameter dfs.client.block.recovery.retries to determine how many times to try to recover block
    
    Reason: Used by append tests
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 128395ae4d317204fe8fb118333270826adf96d5:
    HDFS-1118. DFSOutputStream socket leak when can't connect to DN
    
    Reason: Fixes DFS Client socket leaks in an error condition
    Author: Zheng Shao
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4ba384d2b9f92f7300ce06b35a967e4edc3ba671:
    HADOOP-6762. Interrupting a thread performing an RPC should not hang that thread.
    
    Description: Moves the sending of parameters for RPC calls to a separate
                 thread, such that interrupting a thread that is making
                 an RPC call does not negatively affect the shared RPC channel.
    Reason: Fixes occasional hangs of HBase under heavy load during failure
            testing.
    Author: Sam Rash
    Ref: CDH-659, CDH-1084
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6e99c7e2a12eea782629337f5fb5734e8e5e5865:
    HDFS-1210. DFSClient should print IOE that caused recovery failure
    
    Description: Adds an extra WARN message during DFS client error recovery
    Reason: Makes it easier to debug/diagnose recovery issues
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1b8d8c3de261c8334d6eac4f5d3fd42cad894e81:
    HDFS-1186. Writers should be interrupted when recovery is started, not when it's completed.
    
    Description: When the write pipeline recovery process is initiated, this
                 interrupts any concurrent writers to the block under recovery.
                 This prevents a case where some edits may be lost if the
                 writer has lost its lease but continues to write (eg due to
                 a garbage collection pause)
    Reason: Fixes a potential dataloss bug
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:03 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2ec4301341b249acd0c0cac1792aaa6a6dabab8e:
    HDFS-915. Write pipeline hangs for too long when ResponseProcessor hits timeout
    
    Description: Previously, the write pipeline would hang for the entire write
                 timeout when it encountered a read timeout (eg due to a
                 network connectivity issue). This patch interrupts the writing
                 thread when a read error occurs.
    Reason: Faster recovery from pipeline failure for HBase and other
            interactive applications.
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 641090318603c47bfd55e1eea2b039f37e5b723a:
    HDFS-1218. Replicas that are recovered during DN startup should not be allowed to truncate better replicas.
    
    Description: If a datanode loses power and then recovers, its replicas
                 may be truncated due to the recovery of the local FS
                 journal. This patch ensures that a replica truncated by
                 a power loss does not truncate the block on HDFS.
    Reason: Potential dataloss bug uncovered by power failure simulation
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 46f2b3ad578ea1d2ee2cca4e6467ba2daa57df0e:
    HDFS-445. pread should refetch block locations when necessary
    
    Description: The positional read API in DFSInputStream was previously
                 missing any retry logic. This patch adds this logic.
    Reason: HBase and other applications depend on the pread API.
    Author: Kan Zhang
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit aea067a20e16345f307de7efe80935dd7addbe6b:
    HDFS-1204. LeaseManager expiring leases should only expire the single file, not entire lease
    
    Reason: Logic bug in lease recovery could cause incorrectly interrupted
            writers
    Author: Sam Rash
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 10e5944da20d851a847cb2ef422383507d070085:
    HDFS-1242. Add unit test for the appendFile race condition / synchronization bug fixed in HDFS-142
    
    Reason: Test coverage for previously applied patch.
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 18174a2abc5a91105ae1adc2bda026d90c41a60b:
    HDFS-1202. Don't try to update block scan status if block scanner is not initialized yet
    
    Reason: Fixes NPE seen at DataNode startup
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ca9e1b3c59b05de9dc4fafa19f24dca80110bcc0:
    HDFS-1205. Make async disk service threads nameable
    
    Description: HDFS-611 moved some datanode operations to a separate thread
                 pool. This patch ensures that these worker threads have
                 clear names.
    Reason: Aids debugging/diagnosing of issues
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1b8316d403ac542772c0745159a7397c798a5698:
    HDFS-606. Avoid ConcurrentModification in replica invalidation
    
    Description: Replica invalidation iterated over a collection that it
                 also modified, causing a CME. This patch makes a copy
                 before iteration. Performance should be unaffected
                 as this is a rare code path.
    Reason: Avoid runtime exception in namenode
    Author: Konstantin Shvachko
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b7f908bc77d9344c36dcc409bbfe92709b98cf88:
    HDFS-1244. Misc improvements to TestFileAppend2
    
    Description: Improvements made to a test case to enable it to be run
                 from the command line, with the various test parameters
                 available in arguments.
    Reason: Enable long-running stress tests of append functionality.
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 370c9a1e75cc5d5e93cec066006ada0485139fb8:
    HDFS-1141. completeFile should check lease holder
    
    Description: Fixes a bug where a writer could finalize an in-progress
                 file after it had already lost its lease. This could occur
                 for example if the writer entered a GC pause after finishing
                 the last block but before finalizing the file.
    Reason: Potential dataloss bug with append/sync
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7f0d67fa52b9c58360b06e851bf77bc2f909f65f:
    HDFS-1215. Fix TestNodeCount to not infinite loop after HDFS-409 MiniCluster changes
    
    Description: Fixes a test to work properly after some test infrastructure
                 was changed by HDFS-142 in branch-0.20-append.
    Reason: Fixes failing test.
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 77ac4f46fb5c011b5ac7c5fedb4c51b31580c9ba:
    HDFS-1248. Miscellaneous cleanup and improvements on 0.20 append branch
    
    Description: Miscellaneous code cleanup and logging changes, including:
     - Slight cleanup to recoverFile() function in TestFileAppend4
     - Improve error messages on OP_READ_BLOCK
     - Some comment cleanup in FSNamesystem
     - Remove toInodeUnderConstruction (was not used)
     - Add some checks for null blocks in FSNamesystem to avoid a possible NPE
     - Only log "inconsistent size" warnings at WARN level for non-under-construction blocks.
     - Redundant addStoredBlock calls are also not worthy of WARN level
     - Add some extra information to a warning in ReplicationTargetChooser
    Reason: Improves diagnosis of error cases and clarity of code
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 46e6199d8819538d96c3f4c5dbbfba163382b2a9:
    HDFS-1122. Don't allow client verification to prematurely add inprogress blocks to DataBlockScanner
    
    Description: When a client reads a block that is also open for writing,
                 it should not add it to the datanode block scanner.
                 If it does, the block scanner can incorrectly mark the
                 block as corrupt, causing data loss.
    Reason: Potential dataloss with concurrent writer-reader case.
    Author: Sam Rash
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 07711a4ea3edd1a504eb9bbb13c93d5573620d34:
    HDFS-1057. Fixes for concurrent readers behind an appended file
    
    Description: Allows a client to read a file while it is still being
                 written by a writer, so long as the writer has called
                 sync().
    Reason: Used by HBase replication, and useful for other "tail"-like
            applications.
    Author: Sam Rash
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 587de668e43486f7109a885f617b9b757d7a649e:
    HADOOP-6722. Workaround a TCP spec quirk by not allowing NetUtils.connect to connect to itself
    
    Description: TCP's ephemeral port assignment results in the possibility
                 that a client can connect back to its own outgoing socket,
                 resulting in failed RPCs or datanode transfers.
    Reason: Fixes intermittent errors in cluster testing with ephemeral
            IPC/transceiver ports on datanodes.
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7a93fcc8c22b7cff87221ec0a8bf8f6689f12b82:
    HDFS-1203. Add small sleep to prevent DN flooding NN in error cases
    
    Description: If the datanode experiences an error in sending its block
                 reports to the name node, it previously would loop retrying
                 with no delay between attempts. In the case that the DN
                 is sending an invalid report, this will flood the NN with
                 RPCs. This patch adds a short sleep before the retry.
    Reason: Prevents possible flood of RPCs to the NameNode in DN error
            conditions.
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a30c033c1eed744948ddfddb82b81b06e12bba46:
    HDFS-561. Fix read timeouts in write pipeline to stage correctly
    
    Description: Previously, the read timeout on the write pipeline was
                 incorrectly calculated. This caused the client to detect
                 the wrong failed datanode when a datanode's network
                 failed or froze for another reason.
    Reason: Fix recovery behavior for frozen datanodes
    Author: Kan Zhang
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 02ab12541a004d67a96428055a58a3b726c1c4b6:
    HDFS-895. Allow hflush/sync to operate in parallel with other writers
    
    Description: Modifies synchronization of the DFSOutputStream sync feature
                 such that multiple threads can sync the same stream
                 concurrently and each will wait only the minimal amount
                 of time. Also allows further writes to continue past the
                 sync point while the sync waits.
    Reason: Substantial performance improvement for durable HBase
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d1c4359e1abc3f3e5e4fa16ee1c83a3d7f015da3:
    HDFS-1211. BlockReceiver logs too much at INFO level when using sync()
    
    Description: Reduces the log level from INFO to DEBUG for a common message
                 in the datanode log when using the sync feature.
    Reason: Substantially reduces DN log chattiness for syncing clients.
    Author: Todd Lipcon
    Ref: CDH-659
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 23cfa9e8263ad1d92814b5829e2f50bb37d57857:
    HDFS-1056. Fix possible multinode deadlocks during block recovery when using ephemeral dataxceiver ports
    
    Description: Fixes the logic by which datanodes identify local RPC targets
                 during block recovery for the case when the datanode
                 is configured with an ephemeral data transceiver port.
    Reason: Potential internode deadlock for clusters using ephemeral ports
    Author: Todd Lipcon
    Ref: CDH-659
    
  
  Author: todd <todd@monster01.sf.cloudera.com>  Sun, 21 Mar 2010 16:25:48 -0700
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 08cbce1e413e98d0aaeceeaca26a60c3d9a50b29:
    HDFS-611. Move block deletions to an async thread. Applying this to make the HDFS-142 patch apply cleanly
    
    Description: Moves the deletion of blocks in the datanode into a thread
                 pool. Substantially improves datanode heartbeat consistency
                 for workloads with heavy deletes and/or lots of disks.
    Reason: Substantially reduces frequency of "could not complete block"
            errors and needless re-replication on clusters with lots of disks
            or heavy deletes.
    Author: Zheng Shao
    Ref: CDH-659
    
  
  Author: todd <todd@monster01.sf.cloudera.com>  Sun, 21 Mar 2010 14:56:56 -0700
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 57783d0683f0d675423369e0a0f9f5dd520c17f2:
    HDFS-1055. Improve thread naming in DN Xceiver
    
    Description: Names the threads created by the DataNode based on the action
                 they are performing.
    Reason: Eases diagnosis of datanode performance/lock contention issues.
    Author: Todd Lipcon
    Ref: CDH-659
    
  
  Author: todd <todd@monster01.sf.cloudera.com>  Sun, 21 Mar 2010 03:36:45 -0700
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit fddb2bd057e88506a1bb94232426053d1640a34b:
    HDFS-894. Fix ipcPort tracking in Datanode registration. TODO: add the test case from JIRA
    
    Description: Fixes the NameNode to properly reregister datanodes when they
                 crash and restart with a different IPC port (eg when IPC port
                 is configured to be ephemeral)
    Reason: Fixes errors on clusters with ephemeral ports.
    Author: Todd Lipcon
    Ref: CDH-659
    
  
  Author: todd <todd@monster01.sf.cloudera.com>  Sun, 21 Mar 2010 03:36:29 -0700
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bc5217543eccc2cfd8a182cdbb051b39d2abf3e7:
    HDFS-1054. remove sleep before retry for allocating a block.
    
    Description: When the write pipeline fails to allocate a new block,
                 it previously slept for hard-coded 6 seconds before
                 retrying. This sleep has little reasoning behind it,
                 so is removed.
    Reason: Improve failure recovery performance for interactive applications
            like HBase.
    Author: Todd Lipcon
    Ref: CDH-931
    
  
  Author: Dhruba Borthakur <dhruba@apache.org>  Fri, 11 Jun 2010 16:37:38 +0000
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:10:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 870c7526a3e6a632eb23cf14f9011f279181a759:
    HDFS-142. Blocks that are being written by a client are stored in the blocksBeingWritten directory.
    
    git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/branch-0.20-append@953482 13f79535-47bb-0310-9956-ffa450edef68
    
    Description: Moves blocks being written by clients into a different
                 directory in dfs.data.dir. Also fixes several other bugs
                 in the datanode and namenode to support various error
                 conditions related to append and sync.
    Reason: Necessary for proper recovery of synced data in several error conditions.
    Author: Dhruba Borthakur, Nicolas Spiegelberg, Todd Lipcon
    Ref: CDH-659
    
  
  Author: Dhruba Borthakur <dhruba@apache.org>  Thu, 10 Jun 2010 15:25:39 +0000
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:09:59 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8e888717294496caae825d7f3f609d0661e7997a:
    HDFS-826. Allow a mechanism for an application to detect that datanode(s) have died in the write pipeline. (dhruba)
    
    Description: Adds an API in DFSOutputStream to determine the current length
                 of the write pipeline.
    Reason: Necessary for better reliability of HBase write-ahead logs.
    Author: Dhruba Borthakur
    Ref: CDH-931
    
  
  Author: Dhruba Borthakur <dhruba@apache.org>  Thu, 10 Jun 2010 11:46:03 +0000
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:09:59 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8fcb419648160efaed6fdd467875c3b1743d2bee:
    HDFS-988. Fix bug where savenameSpace can corrupt edits log.
    
    Description: Fixes several synchronization errors in the NameNode and ensures
                 that all edits have been synced to the edits log before
                 the namespace is saved.
    Reason: Fixes potential data corruption bug.
    Author: Todd Lipcon
    Ref: CDH-1436
    
  
  Author: Dhruba Borthakur <dhruba@apache.org>  Wed, 09 Jun 2010 16:12:21 +0000
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:09:59 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f5ace5f920bc16fd202a6e4a53fe0ffe0cb5045e:
    HDFS-101. Datanodes should continue to forward acks until client stops pipeline.
    
    Description: When one node in the pipeline dies, the datanodes in between the client
                 and the dead node should stay alive and continue to forward acks until
                 the client stops the pipeline. This fixes an issue where the client
                 would incorrectly determine that the local DN had failed when in fact
                 another DN in the pipeline was at fault.
    Reason: Common source of failed pipeline recovery in cluster fault testing
    Author: Hairong Kuang, Todd Lipcon
    Ref: CDH-693
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:09:59 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 132ef7c852847e9d2c1e7879f2fca26652bb77ef:
    HDFS-200. Support append and sync for hadoop 0.20 branch.
    
    Description: Provides basic support for append and sync on 0.20
    Reason: Append and sync required for durable HBase and many other
            applications.
    Author: Dhruba Borthakur
    Ref: CDH-659
    
  
  Author: Dhruba Borthakur <dhruba@apache.org>  Fri, 04 Jun 2010 00:20:10 +0000
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:09:59 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 092bcd174dbf609f5002078490c357462e0ce8b1:
    HDFS-909. Fix race in edit log rolling
    
    Description: Fixes a race condition when rolling edit logs that can corrupt
                 the logs.
    Reason: Potential namenode metadata corruption bug.
    Author: Todd Lipcon
    Ref: CDH-1174
    
  
  Author: Konstantin Shvachko <shv@apache.org>  Tue, 20 Apr 2010 20:05:45 +0000
 -- Todd Lipcon <todd@cloudera.com>  Fri, 18 Jun 2010 16:09:59 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e2a78f767d26b838bf67354a4b85235ddd731038:
    CLOUDERA-BUILD. Update hadoop-config.sh to reflect new jar version.
    
 -- Eli Collins <eli@cloudera.com>  Fri, 18 Jun 2010 14:41:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1756e97a35451bbc01a493e843f1ec0885c99792:
    MAPREDUCE-1644. Remove Sqoop from Apache Hadoop (moving to github)
    
    Description: Sqoop is moving to github! All code for sqoop is already live at
    http://github.com/cloudera/sqoop - this issue removes the duplicate code from the Apache Hadoop
    repository. CDH users should install the separate 'sqoop' package for this functionality.
    Reason: Moving to a separate package
    Author: Aaron Kimball
    Ref: CDH-1404
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 18 Jun 2010 14:15:24 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e0afb34b89a013419fca4bdcda5f2cf0401f93ca:
    MAPREDUCE-1302. TrackerDistributedCacheManager can delete file asynchronously
    
    Description: With the help of AsyncDiskService from MAPREDUCE-1213, we should be able to delete
    files from distributed cache asynchronously. That will help make task initialization faster, because task initialization calls the code that
    localizes files into the cache and may delete some other files.
    The deletion can slow down the task initialization speed.
    Reason: Performance improvement
    Author: Zheng Shao
    Ref: CDH-495
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 18 Jun 2010 14:15:15 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 456821d6934fd769ab317c2290a4ff53b075269e:
    HADOOP-6433. Add AsyncDiskService that is used in both hdfs and mapreduce
    
    Description: create a thread pool per disk volume, and use that for scheduling async disk
    operations.
    Reason: Improvement
    Author: Zheng Shao
    Ref: CDH-495
    
 -- Aaron Kimball <aaron@cloudera.com>  Thu, 17 Jun 2010 19:08:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6e467c42d62aafd00fd2f38269806680427631c8:
    MAPREDUCE-1213. TaskTrackers restart is very slow because it deletes distributed cache directory synchronously
    
    Description: We are seeing that when we restart a tasktracker, it tries to recursively delete all
    the file in the distributed cache. It invoked FileUtil.fullyDelete() which is very very slow. This
    means that the TaskTracker cannot join the cluster for an extended period of time (upto 2 hours for
    us). The problem is acute if the number of files in a distributed cache is a few-thousands.
    Reason: Performance
    Author: Zheng Zhao
    Ref: CDH-495
    
 -- Aaron Kimball <aaron@cloudera.com>  Thu, 17 Jun 2010 19:08:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5626a0e301557dbc93ad5084aa9ef4527316db7b:
    MAPREDUCE-1443. DBInputFormat can leak connections
    
    Description: The DBInputFormat creates a Connection to use when enumerating splits, but never closes
    it. This can leak connections to the database which are not cleaned up for a long time.
    Reason: bug
    Author: Aaron Kimball
    Ref: CDH-1435
    
 -- Aaron Kimball <aaron@cloudera.com>  Thu, 17 Jun 2010 19:08:23 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 912eed1c5d50066e68700d2143b775914d7f8e54:
    MAPREDUCE-1489. DataDrivenDBInputFormat should not query the database when generating only one split
    
    Description: DataDrivenDBInputFormat runs a query to establish bounding values for each split it
    generates; but if it's going to generate only one split (mapreduce.job.maps == 1), then there's no
    reason to do this. This will remove overhead associated with a single-threaded import of a
    non-indexed table since it avoids a full table scan.
    Reason: Improvement
    Author: Aaron Kimball
    Ref: CDH-1431
    
 -- Aaron Kimball <aaron@cloudera.com>  Thu, 17 Jun 2010 19:08:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1c3fc82063212196fd2fac7f55df8eb323e8f601:
    MAPREDUCE-1728. Oracle timezone strings do not match Java
    
    Description: OracleDBRecordReader sets the session timezone based on the toString representation of
    the current java.util.TimeZone. This is incorrect; Oracle manages a separate database of acceptable
    timezone strings, whose string representations are different than the timezone representations
    recognized by Java.
    Reason: Bug
    Author: Aaron Kimball
    Ref: CDH-961
    
 -- Aaron Kimball <aaron@cloudera.com>  Thu, 17 Jun 2010 19:08:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 11bc9be1ff2fd994046acd660afa7631f9203cfb:
    HADOOP-6714. FsShell 'hadoop fs -text' does not support compression codecs.
    
    Currently, 'hadoop fs -text myfile' looks at the first few magic bytes
    of a file to determine whether it is gzip compressed or a sequence
    file. This means 'fs -text' cannot properly decode .deflate or .bz2
    files (or other codecs specified via configuration).
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-1136
    
 -- Eli Collins <eli@cloudera.com>  Thu, 27 May 2010 17:45:17 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e95781032b5d886aa6583cab1306025fe372babf:
    HADOOP-1849. IPC server max queue size should be configurable.
    
    Description: Currently max queue size for IPC server is set to (100 *
    handlers). Usually when RPC failures are observed (e.g. HADOOP-1763),
    we increase number of handlers and the problem goes away. I think a
    big part of such a fix is increase in max queue size. I think we
    should make maxQsize per handler configurable (with a bigger default
    than 100). There are other improvements also (HADOOP-1841).  Server
    keeps reading RPC requests from clients. When the number in-flight
    RPCs is larger than maxQsize, the earliest RPCs are deleted. This is
    the main feedback Server has for the client. I have often heard from
    users that Hadoop doesn't handle bursty traffic.
    
    Say handler count is 10 (default) and Server can handle 1000 RPCs a
    sec (quite conservative/low for a typical server), it implies that an
    RPC can wait for only for 1 sec before it is dropped. If there 3000
    clients and all of them send RPCs around the same time (not very rare,
    with heartbeats etc), 2000 will be dropped. In stead of dropping the
    earliest RPCs, if the server delays reading new RPCs, the feedback to
    clients would be much smoother, I will file another jira regd queue
    management.
    
    For this jira I propose to make queue size per handler configurable,
    with a larger default (may be 500).
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-1133
    
 -- Eli Collins <eli@cloudera.com>  Wed, 26 May 2010 14:05:44 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 776a20d37142534751178b060285d2813cc66c1c:
    HADOOP-6724. IPC doesn't properly handle IOEs thrown by socket factory.
    
    Description: If the socket factory throws an IOE inside
    setupIOStreams, then handleConnectionFailure will be called with
    socket still null, and thus generate an NPE on socket.close(). This
    ends up orphaning clients, etc.
    
    Reason: Bug fix
    Author: Eli Collins
    Ref: CDH-1132
    
 -- Eli Collins <eli@cloudera.com>  Wed, 26 May 2010 14:05:39 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1864359f4ef32974ed41a1278e640e1ee246ef9b:
    HADOOP-6723. Unchecked exceptions thrown in IPC connection should not orphan clients.
    
    Description: If the server sends back some malformed data, for
    example, receiveResponse() can end up with an incorrect call ID. Then,
    when it tries to find it in the calls map, it will end up with null
    and throw NPE in receiveResponse. This isn't caught anywhere, so the
    original IPC client ends up hanging forever instead of catching an
    exception. Another example is if the writable implementation itself
    throws an unchecked exception or OOME.
    
    We should catch Throwable in Connection.run() and shut down the
    connection if we catch one.
    
    Reason: Bug fix
    Author: Eli Collins
    Ref: CDH-1131
    
 -- Eli Collins <eli@cloudera.com>  Wed, 26 May 2010 14:05:34 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 95d64157f05d467dad3e1190a5cba2a3f89b0925:
    CLOUDERA-BUILD. Rename the fuse_dfs wrapper.
    
    Description: Rename the fuse_dfs wrapper to hadoop-fuse-dfs.
    
    Reason: Improvement
    Author: Alex Newman
    Ref: CDH-1103
    
 -- Eli Collins <eli@cloudera.com>  Thu, 20 May 2010 19:55:09 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d8c973d9c6f650032c88915d9fef6f4a568d37a5:
    CLOUDERA-BUILD. Fixes for the fuse_dfs wrapper.
    
    Description: The wrapper uses bash syntax (i.e., +=) so we should use
    bash. We need to modprobe fuse explicitly on Ubuntu. Since this is
    installed by install_hadoop.sh we know HADOOP_HOME and should use it
    directly. Lastly, there is more robust JAVA_HOME checking in
    hadoop-config.sh so we should use that.
    
    Reason: Fuse currently broken on Ubuntu
    Author: Chad Metcalf
    Ref: CDH-1089
    
  
  Author: Chad Metcalf <chad@cloudera.com>  Wed, 19 May 2010 15:38:14 -0700
 -- Eli Collins <eli@cloudera.com>  Thu, 20 May 2010 19:54:50 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e810911445859693ee0b868c2a5d8bc18360cdb9:
    HDFS-1161. Make DN minimum valid volumes configurable
    
    Description: This change adds a dfs.datanode.failed.volumes.tolerated parameter so that users can configure the number of volumes that are allowed to fail before a datanode stops offering service. By default any volume failure will cause a datanode to shutdown.
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-1081
    
 -- Eli Collins <eli@cloudera.com>  Wed, 19 May 2010 14:23:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit baa77bdde4fd971877418391a4fe491c2d4c2501:
    HDFS-1160. Improve some FSDataset warnings and comments.
    
    Description: Cleans up HDFS-547 warnings.
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-1080
    
 -- Eli Collins <eli@cloudera.com>  Wed, 19 May 2010 14:23:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 90f5a4bf77d17adcabb834a3cc2e02becb9f012d:
    HDFS-612. FSDataset should not use org.mortbay.log.Log.
    
    Description: Cleans up HDFS-547 logging.
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-1079
    
 -- Eli Collins <eli@cloudera.com>  Wed, 19 May 2010 14:23:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4a925fe53a2015e504cd8c8796e0e590d22019c4:
    HDFS-457. Better handling of volume failure in Data Node storage.
    
    Description: Current implementation shuts DataNode down completely when one of the configured volumes of the storage fails. This is rather wasteful behavior because it decreases utilization (good storage becomes unavailable) and imposes extra load on the system (replication of the blocks from the good volumes). These problems will become even more prominent when we move to mixed (heterogeneous) clusters with many more volumes per Data Node.
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-472
    
 -- Eli Collins <eli@cloudera.com>  Wed, 19 May 2010 14:23:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3af9533ee6f260373f302ff4a16dd04eb75e0616:
    CLOUDERA-BUILD. hadoop-config runs before hadoop-env.sh
    
        conf/hadoop-env.sh says you can update JAVA_HOME there, but it gets
        sourced after hadoop-config.sh, which errors out if JAVA_HOME is not
        set. This patch changes the flow so hadoop-env is always sourced by
        hadoop-config after the --config flag is processed. This will allow
        JAVA_HOME to be set in hadoop-env and still allow for trying to find a valid
        JAVA_HOME.
    
  
  Author: Chad Metcalf <chad@cloudera.com>  Mon, 01 Mar 2010 15:28:19 -0800
 -- Eli Collins <eli@cloudera.com>  Wed, 19 May 2010 13:10:40 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c9295d4ac2848403362e5dbaa78aa7be4ce4254e:
    HADOOP-3659. Fix hadoop native to compile on Mac OS X.
    
    Description: This patch makes the autoconf script work on Mac OS X. LZO needs to be installed (including the optional shared libraries) for the compile to succeed. You'll want to regenerate the configure script using autoconf after applying this patch.
    
    Reason: Bug fix
    Author: Eli Collins
    Ref: CDH-825
    
 -- Eli Collins <eli@cloudera.com>  Sat, 15 May 2010 16:04:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cc035175e1cf1ddef878cba6aa93725f832d0327:
    MAPREDUCE-1785. Add streaming config option for not emitting the key.
    
    Description: PipeMapper currently does not emit the key when using TextInputFormat. If you switch to input formats (eg LzoTextInputFormat) the key will be emitted. We should add an option so users can explicitly make streaming not emit the key so they can change input formats without breaking or having to modify their existing programs.
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-856
    
 -- Eli Collins <eli@cloudera.com>  Sat, 15 May 2010 12:59:00 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 590a82c257842be51170619deafd15cc2988541e:
    HADOOP-4885. Try to restore failed replicas of Name Node storage (at checkpoint time).
    
    Description: If one of the replicas of the NameNode storage fails for whatever reason (for example temporarily failure of NFS) this Storage object is removed from the list of storage objects forever. It can be added back only on restart of the NameNode. We propose to check the status of a failed storage on every checkpoint and if it becomes valid - try to restore the edits and fsimage.
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-473
    
 -- Eli Collins <eli@cloudera.com>  Fri, 14 May 2010 16:15:51 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0f2f19e1bd5725f6163998ae86d9103c0d552de3:
    HDFS-1024. SecondaryNamenode fails to checkpoint because namenode fails with CancelledKeyException.
    
    Description: The secondary namenode fails to retrieve the entire fsimage from the Namenode. It fetches a part of the fsimage but believes that it has fetched the entire fsimage file and proceeds ahead with the checkpointing.
    
    Reason: Bug fix
    Author: Eli Collins
    Ref: CDH-891
    
 -- Eli Collins <eli@cloudera.com>  Thu, 13 May 2010 21:20:45 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0ec1d6ed85a30327c657c2418932728d0e4e98df:
    HADOOP-6254. Slow reads cause s3n to fail with SocketTimeoutException
    
    Reason: Bug fix for users of s3n:// file system
    Author: Andrew Hitchcock
    Ref: CDH-1035
    
 -- Todd Lipcon <todd@lipcon.org>  Wed, 12 May 2010 21:35:33 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d64943401780c3dd1dc498419f33ded8222c3210:
    HADOOP-6667. RPC.waitForProxy should retry through NoRouteToHostException.
    
    Description: RPC.waitForProxy already loops through ConnectExceptions, but NoRouteToHostException is not a subclass of ConnectException. In the case that the NN is on a VIP, the No Route To Host error is reasonably common during a failover, so we should retry through it just the same as the other connection errors.
    
    Reason: Improvement
    Author: Eli Collins
    Ref: CDH-907
    
 -- Eli Collins <eli@cloudera.com>  Wed, 12 May 2010 12:07:59 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a5fb4a8c8bf9d6a3a96c3a06eb3a46febaf21a0f:
    MAPREDUCE-1375. TestFileArgs fails intermittently
    
    Description: Fixes an error in a test case without modifying code. This is an amendment to the prior fix which did not address the issue properly.
    Reason: Should fix flaky tests.
    Author: Todd Lipcon
    Ref: CDH-657
    
 -- Todd Lipcon <todd@cloudera.com>  Fri, 07 May 2010 16:25:43 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 148d291aa14a4481dc206d2fc9a8527eb6761488:
    CLOUDERA-BUILD. Add a fuse manpage
    
    Description: Adding a fuse_dfs manpage and adding a manpage to the build.
    Reason: New Feature
    Author: Alex Newman
    Ref: CDH-927
    
 -- newalex <newalex@ubuntu64-build01.(none)>  Fri, 16 Apr 2010 16:04:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9acfd39492f85c92bc45d47d6dcfb309e3826c64:
    CLOUDERA-BUILD. Build script changes to build DEB packages
    
    Description: The required changes to the cloudera hadoop building scripts for pulling the fuse files out and cleaning up its mess v.v. DEBs.
    Reason: Building packages
    Author: Alex Newman
    Ref: CDH-929
    
 -- newalex <newalex@centos64-build01.sf.cloudera.com>  Thu, 08 Apr 2010 16:43:26 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d144085817496eecc57c510022d66d0540b4511d:
    CLOUDERA-BUILD. Added an RPM for fuse
    
    Description: The required changes to the cloudera hadoop building scripts for pulling the fuse files out and cleaning up its mess.
    Reason: Building packages
    Author: Alex Newman
    Ref: CDH-928
    
 -- newalex <newalex@centos64-build01.sf.cloudera.com>  Thu, 08 Apr 2010 16:43:13 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 56648efe291503249fec22a242917ec4dddc6214:
    HADOOP-6522. Fix decoding of codepoint zero in UTF8.
    
    Description: TestUTF8 is actually flaky. It generates 10 random strings to run the test on. If you change this number to 100000 it fails every time. The problem is that the null character (codepoint zero) was correctly encoded but incorrectly decoded. I've attached a patch that fixes this and increases the size of the tests so that problems like this will likely be discovered sooner.
    
    Reason: Bugfix to UTF8
    Author: Eli Collins
    Ref: CDH-718
    
 -- Eli Collins <eli@cloudera.com>  Tue, 30 Mar 2010 15:20:01 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 936a67ba3b34dc8c8efd3df92d9e50309fafb8f6:
    MAPREDUCE-1460. Oracle support in DataDrivenDBInputFormat
    
    Description: DataDrivenDBInputFormat does not work with Oracle due to various SQL syntax issues.
    Reason: Required for Sqoop/Oracle integration
    Author: Aaron Kimball
    Ref: CDH-888
    
 -- Aaron Kimball <aaron@cloudera.com>  Mon, 29 Mar 2010 23:50:14 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c08f94a6927f9c8b0dfaeb674835afdd3fdd1d08:
    MAPREDUCE-1569. Mock Contexts & Configurations
    
    Description: Currently the library creates a new Configuration object in the MockMapContext and
    MocKReduceContext constructors, rather than allowing the developer to configure and pass their own
    Reason: Feature improvement for MRUnit
    Author: Chris White
    Ref: CDH-838
    
 -- Aaron Kimball <aaron@cloudera.com>  Mon, 29 Mar 2010 17:15:53 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 27cfda1de80048bf2b46d74d78b61275ecc79be1:
    MAPREDUCE-1536. DataDrivenDBInputFormat does not split date columns correctly.
    
    Description: The DateSplitter does not properly split a range of (min, max) dates.
    Reason: Bugfix to DateSplitter
    Author: Aaron Kimball
    Ref: CDH-813
    
 -- Aaron Kimball <aaron@cloudera.com>  Mon, 29 Mar 2010 16:43:49 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7fc6e48e296c30f0afa8ae8da668bddbc9f422bf:
    MAPREDUCE-1480. CombineFileRecordReader does not properly initialize child RecordReader
    
    Description: CombineFileRecordReader instantiates child RecordReader instances but never calls their initialize() method to give them the proper TaskAttemptContext.
    Reason: Bug in CombineFileInputFormat prevents proper use.
    Author: Aaron Kimball
    Ref: CDH-811
    
 -- Aaron Kimball <aaron@cloudera.com>  Mon, 29 Mar 2010 16:11:22 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 32330fbadb4aed16627397979b90d52f2474ef38:
    MAPREDUCE-1423. Improve performance of CombineFileInputFormat when multiple pools are configured
    
    Description: I have a map-reduce job that is using CombineFileInputFormat. It has configured 10000
    pools and 30000 files. The time to create the splits takes more than an hour. The reaosn being that
    CombineFileInputFormat.getSplits() converts the same path from String to Path object multiple times,
    one for each instance of a pool. Similarly, it calls Path.toUri(0 multiple times. This code can be
    optimized.
    
    Reason: Improves CombineFileInputFormat performance (used by Sqoop); needed to apply MAPREDUCE-1480 cleanly
    Author: Dhruba Borthakur
    Ref: CDH-811
    
 -- Aaron Kimball <aaron@cloudera.com>  Mon, 29 Mar 2010 15:50:20 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6906389e07244931a108f2930544b9feada3a487:
    MAPREDUCE-364. Change org.apache.hadoop.examples.MultiFileWordCount to use new mapreduce api.
    
    Description: Updates MultiFileWordCount example to use the new API in
    org.apache.hadoop.mapreduce instead of the deprecated API of
    org.apache.hadoop.mapred.
    
    This incorporates MAPREDUCE-367: Change org.apache.hadoop.mapred.lib.CombineFileInputFormat
    to use the new api.
    
    This solves duplicate issue MAPREDUCE-1112: Fix CombineFileInputFormat for hadoop 0.20
    
    Reason: CombineFileInputFormat required for many clients of the new API, including Sqoop.
    Author: Amareshwari Sriramadasu
    Ref: CDH-811
    
 -- Aaron Kimball <aaron@cloudera.com>  Mon, 29 Mar 2010 15:41:38 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4b592cf8cb44c018f86abe529d71434d5106ce1e:
    HADOOP-6382. Publish hadoop jars to apache mvn repo.
    
    Description: This provides an 'ant mvn-install' command that will
    install Hadoop core, streaming, examples, etc. jars in a maven repository.
    
    Uses the maven ant task to publish hadoop 20 jars to the apache maven repo.
    Reason: Required for cross-distribution dependency management in downstream projects (e.g., sqoop)
    Author: Giridharan Kesavan
    Ref: CDH-402
    
 -- Aaron Kimball <aaron@cloudera.com>  Mon, 29 Mar 2010 14:55:36 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8424e32eb866d677f40a9446f9c4cf74972b751e:
    HADOOP-6643. Set executable bit for python cloud scripts in the distribution
    
    Description: This needs to be set in the tar target.
    Reason: Required for the EC2 scripts.
    Author: Tom White
    Ref: CDH-821
    
  
  Author: Chad Metcalf <chad@cloudera.com>  Thu, 18 Mar 2010 17:05:47 -0700
 -- Tom White <tom@cloudera.com>  Fri, 19 Mar 2010 15:05:02 -0700


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cfc3233ece0769b11af9add328261295aaf4d1ad:
    CLOUDERA-BUILD. Fix ivy xml after rebase. Removed a redundant </dependencies> closing tag.
    
    Author: Matt Massie
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:56:30 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 54e1aefdd7a25a539831cac2c9b1bc3597f119ea:
    CLOUDERA-BUILD. Small tweaks and fixes to Cloudera styling:
    
    Description:
        - Fixes trivial CSS bug for missing table cell borders in Chrome
        - Fixes footer to read "Distribution for Hadoop" instead of "Distribution of Hadoop"
    
    Author: Todd Lipcon
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:56:07 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ea83036b3838fa97c673e73145d52867b8ace6ac:
    HDFS-1013. Miscellaneous improvements to HTML markup for web UIs
    
    Description: The Web UIs have various bits of bad markup (eg missing &lt;head&gt; sections, some pages missing CSS links, inconsistent td vs th for table headings). We should fix this up.
    <hr/>
        Improve markup and add Cloudera styling to Web UIs
    
        This adds a favicon and a number of HTML/CSS improvements to make the
        pages more space-efficient and easy on the eyes.
    
        This may be an incompatible change for users who are scraping the HTML
        output of the web UIs. Those users are encouraged to access the data
        programmatically rather than through scraping.
    
        The non-Cloudera-specific improvements will be contributed upstream
        as HDFS-1013 and MAPREDUCE-1544.
    Reason: User experience improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:55:30 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 90ba5543e4c3176343e23943131a34d666c23d89:
    MAPREDUCE-1436. Deadlock in preemption code in fair scheduler
    
    Description: In testing the fair scheduler with preemption, I found a deadlock between updatePreemptionVariables and some code in the JobTracker. This was found while testing a backport of the fair scheduler to Hadoop 0.20, but it looks like it could also happen in trunk and 0.21. Details are in a comment below.
    <hr/>
    The fair scheduler introduces a potential jobtracker deadlock which
    was fixed on trunk by MAPREDUCE-870. This patch adjusts the locking
    in 0.20-based MapReduce to prevent this condition.
    
    Reason: bugfix (deadlock)
    Author: Matei Zaharia
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:54:58 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6f04e94feee3f40a73449cc6fbe7b4e3c48f1fc4:
    HDFS-696. Java assertion failures triggered by tests
    
    Description: Re-purposing as catch-all ticket for assertion failures when running tests with java asserts enabled. Running with the attached patch on trunk@823732 the following tests all trigger assertion failures:
    
    <p>TestAccessTokenWithDFS<br/>
    TestInterDatanodeProtocol<br/>
    TestBackupNode <br/>
    TestBlockUnderConstruction<br/>
    TestCheckpoint  <br/>
    TestNameEditsConfigs<br/>
    TestStartup<br/>
    TestStorageRestore</p>
    <hr/>
        Disable failing asserts (see HDFS-696).
    
        Disabled asserts in HDFS that cause unit tests to fail.
        These will be re-enabled at a later date when the underlying cause is fixed
        upstream. In the meantime, these are disabled to keep our CI server returning
        only new failures. Issue HDFS-696 lists the failing tests and tracks their
        progress.
    Reason: Test harness improvement
    Author: Eli Collins
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:54:13 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 74b80b9c9490bba1a1120f3a9376d2f21f3763b6:
    MAPREDUCE-1093. Java assertion failures triggered by tests
    
    Description:
        Removes failing asserts from the CDH build until they are fixed in trunk.
        Tracking MAPREDUCE-1506 to include a fix for this assertion failure.
    Reason: Test harness improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:53:38 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b4be440cd928976544bcbeb7e10566fc523dbd0c:
    MAPREDUCE-1092. Enable asserts for tests by default
    
    Description: See <a href="http://issues.apache.org/jira/browse/HADOOP-6309" title="Enable asserts for tests by default"><del>HADOOP-6309</del></a>. Let's make the tests run with java asserts by default.
    Reason: Test coverage improvement
    Author: Eli Collins
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:53:13 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5e7fb9843f99f5e1023f2723210f26ac0c33323b:
    MAPREDUCE-1375. TestFileArgs fails intermittently
    
    Description: TestFileArgs failed once for me with the following error
    <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
    <pre class="code-java">expected:&lt;[job.jar
    sidefile
    tmp
    ]&gt; but was:&lt;[]&gt;
    sidefile
    tmp
    ]&gt; but was:&lt;[]&gt;
            at org.apache.hadoop.streaming.TestStreaming.checkOutput(TestStreaming.java:107)
            at org.apache.hadoop.streaming.TestStreaming.testCommandLine(TestStreaming.java:123)</pre>
    </div></div>
    
        This test was flaky due to trying to write some data into /bin/ls.
        Depending on the speed of the test run, this sometimes resulted
        in a Broken Pipe on flush() which caused the test to fail.
    
    Reason: Bugfix (race condition in test)
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:52:45 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ae699cda01c093097ae723224553773247577aa2:
    HDFS-961. dfs_readdir incorrectly parses paths
    
    Description: fuse-dfs dfs_readdir assumes that DistributedFileSystem#listStatus returns Paths with the same scheme/authority as the dfs.name.dir used to connect. If NameNode.DEFAULT_PORT port is used listStatus returns Paths that have authorities without the port (see <a href="http://issues.apache.org/jira/browse/HDFS-960" title="DistributedFileSystem#makeQualified port inconsistency">HDFS-960</a>), which breaks the following code.
    
    <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
    <pre class="code-java"><span class="code-comment">// hack city: todo fix the below to something nicer and more maintainable but
    </span><span class="code-comment">// with good performance
    </span><span class="code-comment">// strip off the path but be careful <span class="code-keyword">if</span> the path is solely '/'
    </span><span class="code-comment">// NOTE - <span class="code-keyword">this</span> API started returning filenames as full dfs uris
    </span><span class="code-keyword">const</span> <span class="code-object">char</span> *<span class="code-keyword">const</span> str = info[i].mName + dfs-&gt;dfs_uri_len + path_len + ((path_len == 1 &amp;&amp; *path == '/') ? 0 : 1);</pre>
    </div></div>
    
    <p>Let's make the path parsing here more robust. listStatus returns normalized paths so we can find the start of the path by searching for the 3rd slash. A more long term solution is to have hdfsFileInfo maintain a path object or at least pointers to the relevant URI components.</p>
    Reason: bugfix
    Author: Eli Collins
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:52:32 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7f9f42b27b109eff6fafc6ee24526fcadaf68d69:
    MAPREDUCE-1467. Add a --verbose flag to Sqoop
    
    Description: Need a <tt>--verbose</tt> flag that sets the log4j level to DEBUG.
    Reason: Logging improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:52:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit db680058f5796fc41d61242d60bc86b1b25facf9:
    MAPREDUCE-1469. Sqoop should disable speculative execution in export
    
    Description: Concurrent writers of the same output shard may cause the database to try to insert duplicate primary keys concurrently. Not a good situation. Speculative execution should be forced off for this operation.
    Reason: Bugfix (race condition)
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:52:07 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a5ccc56a79fc53de5ff16c6cb996f41a4216c28d:
    MAPREDUCE-1341. Sqoop should have an option to create hive tables and skip the table import step
    
    Description: In case the client only needs to create tables in hive, it would be helpful if Sqoop had an optional parameter:
    
    <p>--hive-create-only</p>
    
    <p>which would omit the time consuming table import step, generate hive create table statements and run them.</p>
    
    <p>Also adds --hive-overwrite flag which allows overwriting of existing table definition.
    
    Reason: New feature
    Author: Leonid Furman
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:51:29 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bdf576aa69eeb56a954416f7c2fcbe0136f421bd:
    HADOOP-4012. Providing splitting support for bzip2 compressed files
    
    Description: Hadoop assumes that if the input data is compressed, it can not be split (mainly due to the limitation of many codecs that they need the whole input stream to decompress successfully).  So in such a case, Hadoop prepares only one split per compressed file, where the lower split limit is at 0 while the upper limit is the end of the file.  The consequence of this decision is that, one compress file goes to a single mapper. Although it circumvents the limitation of codecs (as mentioned above) but reduces the parallelism substantially, as it was possible otherwise in case of splitting.
    
    <p>BZip2 is a compression / De-Compression algorithm which does compression on blocks of data and later these compressed blocks can be decompressed independent of each other.  This is indeed an opportunity that instead of one BZip2 compressed file going to one mapper, we can process chunks of file in parallel.  The correctness criteria of such a processing is that for a bzip2 compressed file, each compressed block should be processed by only one mapper and ultimately all the blocks of the file should be processed.  (By processing we mean the actual utilization of that un-compressed data (coming out of the codecs) in a mapper).</p>
    
    <p>We are writing the code to implement this suggested functionality.  Although we have used bzip2 as an example, but we have tried to extend Hadoop's compression interfaces so that any other codecs with the same capability as that of bzip2, could easily use the splitting support.  The details of these changes will be posted when we submit the code.</p>
    Reason: New feature
    Author: Abdul Qadeer
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:51:16 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8e47288583fcdbdf649ddf3486bf201788e79202:
    MAPREDUCE-707. Provide a jobconf property for explicitly assigning a job to a pool
    
    Description: A common use case of the fair scheduler is to have one pool per user, but then to define some special pools for various production jobs, import jobs, etc. Therefore, it would be nice if jobs went by default to the pool of the user who submitted them, but there was a setting to explicitly place a job in another pool. Today, this can be achieved through a sort of trick in the JobConf:
    
    <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
    <pre class="code-java">&lt;property&gt;
      &lt;name&gt;mapred.fairscheduler.poolnameproperty&lt;/name&gt;
      &lt;value&gt;pool.name&lt;/value&gt;
    &lt;/property&gt;
    
    &lt;property&gt;
      &lt;name&gt;pool.name&lt;/name&gt;
      &lt;value&gt;${user.name}&lt;/value&gt;
    &lt;/property&gt;</pre>
    </div></div>
    
    <p>This JIRA proposes to add a property called mapred.fairscheduler.pool that allows a job to be placed directly into a pool, avoiding the need for this trick.</p>
    Reason: Configuration improvement
    Author: Alan Heirich
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:50:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 96e17e1e593b818a888c8dfc177b8fb36e514e8f:
    MAPREDUCE-967. (version 2) TaskTracker does not need to fully unjar job jars
    
    Description:
        This is a performance improvement for jobs that contain a large number of
        classes. The unpacking of these jars consumes a large amount of time, as
        does the resulting cleanup. This patch changes the classpath to simply
        include the jar itself, and only unpacks the lib/ directory out of the
        jar in order to add those dependencies to the classpath.
    
        Users who previously depended on this functionality for shipping non-code
        dependencies can use the undocumented configuration parameter
        "mapreduce.job.jar.unpack.pattern" to cause specific jar contents to be unpacked
    
        This new patch version fixes a streaming regression where the "-file" argument
        no longer worked. It includes a new unit test, TestFileArgs, to protect
        against this regression.
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:50:18 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cf08a128b87bbfae90babd61795599b3645d37a3:
    HDFS-455, MAPREDUCE-1441, HADOOP-6534. Allow spaces in between comma-separated elements in directory list configurations.
    
    Description: Make NN and DN handle in a intuitive way comma-separated configuration strings
    
    The following configuration causes problems:<br/>
    &lt;property&gt;<br/>
    &lt;name&gt;dfs.data.dir&lt;/name&gt;<br/>
    &lt;value&gt;/mnt/hstore2/hdfs, /home/foo/dfs&lt;/value&gt; <br/>
    &lt;/property&gt;
    
    <p>The problem is that the space after the comma causes the second directory for storage to be " /home/foo/dfs" which is in a directory named &lt;SPACE&gt; which contains a sub-dir named "home" in the hadoop datanodes default directory. This will typically cause the user's home partition to fill, but will be very hard for the user to understand since a directory with a whitespace name is hard to understand.</p>
    
    <p>(ripped from <a href="http://issues.apache.org/jira/browse/HADOOP-2366" title="Space in the value for dfs.data.dir can cause great problems"><del>HADOOP-2366</del></a>)</p>
    
    <hr/>
    This fixes any configuration consisting of a comma-separated list of directories
    (e.g., dfs.data.dir, dfs.name.dir, fs.checkpoint.dir, mapred.local.dir, etc) so that
    the elements may also contain separating whitespace. Without this patch,
    setting mapred.local.dir to "/disk1, /disk2" would create a directory by the name
    " " in the user's home directory, or fail outright. The patch trims the
    directory
    names as they are fetched from the configuration.
    
    Reason: Configuration improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:48:40 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 65a04ab8197a8db21a97d279ca881b5cd45a5365:
    HADOOP-2366. Space in the value for dfs.data.dir can cause great problems
    
    Description: The following configuration causes problems:
    
    <p>&lt;property&gt;<br/>
      &lt;name&gt;dfs.data.dir&lt;/name&gt;<br/>
      &lt;value&gt;/mnt/hstore2/hdfs, /home/foo/dfs&lt;/value&gt;  <br/>
      &lt;description&gt;<br/>
      Determines where on the local filesystem an DFS data node  should store its bl<br/>
    ocks.  If this is a comma-delimited  list of directories, then data will be stor<br/>
    ed in all named  directories, typically on different devices.  Directories that <br/>
    do not exist are ignored.  <br/>
      &lt;/description&gt;<br/>
    &lt;/property&gt;</p>
    
    <p>The problem is that the space after the comma causes the second directory for storage to be " /home/foo/dfs" which is in a directory named &lt;SPACE&gt; which contains a sub-dir named "home" in the hadoop datanodes default directory.  This will typically cause the user's home partition to fill, but will be very hard for the user to understand since a directory with a whitespace name is hard to understand.</p>
    
    <p>My proposed solution would be to trimLeft all path names from this and similar property after splitting on comma.  This still allows spaces in file and directory names but avoids this problem. </p>
    <hr/>
        This provides support in Configuration to get comma-separated string lists in such
        a way that whitespace in between elements is ignored. This patch is required for
        later patches which fix mapred.local.dir, dfs.data.dir, etc to support spaces
        in between elements.
    
        Test plan: unit tested in TestStringUtils
    Reason: Configuration improvement
    Author: Michele (@pirroh) Catasta
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:48:03 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8d4807322a42509726b376b37a89739acd6cbd7d:
    MAPREDUCE-1356. Allow user-specified hive table name in sqoop
    
    Description: The table name used in a hive-destination import is currently pegged to the input table name. This should be user-configurable.
    Reason: New feature
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:47:55 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8bf3439ff69762a33967dca4abb15c0cd2bb8417:
    MAPREDUCE-1395. Sqoop does not check return value of Job.waitForCompletion()
    
    Description: Old code depended on JobClient.runJob() throwing IOException on failure. Job.waitForCompletion can fail in that manner, or it can fail by returning false. Sqoop needs to check for this condition.
    Reason: bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:47:45 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bd4e81234dd12fa9534577f0caa0db5c3d0a99fc:
    CLOUDERA-BUILD. Set HADOOP_PID_DIR to something smarter than /tmp
    
    Author: Chad Metcalf
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:47:30 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2466310d0e2a426e848860e9a8411b8ea14e1bb1:
    HADOOP-6453. Hadoop wrapper script shouldn't ignore an existing JAVA_LIBRARY_PATH
    
    Description: Currently the hadoop wrapper script assumes its the only place that uses JAVA_LIBRARY_PATH and initializes it to a blank line.
    
    <p>JAVA_LIBRARY_PATH=''</p>
    
    <p>This prevents anyone from setting this outside of the hadoop wrapper (say hadoop-config.sh) for their own native libraries.</p>
    
    <p>The fix is pretty simple. Don't initialize it to '' and append the native libs like normal. </p>
    Reason: Bugfix (environment)
    Author: Chad Metcalf
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:47:07 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a67b4b1c361c26e002da64953a7f8bc068d29b98:
    MAPREDUCE-1327. Oracle database import via sqoop fails when a table contains the column types such as TIMESTAMP(6) WITH LOCAL TIME ZONE and TIMESTAMP(6) WITH TIME ZONE
    
    Description: When Oracle table contains the columns "TIMESTAMP(6) WITH LOCAL TIME ZONE" and "TIMESTAMP(6) WITH TIME ZONE", Sqoop fails to map values for those columns to valid Java data types, resulting in the following exception:
    
    <p>ERROR sqoop.Sqoop: Got exception running Sqoop: java.lang.NullPointerException<br/>
    java.lang.NullPointerException<br/>
            at org.apache.hadoop.sqoop.orm.ClassWriter.generateFields(ClassWriter.java:253)<br/>
            at org.apache.hadoop.sqoop.orm.ClassWriter.generateClassForColumns(ClassWriter.java:701)<br/>
            at org.apache.hadoop.sqoop.orm.ClassWriter.generate(ClassWriter.java:597)<br/>
            at org.apache.hadoop.sqoop.Sqoop.generateORM(Sqoop.java:75)<br/>
            at org.apache.hadoop.sqoop.Sqoop.importTable(Sqoop.java:87)<br/>
            at org.apache.hadoop.sqoop.Sqoop.run(Sqoop.java:175)<br/>
            at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)<br/>
            at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)<br/>
            at org.apache.hadoop.sqoop.Sqoop.main(Sqoop.java:201)<br/>
            at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br/>
            at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)</p>
    
    Reason: Compatibility improvement
    Author: Leonid Furman
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:46:42 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a937ba2b9b6132883d727f856911ae31d22ad619:
    MAPREDUCE-1394. Sqoop generates incorrect URIs in paths sent to Hive
    
    Description: Hive used to require a ':8020' in HDFS URIs used with LOAD DATA statements, even though the normalized form of such a URI does not contain an explicit port number (since 8020 is the default port). Sqoop matched this by hacking the URI strings it forwarded to Hive.
    
    <p>Hive fixed this bug a while ago &#8211; Sqoop should catch up.</p>
    Reason: bugfix (compatibility)
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:46:26 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c5c9b8bf0bf83637589a809b3c376cf74a2fb464:
    MAPREDUCE-1313. NPE in FieldFormatter if escape character is set and field is null
    
    Description: Performing an import with the <tt>&#45;&#45;escaped-by</tt> character set on a table with a null field will cause a NullPointerException in FieldFormatter
    Reason: bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:45:54 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1c6dd471832946929928801dd9c9e4b79259ad9d:
    HADOOP-6460. Namenode runs of out of memory due to memory leak in ipc Server
    
    Description: Namenode heap usage grows disproportional to the number objects supports (files, directories and blocks). Based on heap dump analysis, this is due to large growth in ByteArrayOutputStream allocated in o.a.h.ipc.Server.Handler.run().
    Reason: Bugfix (Scalability)
    Author: Suresh Srinivas
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:45:38 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d190a8067827ce09cdcb7741d588cce0e0e7aa02:
    HADOOP-5687. Hadoop NameNode throws NPE if fs.default.name is the default value
    
    Description: Throwing NPE is confusing; instead, an exception with a useful string description could be thrown instead.
    Reason: Logging improvement
    Author: Philip Zeyliger
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:45:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7604c6f69076effbb0c9793e114946d679f5912d:
    HADOOP-6505. sed in build.xml fails
    
    Description: I'm not sure whether this is a Solaris thing or an ant 1.7.1 thing, but it definitely doesn't do what it is supposed to.  Instead of getting SunOS-x86-32 (or whatever) I get -x86-32.
    
    <p>This patch replaces the sed call with tr. </p>
    Reason: OS compatibility improvement
    Author: Allen Wittenauer
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:45:02 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ca662cbba6044be216b586e7359d9fc2f1dd4e4f:
    HDFS-908. (version 2) TestDistributedFileSystem fails with Wrong FS on weird hosts
    
    Description: On the same host where I experienced <a href="http://issues.apache.org/jira/browse/HDFS-874" title="TestHDFSFileContextMainOperations fails on weirdly configured DNS hosts">HDFS-874</a>, I also experience this failure for TestDistributedFileSystem:
    
    <p>Testcase: testFileChecksum took 0.492 sec<br/>
      Caused an ERROR<br/>
    Wrong FS: hftp://localhost.localdomain:59782/filechecksum/foo0, expected: hftp://127.0.0.1:59782<br/>
    java.lang.IllegalArgumentException: Wrong FS: hftp://localhost.localdomain:59782/filechecksum/foo0, expected: hftp://127.0.0.1:59782<br/>
      at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:310)<br/>
      at org.apache.hadoop.fs.FileSystem.makeQualified(FileSystem.java:222)<br/>
      at org.apache.hadoop.hdfs.HftpFileSystem.getFileChecksum(HftpFileSystem.java:318)<br/>
      at org.apache.hadoop.hdfs.TestDistributedFileSystem.testFileChecksum(TestDistributedFileSystem.java:166)</p>
    
    <p>Doesn't appear to occur on trunk or branch-0.21.</p>
    
    This is version two of this patch. THe previous patch fixed some systems
    but broke others.
    Reason: Bugfix
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:44:00 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7fafe032223921ad194c69b16ab451b4aade87fa:
    HADOOP-4368. Superuser privileges required to do "df"
    
    Description: super user privileges are required in DFS in order to get the file system statistics (FSNamesystem.java, getStats method).  This means that when HDFS is mounted via fuse-dfs as a non-root user, "df" is going to return 16exabytes total and 0 free instead of the correct amount.
    
    <p>As far as I can tell, there's no need to require super user privileges to see the file system size (and historically in Unix, this is not required).</p>
    
    <p>To fix this, simply comment out the privilege check in the getStats method.</p>
    Reason: Usability improvement
    Author: Craig Macdonald
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:43:41 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6129c87f5dd1fdb7375c80285534b8b91fbcd392:
    HDFS-412. Hadoop JMX usage makes Nagios monitoring impossible
    
    Description: When Hadoop reports Datanode information to JMX, the bean uses the name "DataNode-" + storageid.  The storage ID incorporates a random number and is unpredictable.
    
    <p>This prevents me from monitoring DFS datanodes through Hadoop using the JMX interface; in order to do that, you must be able to specify the bean name on the command line.</p>
    
    <p>The fix is simple, patch will be coming momentarily.  However, there was probably a reason for making the datanodes all unique names which I'm unaware of, so it'd be nice to hear from the metrics maintainer.</p>
    Reason: Monitoring improvement
    Author: Brian Bockelman
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:43:25 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5dfcc6d2d7806636c6237996e1b28a00ba075b4b:
    HADOOP-6503. contrib projects should pull in the ivy-fetched libs from the root project
    
    Description: On branch-20 currently, I get an error just running "ant contrib -Dtestcase=TestHdfsProxy". In a full "ant test" build sometimes this doesn't appear to be an issue. The problem is that the contrib projects don't automatically pull in the dependencies of the "Hadoop" ivy project. Thus, they each have to declare all of the common dependencies like commons-cli, etc. Some are missing and this causes test failures.
    Reason: Build system improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:43:05 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit be70b10f11445f4a71807405718bfeebd38ad924:
    MAPREDUCE-1155. Streaming tests swallow exceptions
    
    Description: Many of the streaming tests (including TestMultipleArchiveFiles) catch exceptions and print their stack trace rather than failing the job. This means that tests do not fail even when the job fails.
    Reason: Test coverage improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:42:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f84830ae5e6c862cd0e2b8ebea57880e54c8a082:
    HADOOP-5647. TestJobHistory fails if /tmp/_logs is not writable to. Testcase should not depend on /tmp
    
    Description: TestJobHistory sets /tmp as hadoop.job.history.user.location to check if the history file is created in that directory or not. If /tmp/_logs is already created by some other user, this test will fail because of not having write permission.
    Reason: Bugfix in test harness
    Author: Ravi Gummadi
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:42:33 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 669b65f14d78ffd1cf0304cf459d1abbae3412ae:
    CLOUDERA-BUILD. Fix javadoc warnings shown by test-patch, and update eclipse classpath to match current CDH.
    
    Author: Todd Lipcon
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:42:15 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 51804fd45d3a527a130a373c591a17c185102a0c:
    Revert "HDFS-127: DFSClient block read failures cause open DFSInputStream to become unusable"
    
    Description: This is being reverted as it causes infinite retries when there are no valid replicas.
    Reason: bugfix
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:41:40 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 623bfc0c18087274315dfbd41d025a8a775abe80:
    HDFS-877. Client-driven block verification not functioning
    
    Description: This is actually the reason for <a href="http://issues.apache.org/jira/browse/HDFS-734" title="TestDatanodeBlockScanner times out in branch 0.20"><del>HDFS-734</del></a> (TestDatanodeBlockScanner timing out). The issue is that DFSInputStream relies on readChunk being called one last time at the end of the file in order to receive the lastPacketInBlock=true packet from the DN. However, DFSInputStream.read checks pos &lt; getFileLength() before issuing the read. Thus gotEOS never shifts to true and checksumOk() is never called.
    
    This is a simpler patch than the one on 0.21/0.22 since those fix a further regression
    since 0.20.
    
    Reason: bugfix
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:40:30 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b332fe77255047409da701dfb97df1bddb5b10cb:
    CLOUDERA-BUILD. Add mockito to 0.20 branch for easier unit testing of HDFS stability patches.
    
    Reason: Test coverage improvement
    Author: Todd Lipcon
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:40:05 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 44a6c559de056b35c6eb2e2d53798c88d8c779e6:
    HDFS-630. In DFSOutputStream.nextBlockOutputStream(), the client can exclude specific datanodes when locating the next block.
    
    Description: created from hdfs-200.
    
    <p>If during a write, the dfsclient sees that a block replica location for a newly allocated block is not-connectable, it re-requests the NN to get a fresh set of replica locations of the block. It tries this dfs.client.block.write.retries times (default 3), sleeping 6 seconds between each retry ( see DFSClient.nextBlockOutputStream).</p>
    
    <p>This setting works well when you have a reasonable size cluster; if u have few datanodes in the cluster, every retry maybe pick the dead-datanode and the above logic bails out.</p>
    
    <p>Our solution: when getting block location from namenode, we give nn the excluded datanodes. The list of dead datanodes is only for one block allocation.</p>
    Reason: bugfix (Fault tolerance improvement)
    Author: Cosmin Lehene (modified by Cloudera to not break compatibility)
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:39:09 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 47c404e0cf10ceb31336d2a77d53e0a971348102:
    HDFS-908. TestDistributedFileSystem fails with Wrong FS on weird hosts
    
    Description: On the same host where I experienced <a href="http://issues.apache.org/jira/browse/HDFS-874" title="TestHDFSFileContextMainOperations fails on weirdly configured DNS hosts">HDFS-874</a>, I also experience this failure for TestDistributedFileSystem:
    
    <p>Testcase: testFileChecksum took 0.492 sec<br/>
      Caused an ERROR<br/>
    Wrong FS: hftp://localhost.localdomain:59782/filechecksum/foo0, expected: hftp://127.0.0.1:59782<br/>
    java.lang.IllegalArgumentException: Wrong FS: hftp://localhost.localdomain:59782/filechecksum/foo0, expected: hftp://127.0.0.1:59782<br/>
      at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:310)<br/>
      at org.apache.hadoop.fs.FileSystem.makeQualified(FileSystem.java:222)<br/>
      at org.apache.hadoop.hdfs.HftpFileSystem.getFileChecksum(HftpFileSystem.java:318)<br/>
      at org.apache.hadoop.hdfs.TestDistributedFileSystem.testFileChecksum(TestDistributedFileSystem.java:166)</p>
    
    <p>Doesn't appear to occur on trunk or branch-0.21.</p>
    Reason: bugfix
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:37:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7c2a791f0a397d924a623e45bf823c238374c42c:
    MAPREDUCE-1258. Fair scheduler event log not logging job info
    
    Description: The <a href="http://issues.apache.org/jira/browse/MAPREDUCE-706" title="Support for FIFO pools in the fair scheduler"><del>MAPREDUCE-706</del></a> patch seems to have left an unfinished TODO in the Fair Scheduler - namely, in the dump() function for periodically dumping scheduler state to the event log, the part that dumps information about jobs is commented out. This makes the event log less useful than it was before.
    
    <p>It should be fairly easy to update this part to use the new scheduler data structures (Schedulable etc) and print the data.</p>
    Reason: Logging improvement
    Author: Matei Zaharia
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:37:19 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 353f7813bf7dfb0bca1362f9370f6a080256a345:
    MAPREDUCE-1198. Alternatively schedule different types of tasks in fair share scheduler
    
    Description: Matei has mentioned in <a href="http://issues.apache.org/jira/browse/MAPREDUCE-961" title="ResourceAwareLoadManager to dynamically decide new tasks based on current CPU/memory load on TaskTracker(s)">MAPREDUCE-961</a> that the current scheduler will first try to launch map tasks until canLaunthTask() returns false then look for reduce tasks. This might starve reduce task. He also mention that alternatively schedule different types of tasks can solve this problem.
    Reason: bugfix
    Author: Scott Chen
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:36:58 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ef449fb7832055951e2364cf12a73717b2add3ce:
    MAPREDUCE-698. Per-pool task limits for the fair scheduler
    
    Description: The fair scheduler could use a way to cap the share of a given pool similar to <a href="http://issues.apache.org/jira/browse/MAPREDUCE-532" title="Allow admins of the Capacity Scheduler to set a hard-limit on the capacity of a queue"><del>MAPREDUCE-532</del></a>.
    Reason: New feature
    Author: Kevin Peterson
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:36:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a1e25ec70e677db322b2cce43c6381f865eb3f79:
    HDFS-464. Memory leaks in libhdfs
    
    Description: hdfsExists does not call destroyLocalReference for jPath anytime,<br/>
    hdfsDelete does not call it when it fails, and<br/>
    hdfsRename does not call it for jOldPath and jNewPath when it fails
    Reason: bugfix
    Author: Christian Kunz
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:36:42 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d93dad715d3c702d15c2a32c85d586c708e70857:
    CLOUDERA-BUILD. Add test ivy configurations to additional projects.
    
    Author: Aaron Kimball
    Reason: Build system improvement
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:36:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5d0c8f82b87e7cbb541ace9e4f22abfad2799e56:
    CLOUDERA-BUILD. Sqoop bin script now includes jars from contrib/sqoop/lib/ on classpath.
    
    Author: Aaron Kimball
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:35:08 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7e009a29c0806537cd50972df90ec87b617eb78f:
    MAPREDUCE-1212. Mapreduce contrib project ivy dependencies are not included in binary target
    
    Description: As in <a href="http://issues.apache.org/jira/browse/HADOOP-6370" title="Contrib project ivy dependencies are not included in binary target">HADOOP-6370</a>, only Hadoop's own library dependencies are promoted to ${build.dir}/lib; any libraries required by contribs are not redistributed.
    Reason: Build system (packaging) improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:34:54 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8d289f97d6b66cd435f755a4acae9f138de934d6:
    CLOUDERA-BUILD. Update cloud script version to cdh-0.20.1
    
    Author: Tom White
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:34:43 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ac7eacd44af059d7a859b8d6773a82cd84ba4c9b:
    HADOOP-6466. Add a ZooKeeper service to the cloud scripts
    
    Description: It would be good to add other Hadoop services to the cloud scripts.
    Reason: New feature
    Author: Tom White
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:34:35 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 06ceb079693292a41085af795c5b2bbc3fd10af2:
    HADOOP-6454. Create setup.py for EC2 cloud scripts
    
    Description: This would make it easier to install the scripts.
    Reason: Installation improvement
    Author: Tom White
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:34:24 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 23c45791bbc3a23d69c77f3518b5d1a1a4702ccc:
    HADOOP-6462. contrib/cloud failing, target "compile" does not exist
    
    Description: I'm not seeing this mentioned in hudson or other bugreports, which confuses me. With the addition of a src/contrib/cloud/build.xml from <a href="http://issues.apache.org/jira/browse/HADOOP-6426" title="Create ant build for running EC2 unit tests"><del>HADOOP-6426</del></a>, contrib/build.xml won't build no more: <br/>
    hadoop-common/src/contrib/build.xml:30: The following error occurred while executing this line:<br/>
    Target "compile" does not exist in the project "hadoop-cloud".
    
    <p>What is odd is this: the final patch of <a href="http://issues.apache.org/jira/browse/HADOOP-6426" title="Create ant build for running EC2 unit tests"><del>HADOOP-6426</del></a> does include the stub &lt;target&gt; files needed, yet they aren't in SVN_HEAD. Which implies that a different version may have gone in than intended. </p>
    Reason: Build system bugfix
    Author: Tom White
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:34:11 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 083a6a1cfb2a5198243aa82a020681ad62da5938:
    HADOOP-6444. Support additional security group option in hadoop-ec2 script
    
    Description: When deploying a hadoop cluster on ec2 alongside other services it is very useful to be able to specify additional (pre-existing) security groups to facilitate access control.  For example one could use this feature to add a cluster to a generic "hadoop" group, which authorizes hdfs access from instances outside the cluster.  Without such an option the access control for the security groups created by the script need to manually updated after cluster launch.
    Reason: Security improvement
    Author: Paul Egan
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:33:58 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 63152ce4ba3c0cf2006016cc825fc72b0bd23d2d:
    HADOOP-6426. Create ant build for running EC2 unit tests
    
    Description: There is no easy way currently to run the Python unit tests for the cloud contrib.
    Reason: Test coverage improvement
    Author: Tom White
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:33:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a20069b2adfafa59e0001fe5e5685d36d9eb7fee:
    HADOOP-6392. Run namenode and jobtracker on separate EC2 instances
    
    Description: Replace concept of "master" with that of "namenode" and "jobtracker". Still need to be able to run both on one node, of course.
    Reason: Scalability improvement
    Author: Tom White
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:33:15 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 361221a2a082d0ab7a87ba0226dbe05938440738:
    HADOOP-6108. Add support for EBS storage on EC2
    
    Description: By using EBS for namenode and datanode storage we can have persistent, restartable Hadoop clusters running on EC2.
    Reason: New feature
    Author: Tom White
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:33:07 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4ca1c78e1b257eefa10b5ed94479df8a6473d3e9:
    HDFS-861. fuse-dfs does not support O_RDWR
    
    Description: Some applications (for us, the big one is rsync) will open a file in read-write mode when it really only intends to read xor write (not both).  fuse-dfs should try to not fail until the application actually tries to write to a pre-existing file or read from a newly created file.
    Reason: bugfix
    Author: Brian Bockelman
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:32:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 00f6976093cc20ea825a35f6831f645dc5f61637:
    HDFS-860. fuse-dfs truncate behavior causes issues with scp
    
    Description: For whatever reason, scp issues a "truncate" once it's written a file to truncate the file to the # of bytes it has written (i.e., if a file is X bytes, it calls truncate(X)).
    
    <p>This fails on the current fuse-dfs.</p>
    Reason: bugfix (tool compatibility)
    Author: Brian Bockelman
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:32:17 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 46d2b6d6b27887375c44d691d776f70e89e4b81b:
    HDFS-859. fuse-dfs utime behavior causes issues with tar
    
    Description: When trying to untar files onto fuse-dfs, tar will try to set the utime on all the files and directories.  However, setting the utime on a directory in libhdfs causes an error.
    
    <p>We should silently ignore the failure of setting a utime on a directory; this will allow tar to complete successfully.</p>
    Reason: bugfix (tool compatibility)
    Author: Brian Bockelman
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:31:58 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9a38b9c423aca358307aa6455977432f34aef990:
    HDFS-858. Incorrect return codes for fuse-dfs
    
    Description: fuse-dfs doesn't pass proper error codes from libhdfs; places I'd like to correct are hdfsFileOpen (which can result in permission denied or quota violations) and hdfsWrite (which can result in quota violations).
    
    <p>By returning the correct error codes, command line utilities return much better error messages - especially for quota violations, which can be a devil to debug.</p>
    Reason: bugfix
    Author: Brian Bockelman
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:31:45 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 84afb26bb0e42eda1e26b07e3aac016695f5ad87:
    HDFS-857. Incorrect type for fuse-dfs capacity can cause "df" to return negative values on 32-bit machines
    
    Description: On sufficiently large HDFS installs, the casting of hdfsGetCapacity to a long may cause "df" to return negative values.  tOffset should be used instead.
    Reason: bugfix
    Author: Brian Bockelman
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:31:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a4cf3e8e86cbd42bef25eb3aab7e464ac86e3068:
    HDFS-856. Hardcoded replication level for new files in fuse-dfs
    
    Description: In fuse-dfs, the number of replicas is always hardcoded to 3 in the arguments to hdfsOpenFile.  We should use the setting in the hadoop configuration instead.
    Reason: Configuration improvement
    Author: Brian Bockelman
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:31:19 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e9f3ec90e57b383faf49e6a6eb8cc91e5182d31e:
    HADOOP-5625. Add I/O duration time in client trace
    
    Description: Add I/O duration information into client trace log for analyzing performance.
    
    Reason: Logging improvement
    Author: Lei Xu
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:31:08 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 42eeb4540850278563e76841f0c6b369933d5b70:
    HADOOP-5222. Add offset in client trace
    
    Description: By adding offset in client trace, the client trace information can provide more accurately information about I/O.<br/>
    It is useful for performance analyzing.
    
    <p>Since there is  no random write now, the offset of writing is always zero.</p>
    Reason: Logging improvement
    Author: Lei Xu
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:30:43 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5880960fb32ae0fc2c16bac1f333dbb237c3448f:
    CLOUDERA-BUILD. Solaris do-release-build fix
    
    Author: Eli Collins
    Ref: CDH-531
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:30:27 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 35f87aef6d7cd4030644a1d454da2e0a6e2969c0:
    MAPREDUCE-1310. CREATE TABLE statements for Hive do not correctly specify delimiters
    
    Description: Imports to HDFS via Sqoop that also inject metadata into Hive do not correctly specify delimiters; using Hive to access the data results in rows being parsed as NULL characters. See <span class="nobr"><a href="http://getsatisfaction.com/cloudera/topics/sqoop_hive_import_giving_null_query_values">http://getsatisfaction.com/cloudera/topics/sqoop_hive_import_giving_null_query_values<sup><img class="rendericon" src="https://issues.apache.org/jira/images/icons/linkext7.gif" height="7" width="7" align="absmiddle" alt="" border="0"/></sup></a></span> for an example bug report
    Reason: Bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:30:18 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 60784d712cdd5781ceff262bb67e2d484fde428b:
    MAPREDUCE-1235. java.io.IOException: Cannot convert value '0000-00-00 00:00:00' from column 6 to TIMESTAMP.
    
    Description: <b>Description</b>: java.io.IOException is thrown when trying to import a table to HDFS using Sqoop. Table has "0" value in a field of type datetime. <br/>
    <b>Full Exception</b>: java.io.IOException: Cannot convert value '0000-00-00 00:00:00' from column 6 to TIMESTAMP. <br/>
    <b>Original question</b>: <span class="nobr"><a href="http://getsatisfaction.com/cloudera/topics/cant_import_table?utm_content=reply_link&amp;utm_medium=email&amp;utm_source=reply_notification">http://getsatisfaction.com/cloudera/topics/cant_import_table?utm_content=reply_link&amp;utm_medium=email&amp;utm_source=reply_notification<sup><img class="rendericon" src="https://issues.apache.org/jira/images/icons/linkext7.gif" height="7" width="7" align="absmiddle" alt="" border="0"/></sup></a></span>
    Reason: Bugfix (compatibility)
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:29:56 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 23c116b6ab5615bdb846e22b61a41e92ca287bdf:
    MAPREDUCE-1174. Sqoop improperly handles table/column names which are reserved sql words
    
    Description: In some databases it is legal to name tables and columns with terms that overlap SQL reserved keywords (e.g., <tt>CREATE</tt>, <tt>table</tt>, etc.). In such cases, the database allows you to escape the table and column names. We should always escape table and column names when possible.
    Reason: Bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:29:47 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d4b3b7592c94aa1f4608245829b5de202ed1b148:
    MAPREDUCE-1168. Export data to databases via Sqoop
    
    Description: Sqoop can import from a database into HDFS. It's high time it works in reverse too.
    Reason: New feature
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:29:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b29023803d1136bf7d4de45853a2d4481fb36d3c:
    MAPREDUCE-1169. Improvements to mysqldump use in Sqoop
    
    Description: Improve Sqoop's integration with mysqldump
    Reason: Feature/performance improvements
    Author: Aaron Kimball
    Ref: UNKNOWN
    
    commit c6b956630e327ddabf674f8e06de02408e603155
    Author: Aaron Kimball <aaron@cloudera.com>
    Date:   Wed Jan 6 16:05:05 2010 -0800
    
        MAPREDUCE-1169. Improvements to mysqldump use in Sqoop
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:29:24 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 26ba4fd749755a3df79eaa27792662e5b7e3da80:
    MAPREDUCE-1036. An API Specification for Sqoop
    
    Description: Over the last several months, Sqoop has evolved to a state that is functional and has room for extensions. Developing extensions requires a stable API and documentation. I am attaching to this ticket a description of Sqoop's design and internal APIs, which include some open questions. I would like to solicit input on the design regarding these open questions and standardize the API.
    Reason: Documentation
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:29:15 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e8c47124bb2ada5de0cfdf49150dd7296a41df71:
    MAPREDUCE-1069. Implement Sqoop API refactoring
    
    Description: Implement refactoring decisions outlined in <a href="http://issues.apache.org/jira/browse/MAPREDUCE-1036" title="An API Specification for Sqoop"><del>MAPREDUCE-1036</del></a>
    Reason: API compatibility
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:29:04 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b73cab8083c1594c0328a565eef05951a17f998a:
    MAPREDUCE-1146. Sqoop dependencies break Eclipse build on Linux
    
    Description: Under  Linux there's the error in the Eclipse "Problems" view:
    <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent">
    <pre>- "com.sun.tools cannot be resolved" at line 166 of  org.apache.hadoop.sqoop.orm.CompilationManager
    </pre>
    </div></div>
    <p>The problem doesn't appear on MacOS though</p>
    Reason: bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:28:46 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0629ac30abb5e58fb80be56a385867ac7360de22:
    MAPREDUCE-1148. SQL identifiers are a superset of Java identifiers
    
    Description: SQL identifiers can contain arbitrary characters, can start with numbers, can be words like <tt>class</tt> which are reserved in Java, etc. If Sqoop uses these names literally for class and field names then compilation errors can occur in auto-generated classes. SQL identifiers need to be cleansed to map onto Java identifiers.
    Reason: bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:28:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit dec4c616921b547e5a332a254254d77efc3a7d5e:
    MAPREDUCE-1224. Calling "SELECT t.* from <table> AS t" to get meta information is too expensive for big tables
    
    Description: The SqlManager uses the query, "SELECT t.* from &lt;table&gt; AS t" to get table spec is too expensive for big tables, and it was called twice to generate column names and types.  For tables that are big enough to be map-reduced, this is too expensive to make sqoop useful.
    Reason: Performance improvement
    Author: Spencer Ho
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:28:25 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1198ef1375387ba107d46f0ab5e9a7c6a7645931:
    MAPREDUCE-706. Support for FIFO pools in the fair scheduler
    
    Description: The fair scheduler should support making the internal scheduling algorithm for some pools be FIFO instead of fair sharing in order to work better for batch workloads. FIFO pools will behave exactly like the current default scheduler, sorting jobs by priority and then submission time. Pools will have their scheduling algorithm set through the pools config file, and it will be changeable at runtime.
    
    <p>To support this feature, I'm also changing the internal logic of the fair scheduler to no longer use deficits. Instead, for fair sharing, we will assign tasks to the job farthest below its share as a ratio of its share. This is easier to combine with other scheduling algorithms and leads to a more stable sharing situation, avoiding unfairness issues brought up in <a href="http://issues.apache.org/jira/browse/MAPREDUCE-543" title="large pending jobs hog resources"><del>MAPREDUCE-543</del></a> and <a href="http://issues.apache.org/jira/browse/MAPREDUCE-544" title="deficit computation is biased by historical load">MAPREDUCE-544</a> that happen when some jobs have long tasks. The new preemption (<a href="http://issues.apache.org/jira/browse/MAPREDUCE-551" title="Add preemption to the fair scheduler"><del>MAPREDUCE-551</del></a>) will ensure that critical jobs can gain their fair share within a bounded amount of time.</p>
    Reason: New feature
    Author: Matei Zaharia
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:28:15 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5699f5483e2a9ee9debd0f0154c6506ee5dc87e2:
    MAPREDUCE-1285. DistCp cannot handle -delete if destination is local filesystem
    
    Description: The following exception is thrown:
    <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
    <pre class="code-java">Copy failed: java.io.IOException: wrong value class: org.apache.hadoop.fs.RawLocalFileSystem$RawLocalFileStatus is not class org.apache.hadoop.fs.FileStatus
    	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:988)
    	at org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:977)
    	at org.apache.hadoop.tools.DistCp.deleteNonexisting(DistCp.java:1226)
    	at org.apache.hadoop.tools.DistCp.setup(DistCp.java:1134)
    	at org.apache.hadoop.tools.DistCp.copy(DistCp.java:650)
    	at org.apache.hadoop.tools.DistCp.run(DistCp.java:857)
    	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)
    	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)</pre>
    </div></div>
    Reason: bugfix
    Author: Peter Romianowski
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:28:03 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 34bb813a5884aeb05909c2ce2cc541882ca3eda1:
    MAPREDUCE-764. TypedBytesInput's readRaw() does not preserve custom type codes
    
    Description: The typed bytes format supports byte sequences of the form <tt>&lt;custom type code&gt; &lt;length&gt; &lt;bytes&gt;</tt>. When reading such a sequence via <tt>TypedBytesInput</tt>'s <tt>readRaw()</tt> method, however, the returned sequence currently is <tt>0 &lt;length&gt; &lt;bytes&gt;</tt> (0 is the type code for a bytes array), which leads to bugs such as the one described <span class="nobr"><a href="http://dumbo.assembla.com/spaces/dumbo/tickets/54">here<sup><img class="rendericon" src="https://issues.apache.org/jira/images/icons/linkext7.gif" height="7" width="7" align="absmiddle" alt="" border="0"/></sup></a></span>.
    Reason: bugfix
    Author: Klaas Bosteels
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:27:53 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7fd2cb371354219abd108fda35087f08dc481b35:
    HADOOP-6400. Log errors getting Unix UGI
    
    Description: For various reasons, the calls out to `whoami` and `id` can fail when trying to get the unix UGI information. Currently it silently ignores failures and uses the default DrWho/Tardis ugi. This is extremely confusing for users - we should log the exception at warn level when the shell execs fail.
    Reason: Debug logging improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:27:31 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d6dc22fecc058e12695a481fa354078d9b012089:
    MAPREDUCE-1293. AutoInputFormat doesn't work with non-default FileSystems
    
    Description: AutoInputFormat uses the wrong FileSystem.get() method when getting a reference to a FileSystem object. AutoInputFormat gets the default FileSystem, so this method breaks if the InputSplit's path is pointing to a different FileSystem.
    Reason: bugfix
    Author: Andrew Hitchcock
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:27:21 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 25a4ea86b0b085e3afd6f2f040201594155b3de1:
    MAPREDUCE-1131. Using profilers other than hprof can cause JobClient to report job failure
    
    Description: If task profiling is enabled, the JobClient will download the <tt>profile.out</tt> file created by the tasks under profile. If this causes an IOException, the job is reported as a failure to the client, even though all the tasks themselves may complete successfully. The expected result files are assumed to be generated by hprof. Using the profiling system with other profilers will cause job failure.
    Reason: compatibility bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:27:09 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ab98123c7114752945452af0b96c8de04af9ba93:
    MAPREDUCE-370. Change org.apache.hadoop.mapred.lib.MultipleOutputs to use new api.
    
    Description: Ports the MultipleOutputs OutputFormat to the new context-based API.
    Reason: API compatibility improvement.
    Author: Amareshwari Sriramadasu
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:26:02 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 50726d13750f3f71d2fc5d3a012ce81aa2adb26d:
    CLOUDERA-BUILD. Backport MapReduceTestUtil to Hadoop 0.20
    
    Description: MapReduceTestUtil is required for unit tests in subsequent
    patches, but this class itself was not created in one clean JIRA. Therefore
    it was backported "As-is" from the trunk and not in a patch-wise fashion.
    This class is only used in the JUnit tests for Hadoop.
    Author: Aaron Kimball
    Reason: Testing improvement
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:24:46 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d713dc1063afc4967381b6583ec424d2850bac63:
    MAPREDUCE-1059. distcp can generate uneven map task assignments
    
    Description: distcp writes out a SequenceFile containing the source files to transfer, and their sizes. Map tasks are created over spans of this file, representing files which each mapper should transfer. In practice, some transfer loads yield many empty map tasks and a few tasks perform the bulk of the work.
    Reason: Improvement for load balancing
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:24:30 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 855b0bf3718f2c397ef79967475468e4153f120a:
    MAPREDUCE-1128. MRUnit Allows Iteration Twice
    
    Description: MRUnit allows one to iterate over a collection of values twice (ie.
    
    <p>reduce(Key key, Iterable&lt;Value&gt; values, Context context){
       for(Value : values ) /* iterate once */;
       for(Value : values ) /* iterate again */;
    }</p>
    
    <p>Hadoop will allow this as well, however the second iterator will be empty. MRUnit should either match hadoop's behavior or warn the user that their code is likely flawed.</p>
    Reason: bugfix (API compatibility)
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:24:20 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c9d77f6e1fdbb24b45675e363e3bd5111533893a:
    HDFS-464. Memory leaks in libhdfs
    
    Description: hdfsExists does not call destroyLocalReference for jPath anytime,<br/>
    hdfsDelete does not call it when it fails, and<br/>
    hdfsRename does not call it for jOldPath and jNewPath when it fails
    Reason: bugfix
    Author: Christian Kunz
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:24:10 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c7996c5e2fbb9260740fec369550551d6320762a:
    HDFS-423. Unbreak FUSE build and fuse_dfs_wrapper.sh
    
    Description: fuse-dfs depends on libhdfs, and fuse-dfs build.xml still points to the libhfds/libhdfs.so location but libhdfs now is build in a different location <br/>
    please take a look at this bug for the location details
    
    <p><span class="nobr"><a href="https://issues.apache.org/jira/browse/HADOOP-3344">https://issues.apache.org/jira/browse/HADOOP-3344<sup><img class="rendericon" src="https://issues.apache.org/jira/images/icons/linkext7.gif" height="7" width="7" align="absmiddle" alt="" border="0"/></sup></a></span></p>
    
    <p>Thanks,<br/>
    Giri</p>
    Reason: Build system bugfix
    Author: Eli Collins
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:23:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 72b0b791cd347e760807a44f5197599f57afde03:
    CLOUDERA-BUILD. Make bin/hadoop-config.sh work with dev builds
    
    Author: Eli Collins
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:23:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a9466041ccfcdb07f4f0dd34a57c9e9bdd6a3e70:
    HDFS-727. bug setting block size hdfsOpenFile
    
    Description: In hdfsOpenFile in libhdfs invokeMethod needs to cast the block size argument to a jlong so a full 8 bytes are passed (rather than 4 plus some garbage which causes writes to fail due to a bogus block size).
    
    Reason: Bugfix
    Author: Eli Collins
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:23:06 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4e7d205daa86d904614252101bb422664ab6d203:
    Revert MAPREDUCE-967. TaskTracker does not need to fully unjar job jars
    
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:22:47 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d5f0c77a6c81e9e56da81976645614280247f7a2:
    HADOOP-5640. Allow ServicePlugins to hook callbacks into key service events
    
    Description: <a href="http://issues.apache.org/jira/browse/HADOOP-5257" title="Export namenode/datanode functionality through a pluggable RPC layer"><del>HADOOP-5257</del></a> added the ability for NameNode and DataNode to start and stop ServicePlugin implementations at NN/DN start/stop. However, this is insufficient integration for some common use cases.
    
    <p>We should add some functionality for Plugins to subscribe to events generated by the service they're plugging into. Some potential hook points are:</p>
    
    <p>NameNode:</p>
    <ul class="alternate" type="square">
    	<li>new datanode registered</li>
    	<li>datanode has died</li>
    	<li>exception caught</li>
    	<li>etc?</li>
    </ul>
    
    <p>DataNode:</p>
    <ul class="alternate" type="square">
    	<li>startup</li>
    	<li>initial registration with NN complete (this is important for HADOOP-4707 to sync up datanode.dnRegistration.name with the NN-side registration)</li>
    	<li>namenode reconnect</li>
    	<li>some block transfer hooks?</li>
    	<li>exception caught</li>
    </ul>
    
    <p>I see two potential routes for implementation:</p>
    
    <p>1) We make an enum for the types of hookpoints and have a general function in the ServicePlugin interface. Something like:</p>
    
    <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
    <pre class="code-java"><span class="code-keyword">enum</span> HookPoint {
      DN_STARTUP,
      DN_RECEIVED_NEW_BLOCK,
      DN_CAUGHT_EXCEPTION,
     ...
    }
    
    void runHook(HookPoint hp, <span class="code-object">Object</span> value);</pre>
    </div></div>
    
    <p>2) We make classes specific to each "pluggable" as was originally suggested in HADDOP-5257. Something like:</p>
    
    <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
    <pre class="code-java">class DataNodePlugin {
      void datanodeStarted() {}
      void receivedNewBlock(block info, etc) {}
      void caughtException(Exception e) {}
      ...
    }</pre>
    </div></div>
    
    <p>I personally prefer option (2) since we can ensure plugin API compatibility at compile-time, and we avoid an ugly switch statement in a runHook() function.</p>
    
    <p>Interested to hear what people's thoughts are here.</p>
    
    HADOOP-5640 puts this in the new test dir. It needs to be in the old one.
    
    Reason: Improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:22:18 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e9b04609d88ed5d1af442ee950aa5dcd6646e830:
    MAPREDUCE-1017. Compression and output splitting for Sqoop
    
    Description: Sqoop "direct mode" writing will generate a single large text file in HDFS. It is important to be able to compress this data before it reaches HDFS. Due to the difficulty in splitting compressed files in HDFS for use by MapReduce jobs, data should also be split at compression time.
    Reason: New feature
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:22:08 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8c9b473e1af036a3e2cc9036a945a4567277db8a:
    HADOOP-6312. Configuration sends too much data to log4j
    
    Description: Configuration objects send a DEBUG-level log message every time they're instantiated, which include a full stack trace. This is more appropriate for TRACE-level logging, as it renders other debug logs very hard to read.
    Reason: Logging improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:21:14 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 698fe169f31e54111d30e4420cd1c1c5eaeecdec:
    HDFS-686. NullPointerException is thrown while merging edit log and image
    
    Description: Our secondary name node is not able to start on NullPointerException:<br/>
    ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: java.lang.NullPointerException<br/>
            at org.apache.hadoop.hdfs.server.namenode.FSDirectory.unprotectedSetTimes(FSDirectory.java:1232)<br/>
            at org.apache.hadoop.hdfs.server.namenode.FSDirectory.unprotectedSetTimes(FSDirectory.java:1221)<br/>
            at org.apache.hadoop.hdfs.server.namenode.FSEditLog.loadFSEdits(FSEditLog.java:776)<br/>
            at org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSEdits(FSImage.java:992)<br/>
            at<br/>
    org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.doMerge(SecondaryNameNode.java:590)<br/>
            at<br/>
    org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$CheckpointStorage.access$000(SecondaryNameNode.java:473)<br/>
            at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doMerge(SecondaryNameNode.java:350)<br/>
            at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:314)<br/>
            at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:225)<br/>
            at java.lang.Thread.run(Thread.java:619)
    
    <p>This was caused by setting access time on a non-existent file.</p>
    Reason: bugfix
    Author: Hairong Kuang
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:21:03 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b2cc8e02f37a1604bb076acefff0ebf016c249d5:
    MAPREDUCE-112. Reduce Input Records and Reduce Output Records counters are not being set when using the new Mapreduce reducer API
    
    Description: After running the examples/wordcount (which uses the new API), the reduce input and output record counters always show 0. This is because these counters are not getting updated in the new API
    This adds counters for reduce input, output records to the new API.
    Reason: Bugfix
    Author: Jothi Padmanabhan
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:20:40 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3e62477434542dc3de89fd43fd9b19abaf76f0de:
    MAPREDUCE-768. Configuration information should generate dump in a standard format.
    
    Description:  We need to generate the configuration dump in a standard format .
    This adds the 'hadoop jobtracker -dumpConfiguration' command.
    This is modified from the original patch in that it does not dump QueueManager configuration.
    This is because we have not backported HADOOP-5396
    
    Reason: New feature
    Author: V.V.Chaitanya Krishna
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:20:00 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4d9333b00772455a1ca7a365fa5b5b2f6872abd7:
    HADOOP-6184. Provide a configuration dump in json format.
    
    Description: Configuration dump in json format.
    Reason: New feature
    Author: V.V.Chaitanya Krishna
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:19:46 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 96244c3e7d6735f450b618fdcbdbbf9a81436ba3:
    CLOUDERA-BUILD. Duplicated effort. FULL_VERSION already set in package.mk
    
    Description: Revert "Need to pass in FULL_VERSION"
    Author: Chad Metcalf
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:19:27 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 604d3a71334b9340a6219e3b88bf563b79f5d083:
    CLOUDERA-BUILD. Copy the sqoop manpage to the expected version number
    
    Author: Chad Metcalf
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:19:11 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6d428f70591a92a90dca5256968c62a510659240:
    CLOUDERA-BUILD. Bump jdiff stable to 0.20.1
    
    Author: Chad Metcalf
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:18:58 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 46ffc9aa9260a96bdf67fbaee9a2acd76cfcf675:
    CLOUDERA-BUILD. Need to pass in FULL_VERSION
    
    Author: Chad Metcalf
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:18:44 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit aa7ae9d9826866f94ecfe5629d087ef68e4b5c54:
    MAPREDUCE-999. Improve Sqoop test speed and refactor tests
    
    Description: Sqoop's tests take a long time to run, but this can be improved (by a factor of 2 or more) by taking advantage of <tt>jobclient.completion.poll.interval</tt>.
    Reason: Testing performance improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:18:29 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 084c390ed5fcb03c456121c8497759b40a74f809:
    MAPREDUCE-1089. Fair Scheduler preemption triggers NPE when tasks are scheduled but not running
    
    Description: We see exceptions like this when preemption runs when a task has been scheduled on a TT but has not yet started running.
    
    <p>2009-10-09 14:30:53,989 INFO org.apache.hadoop.mapred.FairScheduler: Should preempt 2 MAP tasks for job_200910091420_0006: tasksDueToMinShare = 2, tasksDueToFairShare = 0<br/>
    2009-10-09 14:30:54,036 ERROR org.apache.hadoop.mapred.FairScheduler: Exception in fair scheduler UpdateThread<br/>
    java.lang.NullPointerException<br/>
            at org.apache.hadoop.mapred.FairScheduler$2.compare(FairScheduler.java:1015)<br/>
            at org.apache.hadoop.mapred.FairScheduler$2.compare(FairScheduler.java:1013)<br/>
            at java.util.Arrays.mergeSort(Arrays.java:1270)<br/>
            at java.util.Arrays.sort(Arrays.java:1210)<br/>
            at java.util.Collections.sort(Collections.java:159)<br/>
            at org.apache.hadoop.mapred.FairScheduler.preemptTasks(FairScheduler.java:1013)<br/>
            at org.apache.hadoop.mapred.FairScheduler.preemptTasksIfNecessary(FairScheduler.java:911)<br/>
            at org.apache.hadoop.mapred.FairScheduler$UpdateThread.run(FairScheduler.java:286)</p>
    Reason: Bugfix
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:18:13 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 34ca2a5547398f9435a5d3d22603d0f7da420226:
    MAPREDUCE-551. Add preemption to the fair scheduler
    
    Description: Task preemption is necessary in a multi-user Hadoop cluster for two reasons: users might submit long-running tasks by mistake (e.g. an infinite loop in a map program), or tasks may be long due to having to process large amounts of data. The Fair Scheduler (<a href="http://issues.apache.org/jira/browse/HADOOP-3746" title="A fair sharing job scheduler"><del>HADOOP-3746</del></a>) has a concept of guaranteed capacity for certain queues, as well as a goal of providing good performance for interactive jobs on average through fair sharing. Therefore, it will support preempting under two conditions:<br/>
    1) A job isn't getting its <em>guaranteed</em> share of the cluster for at least T1 seconds.<br/>
    2) A job is getting significantly less than its <em>fair</em> share for T2 seconds (e.g. less than half its share).
    
    <p>T1 will be chosen smaller than T2 (and will be configurable per queue) to meet guarantees quickly. T2 is meant as a last resort in case non-critical jobs in queues with no guaranteed capacity are being starved.</p>
    
    <p>When deciding which tasks to kill to make room for the job, we will use the following heuristics:</p>
    <ul class="alternate" type="square">
    	<li>Look for tasks to kill only in jobs that have more than their fair share, ordering these by deficit (most overscheduled jobs first).</li>
    	<li>For maps: kill tasks that have run for the least amount of time (limiting wasted time).</li>
    	<li>For reduces: similar to maps, but give extra preference for reduces in the copy phase where there is not much map output per task (at Facebook, we have observed this to be the main time we need preemption - when a job has a long map phase and its reducers are mostly sitting idle and filling up slots).</li>
    </ul>
    
    This fixes an error in the previous backport where the
    EagerTaskInitializationListener wasn't properly passed the
    TaskTrackerManager before starting.
    
    Reason: New feature
    Author: Matei Zaharia
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:17:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a3e29eff0b9337a1007ec1b90ccb832dca5c1d20:
    CLOUDERA-BUILD. Fix hadoop wrapper to properly pass through multiword quoted arguments
    
    Author: Todd Lipcon
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:17:33 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 975647b6c3a6644cabbd48bf14e074a0efda2cb9:
    CLOUDERA-BUILD. Sqoop documentation is now part of the generated tarball. Updated the install script to reflect that change.
    
    Author: Matt Massie
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:17:15 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 19c038a6af07e3999e83a2178d2328535e00dedb:
    CLOUDERA-BUILD. Generate the sqoop documentation and ensure that it's in the release tarball
    
    Author: Matt Massie
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:16:55 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6957626991875302f33bb73630f4f376412f9711:
    CLOUDERA-BUILD. More changes to get debs building correctly
    
    Author: Chad Metcalf
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:16:43 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 67d1c732cea0eebf59de512301ae8f2a1cb2f349:
    CLOUDERA-BUILD. Reformatted Sqoop manpage asciidoc for CDH build process
    
    Author: Aaron Kimball
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:16:30 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit af158d6aa7ffe72d931bc4763ace7d4a299d077b:
    CLOUDERA-BUILD. Only rerun libtoolize if version 2.2 is installed
    
    Author: Todd Lipcon
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:16:14 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 586992381042e1b4ec8c9ece069561ad2e4dfcc0:
    HADOOP-6279. Add JVM memory usage to JvmMetrics
    
    Description: The JvmMetrics currently publish memory usage from the MemoryMXBean. This is useful, but doesn't include the total heap size (eg as displayed in the JT Web UI).
    
    <p>It would be nice to expose Runtime.getRuntime().maxMemory() as part of JvmMetrics.</p>
    
    <p>It seems that Runtime.getRuntime().totalMemory() (used by the JT for "memory used") is the same as the 'memHeapCommittedM' which already exists.</p>
    Reason: Metrics improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:15:42 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7c168a8a2613d93e19508a91e7c4db3b3cfb503b:
    HADOOP-6269. Missing synchronization for defaultResources in Configuration.addResource
    
    Description: Configuration.defaultResources is a simple ArrayList. In two places in Configuration it is accessed without appropriate synchronization, which we've seen to occasionally result in ConcurrentModificationExceptions.
    Reason: bugfix (race condition)
    Author: Sreekanth Ramakrishnan
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:15:26 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8bf845170decdcb12254bc1dc98ccbf0fda7d233:
    CLOUDERA-BUILD. Recreate c++ configure files during build if we have the right build dependencies
    
    Author: Todd Lipcon
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:15:01 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e7e9812fa7a6a256652f2f6bbb269334f883c53b:
    CLOUDERA-BUILD. Package sqoop docs w/o requiring asciidoc
    
    Author: Chad Metcalf
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:14:43 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7171eabfad501d635b1da9e0287f50e025b4a83f:
    CLOUDERA-BUILD. Revert "Package sqoop docs."
    
    Description: This reverts packaging of sqoop documentation in preparation
    for including MAPREDUCE-906 properly after it has been committed
    to Apache.
    Author: Chad Metcalf
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:13:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4bd437c9d70f2c0d68047e0376a7af21cc4a70e0:
    HADOOP-5891. If dfs.http.address is default, SecondaryNameNode can't find NameNode
    
    Description: As detailed in this blog post:<br/>
    <span class="nobr"><a href="http://www.cloudera.com/blog/2009/02/10/multi-host-secondarynamenode-configuration/">http://www.cloudera.com/blog/2009/02/10/multi-host-secondarynamenode-configuration/<sup><img class="rendericon" src="https://issues.apache.org/jira/images/icons/linkext7.gif" height="7" width="7" align="absmiddle" alt="" border="0"/></sup></a></span><br/>
    if dfs.http.address is not configured, and the 2NN is a different machine from the NN, the 2NN fails to connect.
    
    <p>In SecondaryNameNode.getInfoServer, the 2NN should notice a "0.0.0.0" dfs.http.address and, in that case, pull the hostname out of fs.default.name. This would fix the default configuration to work properly for most users.</p>
    Reason: Configuration improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:13:17 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 74e10e4a137b2aa60ab39186115350b5e82464fc:
    HDFS-127. DFSClient block read failures cause open DFSInputStream to become unusable
    
    Description: We are using some Lucene indexes directly from HDFS and for quite long time we were using Hadoop version 0.15.3.
    
    <p>When tried to upgrade to Hadoop 0.19 - index searches started to fail with exceptions like:<br/>
    2008-11-13 16:50:20,314 WARN <span class="error">&#91;Listener-4&#93;</span> [] DFSClient : DFS Read: java.io.IOException: Could not obtain block: blk_5604690829708125511_15489 file=/usr/collarity/data/urls-new/part-00000/20081110-163426/_0.tis<br/>
    at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.chooseDataNode(DFSClient.java:1708)<br/>
    at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.blockSeekTo(DFSClient.java:1536)<br/>
    at org.apache.hadoop.hdfs.DFSClient$DFSInputStream.read(DFSClient.java:1663)<br/>
    at java.io.DataInputStream.read(DataInputStream.java:132)<br/>
    at org.apache.nutch.indexer.FsDirectory$DfsIndexInput.readInternal(FsDirectory.java:174)<br/>
    at org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:152)<br/>
    at org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:38)<br/>
    at org.apache.lucene.store.IndexInput.readVInt(IndexInput.java:76)<br/>
    at org.apache.lucene.index.TermBuffer.read(TermBuffer.java:63)<br/>
    at org.apache.lucene.index.SegmentTermEnum.next(SegmentTermEnum.java:131)<br/>
    at org.apache.lucene.index.SegmentTermEnum.scanTo(SegmentTermEnum.java:162)<br/>
    at org.apache.lucene.index.TermInfosReader.scanEnum(TermInfosReader.java:223)<br/>
    at org.apache.lucene.index.TermInfosReader.get(TermInfosReader.java:217)<br/>
    at org.apache.lucene.index.SegmentTermDocs.seek(SegmentTermDocs.java:54) <br/>
    ...</p>
    
    <p>The investigation showed that the root of this issue is that we exceeded # of xcievers in the data nodes and that was fixed by changing configuration settings to 2k.<br/>
    However - one thing that bothered me was that even after datanodes recovered from overload and most of client servers had been shut down - we still observed errors in the logs of running servers.<br/>
    Further investigation showed that fix for <a href="http://issues.apache.org/jira/browse/HADOOP-1911" title="infinite loop in dfs -cat command."><del>HADOOP-1911</del></a> introduced another problem - the DFSInputStream instance might become unusable once number of failures over lifetime of this instance exceeds configured threshold.</p>
    
    <p>The fix for this specific issue seems to be trivial - just reset failure counter before reading next block (patch will be attached shortly).</p>
    
    <p>This seems to be also related to HADOOP-3185, but I'm not sure I really understand necessity of keeping track of failed block accesses in the DFS client.</p>
    
        HADOOP-4681: Also referenced
    
        This as-yet-uncommitted patch is recommended by HBase people.
        Applied patch "4681.patch" attached to the JIRA on 2008-11-18.
    
    Reason: Bugfix
    Author: Igor Bolotin
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:11:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ca547d89042fff3a38c0c93b6e0ece78e74ae064:
    HADOOP-4655. FileSystem.CACHE should be ref-counted
    
    Description: FileSystem.CACHE is not ref-counted, and could lead to resource leakage.
    Adds new method FileSystem.newInstance() that always returns a newly allocated
    FileSystem object.
    Reason: Bugfix
    Author: dhruba borthakur
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:11:10 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 15660507606b32c3c6c2878f8ed69fe106119bc9:
    MAPREDUCE-967. TaskTracker does not need to fully unjar job jars
    
    Description: In practice we have seen some users submitting job jars that consist of 10,000+ classes. Unpacking these jars into mapred.local.dir and then cleaning up after them has a significant cost (both in wall clock and in unnecessary heavy disk utilization). This cost can be easily avoided
    Reason: Performance improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:10:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 648e30e074a16de837fb4c604a198bc780c2e6c5:
    MAPREDUCE-968. NPE in distcp encountered when placing _logs directory on S3FileSystem
    
    Description: If distcp is pointed to an empty S3 bucket as the destination for an s3:// filesystem transfer, it will fail with the following exception
    
    <p>Copy failed: java.lang.NullPointerException<br/>
    at org.apache.hadoop.fs.s3.S3FileSystem.makeAbsolute(S3FileSystem.java:121)<br/>
    at org.apache.hadoop.fs.s3.S3FileSystem.getFileStatus(S3FileSystem.java:332)<br/>
    at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:633)<br/>
    at org.apache.hadoop.tools.DistCp.setup(DistCp.java:1005)<br/>
    at org.apache.hadoop.tools.DistCp.copy(DistCp.java:650)<br/>
    at org.apache.hadoop.tools.DistCp.run(DistCp.java:857)<br/>
    at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)<br/>
    at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)<br/>
    at org.apache.hadoop.tools.DistCp.main(DistCp.java:884) </p>
    Reason: Bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:10:34 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a61718b87c36dbeddcc6f9917438f81ebdda0214:
    HADOOP-6133. ReflectionUtils performance regression
    
    Description: <a href="http://issues.apache.org/jira/browse/HADOOP-4187" title="Create a MapReduce-specific ReflectionUtils that handles JobConf and JobConfigurable"><del>HADOOP-4187</del></a> introduced extra calls to Class.forName in ReflectionUtils.setConf. This caused a fairly large performance regression. Attached is a microbenchmark that shows the following timings (ms) for 100M constructions of new instances:
    
    <p>Explicit construction (new Test): around ~1.6sec<br/>
    Using Test.class.newInstance: around ~2.6sec<br/>
    ReflectionUtils on 0.18.3: ~8.0sec<br/>
    ReflectionUtils on 0.20.0: ~200sec</p>
    
    <p>This illustrates the ~80x slowdown caused by <a href="http://issues.apache.org/jira/browse/HADOOP-4187" title="Create a MapReduce-specific ReflectionUtils that handles JobConf and JobConfigurable"><del>HADOOP-4187</del></a>.</p>
    Reason: Performance improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
    commit 5e299f831420ed52569eefc5ba815359a0ebc64e
    Author: Chad Metcalf <chad@cloudera.com>
    Date:   Tue Sep 15 22:21:42 2009 -0700
    
        HADOOP-6133: ReflectionUtils performance regression
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:10:22 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b6f790774d34ed34bb7c649142dc770c25121ac3:
    HADOOP-5981. HADOOP-2838 doesnt work as expected
    
    Description: The substitution feature i.e X=$X:/tmp doesnt work as expected.
    
    <p>This issue completes the feature mentioned in <a href="http://issues.apache.org/jira/browse/HADOOP-2838" title="Add HADOOP_LIBRARY_PATH config setting so Hadoop will include external directories for jni"><del>HADOOP-2838</del></a>. <a href="http://issues.apache.org/jira/browse/HADOOP-2838" title="Add HADOOP_LIBRARY_PATH config setting so Hadoop will include external directories for jni"><del>HADOOP-2838</del></a> provided a way to set env variables in child process. This issue provides a way to inherit tt's env variables and append or reset it. So now <br/>
    X=$X:y will inherit X (if  there) and append y to it. </p>
    Reason: Bugfix
    Author: Amar Kamat
    Ref: UNKNOWN
    
    commit eb635e4de3a8b2b5bd9f34225770f24be42dcd83
    Author: Chad Metcalf <chad@cloudera.com>
    Date:   Tue Sep 15 22:29:50 2009 -0700
    
        HADOOP-5981: HADOOP-2838 doesnt work as expected
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:10:13 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5d4e93d8e0df3c445f56c5eb51965eef92bebd78:
    HADOOP-2838. Add HADOOP_LIBRARY_PATH config setting so Hadoop will include external directories for jni
    
    Description: Currently there is no way to configure Hadoop to use external JNI directories. I propose we add a new variable like HADOOP_CLASS_PATH that is added to the JAVA_LIBRARY_PATH before the process is run.
    
    <p>Now the users can set environment variables using mapred.child.env. They can do the following <br/>
    X=Y : set X to Y<br/>
    X=$X:Y : Append Y to X (which should be taken from the tasktracker)</p>
    Reason: Improves job launch flexibility
    Author: Amar Kamat
    Ref: UNKNOWN
    
    commit 9b3fc32fa793b338dc700a7f6c437402f80d6b7f
    Author: Chad Metcalf <chad@cloudera.com>
    Date:   Tue Sep 15 22:09:57 2009 -0700
    
        HADOOP-2838: Add HADOOP_LIBRARY_PATH config setting so Hadoop will include external directories for jni
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:09:46 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 877429c3f94a1e937fbe29b4cbe8da573831d802:
    MAPREDUCE-814. Move completed Job history files to HDFS
    
    Description: Currently completed job history files remain on the jobtracker node. Having the files available on HDFS will enable clients to access these files more easily.
    Reason: New feature
    Author: Sharad Agarwal
    Ref: UNKNOWN
    
    commit c0575c0908fee4ec01f5bc0abbd7f4b2254dd38e
    Author: Chad Metcalf <chad@cloudera.com>
    Date:   Tue Sep 15 18:15:17 2009 -0700
    
        MAPREDUCE-814: Move completed Job history files to HDFS
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:09:31 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a8bf06eac5312ede0982118801e4495285a442fe:
    MAPREDUCE-693. Conf files not moved to "done" subdirectory after JT restart
    
    Description: After <a href="http://issues.apache.org/jira/browse/MAPREDUCE-516" title="Fix the 'cluster drain' problem in the Capacity Scheduler wrt High RAM Jobs"><del>MAPREDUCE-516</del></a>, when a job is submitted and the JT is restarted (before job files have been written) and the job is killed after recovery, the conf files fail to be moved to the "done" subdirectory.<br/>
    The exact scenario to reproduce this issue is:
    <ul>
    	<li>Submit a job</li>
    	<li>Restart JT before anything is written to the job files</li>
    	<li>Kill the job</li>
    	<li>The old conf files remain in the history folder and fail to be moved to "done" subdirectory</li>
    </ul>
    
    Reason: bugfix
    Author: Amar Kamat
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:08:12 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cc22e9f92db6470d244fb17f57601b93bab6db80:
    MAPREDUCE-683. TestJobTrackerRestart fails with Map task completion events ordering mismatch
    
    Description: <tt>TestJobTrackerRestart</tt> fails consistently with Map task completion events ordering mismatch error.
    Reason: bugfix
    Author: Amar Kamat
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:07:55 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 57a67dff5d15e3833c7968254df076e440de2765:
    MAPREDUCE-416. Move the completed jobs' history files to a DONE subdirectory inside the configured history directory
    
    Description: Whenever a job completes, the history file can be moved to a directory called DONE. That would make the management of job history files easier (for example, administrators can move the history files from that directory to some other place, delete them, archive them, etc.).
    Reason: System management improvement
    Author: Amar Kamat
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:07:39 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 99dfdb9a98e1ebd643f47877be3541962c32dcd0:
    HADOOP-5733. Add map/reduce slot capacity and lost map/reduce slot capacity to JobTracker metrics
    
    Description: It would be nice to have the actual map/reduce slot capacity and the lost map/reduce slot capacity (# of blacklisted nodes * map-slot-per-node or reduce-slot-per-node). This information can be used to calculate a JT view of slot utilization.
    Reason: Metrics improvement
    Author: Sreekanth Ramakrishnan
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:07:18 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 955fe9433b13f21079f92e4035393b683486ad07:
    HADOOP-5738. Split waiting tasks field in JobTracker metrics to individual tasks
    
    Description: Currently, job tracker metrics reports waiting tasks as a single field in metrics. It would be better if we can split waiting tasks into maps and reduces.
    Reason: User experience improvement
    Author: Sreekanth Ramakrishnan
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:05:59 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3b8f77cd452c1098c6af5907b787bf9167df806b:
    HADOOP-5442. The job history display needs to be paged
    
    Description: Currently the list of job history will try to render the entire list of jobs that have run. That doesn't scale up as more and more jobs run on a job tracker.
    Reason: Scalability improvement
    Author: Amar Kamat
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:05:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit dfac0482267aaf0fabac97c163e0015306ec5b16:
    HADOOP-4842. Streaming combiner should allow command, not just JavaClass
    
    Description: Streaming jobs are way slower than Java jobs for many reasons, but certainly stopping the shell-only programmer from using the combiner feature won't help. Right now, the streaming usage says:
    
    <blockquote>
    <p>  -mapper   &lt;cmd|JavaClassName&gt;      The streaming command to run<br/>
      -combiner &lt;JavaClassName&gt; Combiner has to be a Java class<br/>
      -reducer  &lt;cmd|JavaClassName&gt;      The streaming command to run</p></blockquote>
    Reason: Usability improvement
    Author: Amareshwari Sriramadasu
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:05:16 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 33e4f0a87effa466914e292488c47977245edc96:
    MAPREDUCE-987. Exposing MiniDFS and MiniMR clusters as a single process command-line
    
    Description: It's hard to test non-Java programs that rely on significant mapreduce functionality.  The patch I'm proposing shortly will let you just type "bin/hadoop jar hadoop-hdfs-hdfswithmr-test.jar minicluster" to start a cluster (internally, it's using Mini{MR,HDFS}Cluster) with a specified number of daemons, etc.  A test that checks how some external process interacts with Hadoop might start minicluster as a subprocess, run through its thing, and then simply kill the java subprocess.
    
    <p>I've been using just such a system for a couple of weeks, and I like it.  It's significantly easier than developing a lot of scripts to start a pseudo-distributed cluster, and then clean up after it.  I figure others might find it useful as well.</p>
    
    <p>I'm at a bit of a loss as to where to put it in 0.21.  hdfs-with-mr tests have all the required libraries, so I've put it there.  I could conceivably split this into "minimr" and "minihdfs", but it's specifically the fact that they're configured to talk to each other that I like about having them together.  And one JVM is better than two for my test programs.</p>
    Reason: Testing feature
    Author: Philip Zeyliger
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:04:06 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 39ff7e5ee285df97c765a73271066df718be0e30:
    HADOOP-6267. build-contrib.xml unnecessarily enforces that contrib projects be located in contrib/ dir
    
    Description: build-contrib.xml currently sets hadoop.root to ${basedir}/../../../. This path is relative to the contrib project which is assumed to be inside src/contrib/. We occasionally work on contrib projects in other repositories until they're ready to contribute. We can use the &lt;dirname&gt; ant task to do this more correctly.
    Reason: Build system improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 17:03:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 139bea6660193cc73852832e03fe570437343e96:
    HDFS-528. Add ability for safemode to wait for a minimum number of live datanodes
    
    Description: When starting up a fresh cluster programatically, users often want to wait until DFS is "writable" before continuing in a script. "dfsadmin -safemode wait" doesn't quite work for this on a completely fresh cluster, since when there are 0 blocks on the system, 100% of them are accounted for before any DNs have reported.
    
    <p>This JIRA is to add a command which waits until a certain number of DNs have reported as alive to the NN.</p>
    Reason: New feature
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 15:02:55 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b301746d45bde2759535549f87c6485f4ee577b2:
    HADOOP-4936. Improvements to TestSafeMode
    
    Description: TestSafeMode
    <ul class="alternate" type="square">
    	<li>needs a detailed description of the test case</li>
    	<li>should not use direct calls to the name-node rather call <tt>DistributedFileSystem</tt> methods.</li>
    </ul>
    
    Reason: Test coverage improvement
    Author: Konstantin Shvachko
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 15:02:38 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f04a321596a513e71354f2a6829b44e474077507:
    HADOOP-5650. Namenode log that indicates why it is not leaving safemode may be confusing
    
    Description: A namenode with a large number of datablocks is setup with dfs.safemode.threshold.pct set to 1.0. With a small number of unreported blocks, namenode prints the following as the reason for not leaving safe mode:<br/>
    <tt>The ratio of reported blocks 1.0000 has not reached the threshold 1.0000</tt>
    
    <p>With a large number of blocks, precision used for printing the log may not indicate the difference between the actual ratio of safe blocks to total blocks and the configured threshold. Printing number of blocks instead of ratio will improve the clarity.</p>
    Reason: User experience improvement
    Author: Suresh Srinivas
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 15:02:22 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 13e35e654c51a5b1cfe809ef1e2c4d2ca46ed612:
    HADOOP-4675. Current Ganglia metrics implementation is incompatible with Ganglia 3.1
    
    Description: Ganglia changed its wire protocol in the 3.1.x series; the current implementation only works for 3.0.x.
    
    Patched using
    https://issues.apache.org/jira/secure/attachment/12407207/HADOOP-4675-v7.patch
    
    Reason: Compatibility improvement
    Author: Brian Bockelman
    Ref: UNKNOWN
    
    commit dcf76896b1c8a7b891995b1546eef6ea3018e7ca
    Author: Philip Zeyliger <philip@cloudera.com>
    Date:   Tue Jul 28 15:28:18 2009 -0700
    
        HADOOP-4675. Current Ganglia metrics implementation is incompatible with Ganglia 3.1
    
        Patched using
        https://issues.apache.org/jira/secure/attachment/12407207/HADOOP-4675-v7.patch
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 15:01:52 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4305750d026b895b3afbd0d4a4ee4b3b42596016:
    HADOOP-6269. Missing synchronization for defaultResources in Configuration.addResource
    
    Description: Configuration.defaultResources is a simple ArrayList. In two places in Configuration it is accessed without appropriate synchronization, which we've seen to occasionally result in ConcurrentModificationExceptions.
    Reason: Bugfix (race condition)
    Author: Sreekanth Ramakrishnan
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 15:01:29 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 90f9c40df18fe464383de52e3d3952638a393e34:
    CLOUDERA-BUILD. Make some JT methods and classes public for use from within contrib plugins
    
    Author: Henry Robinson
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 15:01:08 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f8e0599a434e1ce94158384f575e912e9f988229:
    MAPREDUCE-461. Enable ServicePlugins for the JobTracker
    
    Description: Allow ServicePlugins (see <a href="http://issues.apache.org/jira/browse/HADOOP-5257" title="Export namenode/datanode functionality through a pluggable RPC layer"><del>HADOOP-5257</del></a>) for the JobTracker.
    (Relies on HADOOP-5640)
    Reason: API Improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:59:40 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c58318cfa6e26b7dbacd4093d646fc8b66f9eda6:
    HADOOP-5640. Allow ServicePlugins to hook callbacks into key service events
    
    Description: <a href="http://issues.apache.org/jira/browse/HADOOP-5257" title="Export namenode/datanode functionality through a pluggable RPC layer"><del>HADOOP-5257</del></a> added the ability for NameNode and DataNode to start and stop ServicePlugin implementations at NN/DN start/stop. However, this is insufficient integration for some common use cases.
    
    <p>We should add some functionality for Plugins to subscribe to events generated by the service they're plugging into. Some potential hook points are:</p>
    
    <p>NameNode:</p>
    <ul class="alternate" type="square">
    	<li>new datanode registered</li>
    	<li>datanode has died</li>
    	<li>exception caught</li>
    	<li>etc?</li>
    </ul>
    
    <p>DataNode:</p>
    <ul class="alternate" type="square">
    	<li>startup</li>
    	<li>initial registration with NN complete (this is important for HADOOP-4707 to sync up datanode.dnRegistration.name with the NN-side registration)</li>
    	<li>namenode reconnect</li>
    	<li>some block transfer hooks?</li>
    	<li>exception caught</li>
    </ul>
    
    <p>I see two potential routes for implementation:</p>
    
    <p>1) We make an enum for the types of hookpoints and have a general function in the ServicePlugin interface. Something like:</p>
    
    <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
    <pre class="code-java"><span class="code-keyword">enum</span> HookPoint {
      DN_STARTUP,
      DN_RECEIVED_NEW_BLOCK,
      DN_CAUGHT_EXCEPTION,
     ...
    }
    
    void runHook(HookPoint hp, <span class="code-object">Object</span> value);</pre>
    </div></div>
    
    <p>2) We make classes specific to each "pluggable" as was originally suggested in HADDOP-5257. Something like:</p>
    
    <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
    <pre class="code-java">class DataNodePlugin {
      void datanodeStarted() {}
      void receivedNewBlock(block info, etc) {}
      void caughtException(Exception e) {}
      ...
    }</pre>
    </div></div>
    
    <p>I personally prefer option (2) since we can ensure plugin API compatibility at compile-time, and we avoid an ugly switch statement in a runHook() function.</p>
    
    <p>Interested to hear what people's thoughts are here.</p>
    Reason: API Improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:58:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 137999a0b48a81bed10a5f30868dbfe6d176956b:
    HADOOP-5257. Export namenode/datanode functionality through a pluggable RPC layer
    
    Description: Adding support for pluggable components would allow exporting DFS functionallity using arbitrary protocols, like Thirft or Protocol Buffers. I'm opening this issue on Dhruba's suggestion in HADOOP-4707.
    
    <p>Plug-in implementations would extend this base class:</p>
    
    <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
    <pre class="code-java"><span class="code-keyword">abstract</span> class Plugin {
    
        <span class="code-keyword">public</span> <span class="code-keyword">abstract</span> datanodeStarted(DataNode datanode);
    
        <span class="code-keyword">public</span> <span class="code-keyword">abstract</span> datanodeStopping();
    
        <span class="code-keyword">public</span> <span class="code-keyword">abstract</span> namenodeStarted(NameNode namenode);
    
        <span class="code-keyword">public</span> <span class="code-keyword">abstract</span> namenodeStopping();
    }</pre>
    </div></div>
    
    <p>Name node instances would then start the plug-ins according to a configuration object, and would also shut them down when the node goes down:</p>
    
    <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent">
    <pre class="code-java"><span class="code-keyword">public</span> class NameNode {
    
        <span class="code-comment">// [..]
    </span>
        <span class="code-keyword">private</span> void initialize(Configuration conf)
            <span class="code-comment">// [...]
    </span>        <span class="code-keyword">for</span> (Plugin p: PluginManager.loadPlugins(conf))
              p.namenodeStarted(<span class="code-keyword">this</span>);
        }
    
        <span class="code-comment">// [..]
    </span>
        <span class="code-keyword">public</span> void stop() {
            <span class="code-keyword">if</span> (stopRequested)
                <span class="code-keyword">return</span>;
            stopRequested = <span class="code-keyword">true</span>;
            <span class="code-keyword">for</span> (Plugin p: plugins)
                p.namenodeStopping();
            <span class="code-comment">// [..]
    </span>    }
    
        <span class="code-comment">// [..]
    </span>}</pre>
    </div></div>
    
    <p>Data nodes would do a similar thing in <tt>DataNode.startDatanode()</tt> and <tt>DataNode.shutdown</tt></p>
    Reason: MISSING: Reason for inclusion
    Author: Carlos Valiente
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:58:09 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 155394ca5eed2e2a6151a5c9d9452e9cfbb30a11:
    MAPREDUCE-971. distcp does not always remove distcp.tmp.dir
    
    Description: Sometimes distcp leaves behind its tmpdir when the target filesystem is s3n.
    Reason: Bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:57:58 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7575b83ba0cab30394bad0943ff906ab0609dc40:
    CLOUDERA-BUILD. Package sqoop docs.
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:57:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9321b18352e55d4d37c25335b578151b18f938f2:
    MAPREDUCE-923. Sqoop's ORM uses URLDecoder on a file, which replaces plus signs in a jar file name with spaces
    
    Description: In findThisJar, sqoop runs URLDecoder.decode on the resulting jar, which has the effect of replacing any + signs in the path with a space.  This obviously breaks the classpath variable that it's trying to set, and the sqoop-generated code fails to compile.  Ironically, Cloudera's hadoop distro is the one that puts + characters in jar files, and so exhibits the bug.  Here is an example from running sqoop with log4j at debug level.  Note the space in the very last term, which should read hadoop-0.20.0+61-sqoop.jar rather than hadoop-0.20.0 61-sqoop.jar.
    
    <p>09/08/27 18:00:07 DEBUG orm.CompilationManager: Invoking javac with args: -sourcepath ./ -d /tmp/sqoop/compile/ -classpath /usr/lib/hadoop-0.20/conf:/usr/java/jdk1.6.0_06/lib/tools.jar:/usr/lib/hadoop-0.20:/usr/lib/hadoop-0.20/hadoop-0.20.0+61-core.jar:/usr/lib/hadoop-0.20/lib/commons-cli-2.0-SNAPSHOT.jar:/usr/lib/hadoop-0.20/lib/commons-codec-1.3.jar:/usr/lib/hadoop-0.20/lib/commons-el-1.0.jar:/usr/lib/hadoop-0.20/lib/commons-httpclient-3.0.1.jar:/usr/lib/hadoop-0.20/lib/commons-logging-1.0.4.jar:/usr/lib/hadoop-0.20/lib/commons-logging-api-1.0.4.jar:/usr/lib/hadoop-0.20/lib/commons-net-1.4.1.jar:/usr/lib/hadoop-0.20/lib/core-3.1.1.jar:/usr/lib/hadoop-0.20/lib/hadoop-0.20.0+61-fairscheduler.jar:/usr/lib/hadoop-0.20/lib/hadoop-0.20.0+61-scribe-log4j.jar:/usr/lib/hadoop-0.20/lib/hsqldb-1.8.0.10.jar:/usr/lib/hadoop-0.20/lib/hsqldb.jar:/usr/lib/hadoop-0.20/lib/jasper-compiler-5.5.12.jar:/usr/lib/hadoop-0.20/lib/jasper-runtime-5.5.12.jar:/usr/lib/hadoop-0.20/lib/jets3t-0.6.1.jar:/usr/lib/hadoop-0.20/lib/jetty-6.1.14.jar:/usr/lib/hadoop-0.20/lib/jetty-util-6.1.14.jar:/usr/lib/hadoop-0.20/lib/junit-3.8.1.jar:/usr/lib/hadoop-0.20/lib/junit-4.5.jar:/usr/lib/hadoop-0.20/lib/kfs-0.2.2.jar:/usr/lib/hadoop-0.20/lib/libfb303.jar:/usr/lib/hadoop-0.20/lib/libthrift.jar:/usr/lib/hadoop-0.20/lib/log4j-1.2.15.jar:/usr/lib/hadoop-0.20/lib/mysql-connector-java-5.0.8-bin.jar:/usr/lib/hadoop-0.20/lib/oro-2.0.8.jar:/usr/lib/hadoop-0.20/lib/servlet-api-2.5-6.1.14.jar:/usr/lib/hadoop-0.20/lib/slf4j-api-1.4.3.jar:/usr/lib/hadoop-0.20/lib/slf4j-log4j12-1.4.3.jar:/usr/lib/hadoop-0.20/lib/xmlenc-0.52.jar:/usr/lib/hadoop-0.20/lib/jsp-2.1/jsp-2.1.jar:/usr/lib/hadoop-0.20/lib/jsp-2.1/jsp-api-2.1.jar:/usr/local/hadoop/lib/hadoop-gpl-compression.jar:/usr/lib/hadoop-0.20/hadoop-0.20.0+61-core.jar:/usr/lib/hadoop-0.20/contrib/sqoop/hadoop-0.20.0 61-sqoop.jar</p>
    Reason: Bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:57:32 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e97883c5b9c389f82a6447e4cb1678c0a0ed83ba:
    CLOUDERA-BUILD. Sqoop asciidoc syntax error
    
    Author: Aaron Kimball
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:57:19 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 520bda2edcb90dfe9461e16b96aa4a048d33ed7b:
    HADOOP-5450. Add support for application-specific typecodes to typed bytes
    
    Description: For serializing objects of types that are not supported by typed bytes serialization, applications might want to use a custom serialization format. Right now, typecode 0 has to be used for the bytes resulting from this custom serialization, which could lead to problems when deserializing the objects because the application cannot know if a byte sequence following typecode 0 is a customly serialized object or just a raw sequence of bytes. Therefore, a range of typecodes that are treated as aliases for 0 should be added, such that different typecodes can be used for application-specific purposes.
    Reason: New feature
    Author: Klaas Bosteels
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:57:11 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b30fc99332c4a444d275731dac4b4245115d65b2:
    HADOOP-1722. Make streaming to handle non-utf8 byte array
    
    Description: Right now, the streaming framework expects the output sof the steam process (mapper or reducer) are line <br/>
    oriented UTF-8 text. This limit makes it impossible to use those programs whose outputs may be non-UTF-8<br/>
     (international encoding, or maybe even binary data). Streaming can overcome this limit by introducing a simple<br/>
    encoding protocol. For example, it can allow the mapper/reducer to hexencode its keys/values, <br/>
    the framework decodes them in the Java side.<br/>
    This way, as long as the mapper/reducer executables follow this encoding protocol, <br/>
    they can output arabitary bytearray and the streaming framework can handle them.
    Reason: New feature
    Author: Klaas Bosteels
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:56:59 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 921c135653736bcc279700435358058762bc8f78:
    CLOUDERA-BUILD. More Sqoop documentation updates
    
    Author: Aaron Kimball
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:56:43 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit be7f1dc031e17dc4f53ebe76d27c1b9242105785:
    MAPREDUCE-840. DBInputFormat leaves open transaction
    
    Description: (Reapplied after HADOOP-4687)
    Reason: MISSING: Reason for inclusion
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:56:26 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 89a96d8fff80ac809dbda9582044a7c6b3986d16:
    MAPREDUCE-906. Updated Sqoop documentation
    
    Description: Provides the latest documentation for Sqoop, in both user-guide and manpage form. Built with asciidoc.
    Reason: Documentation
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:56:07 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 51f867aea0667d0191b730ea3abf114e75cafa4b:
    MAPREDUCE-907. Sqoop should use more intelligent splits
    
    Description: Sqoop should use the new split generation / InputFormat in <a href="http://issues.apache.org/jira/browse/MAPREDUCE-885" title="More efficient SQL queries for DBInputFormat"><del>MAPREDUCE-885</del></a>
    Reason: Performance / scalability improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:55:54 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 239df04415dba8d12c7d3fbf33c580d473202e94:
    MAPREDUCE-885. More efficient SQL queries for DBInputFormat
    
    Description: DBInputFormat generates InputSplits by counting the available rows in a table, and selecting subsections of the table via the "LIMIT" and "OFFSET" SQL keywords. These are only meaningful in an ordered context, so the query also includes an "ORDER BY" clause on an index column. The resulting queries are often inefficient and require full table scans. Actually using multiple mappers with these queries can lead to O(n^2) behavior in the database, where n is the number of splits. Attempting to use parallelism with these queries is counter-productive.
    
    <p>A better mechanism is to organize splits based on data values themselves, which can be performed in the WHERE clause, allowing for index range scans of tables, and can better exploit parallelism in the database.</p>
    Reason: Performance and scalability improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:55:28 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 23a0d1882c797160cc7b6fae99fc5e686aa30191:
    MAPREDUCE-938. Postgresql support for Sqoop
    
    Description: Sqoop should be able to import from postgresql databases.
    Reason: Compatability improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:55:16 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7b89feb34fafd2365f75ab744db9cb07a5443046:
    MAPREDUCE-876. Sqoop import of large tables can time out
    
    Description: Related to <a href="http://issues.apache.org/jira/browse/MAPREDUCE-875" title="Make DBRecordReader execute queries lazily"><del>MAPREDUCE-875</del></a>, Sqoop should use a background thread to ensure that progress is being reported while a database does external work for the MapReduce task.
    Reason: Scalability improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:55:05 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 61d4ef5175dca1859a1320f9e7cad1caeab5d982:
    MAPREDUCE-918. Test hsqldb server should be memory-only.
    
    Description: Sqoop launches a standalone hsqldb server for unit tests, but it currently writes its database to disk and uses a connect string of <tt>//localhost</tt>. If multiple test instances are running concurrently, one test server may serve to the other instance of the unit tests, causing race conditions.
    Reason: Bugfix in test harness
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:54:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1fc17ad34e8288b54503eeb15f788eb4e6a070dc:
    MAPREDUCE-875. Make DBRecordReader execute queries lazily
    
    Description: DBInputFormat's DBRecordReader executes the user's SQL query in the constructor. If the query is long-running, this can cause task timeout. The user is unable to spawn a background thread (e.g., in a MapRunnable) to inform Hadoop of on-going progress.
    Reason: Scalability improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:54:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 21fdb7a7fd501fd63e1a540c2b55cf410d057301:
    MAPREDUCE-825. JobClient completion poll interval of 5s causes slow tests in local mode
    
    Description: The JobClient.NetworkedJob.waitForCompletion() method polls for job completion every 5 seconds. When running a set of short tests in pseudo-distributed mode, this is unnecessarily slow and causes lots of wasted time. When bandwidth is not scarce, setting the poll interval to 100 ms results in a 4x speedup in some tests.  This interval should be parametrized to allow users to control the interval for testing purposes.
    Reason: Test performance improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:54:27 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f996b8a019bffefff183d7d688ccf95b8cb73de5:
    MAPREDUCE-750. Extensible ConnManager factory API
    
    Description: Sqoop uses the ConnFactory class to instantiate a ConnManager implementation based on the connect string and other arguments supplied by the user. This allows per-database logic to be encapsulated in different ConnManager instances, and dynamically chosen based on which database the user is actually importing from. But adding new ConnManager implementations requires modifying the source of a common ConnFactory class. An indirection layer should be used to delegate instantiation to a number of factory implementations which can be specified in the static configuration or at runtime.
    Reason: API flexibility improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:54:15 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 39bdff7bd3b83359884c90ae857d3f3144a94803:
    MAPREDUCE-749. Make Sqoop unit tests more Hudson-friendly
    
    Description: Hudson servers (other than Apache's) need to be able to run the sqoop unit tests which depend on thirdparty JDBC drivers / database implementations. The build.xml needs some refactoring to make this happen.
    Reason: Test coverage improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:54:04 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0ca54f2722206685d9e36fcbb2656d0ac1957311:
    MAPREDUCE-792. javac warnings in DBInputFormat
    
    Description: <a href="http://issues.apache.org/jira/browse/MAPREDUCE-716" title="org.apache.hadoop.mapred.lib.db.DBInputformat not working with oracle"><del>MAPREDUCE-716</del></a> introduces javac warnings
    Reason: Technical debt
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:53:47 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e39ae9d017e89e4df193b1f8075184320230499b:
    MAPREDUCE-716. org.apache.hadoop.mapred.lib.db.DBInputformat not working with oracle
    
    Description: Applied "trunk" version of the patch after incorporating
    HADOOP-4687's move of DBInputFormat-related files. (Prior patch was 0.20-branch
    specific)
    Reason: Branch compatibility improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:52:45 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 074e824f5d3d2f6ab862083e6eb4b0df8c881bfc:
    MAPREDUCE-910. MRUnit should support counters
    
    Description: incrCounter() is currently a dummy stub method in MRUnit that does nothing. Would be good for the mock reporter/context implementations to support counters.
    Reason: New feature
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:52:27 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b4b7c5d9b4cba84bc47f4a48074fd295d060ab35:
    MAPREDUCE-798. MRUnit should be able to test a succession of MapReduce passes
    
    Description: MRUnit can currently test that the inputs to a given (mapper, reducer) "job" produce certain outputs at the end of the reducer. It would be good to support more end-to-end tests of a series of MapReduce jobs that form a longer pipeline surrounding some data.
    Reason: New Feature
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:52:17 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 59677d22261974560117fa82e74d9a7f80f804d5:
    MAPREDUCE-800. MRUnit should support the new API
    
    Description: MRUnit's TestDriver implementations use the old org.apache.hadoop.mapred-based classes. TestDrivers and associated mock object implementations are required for org.apache.hadoop.mapreduce-based code.
    Reason: New feature (API Compatibility)
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:52:06 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7fda23b419b1c98e84eea43a0f35191d41032e18:
    MAPREDUCE-799. Some of MRUnit's self-tests were not being run
    
    Description: Due to method naming issues, some test cases were not being executed.
    Reason: Bugfix; test coverage
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:51:53 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 20d5bf205e9f2864f3da53d30408ba97763a46e9:
    MAPREDUCE-797. MRUnit MapReduceDriver should support combiners
    
    Description: The MapReduceDriver allows you to specify a mapper and a reducer class with a simple sort/"shuffle" between the passes. It would be nice to also support another Reducer implementation being used as a combiner in the middle.
    Reason: New feature
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:51:40 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5c873336b3380e6c8f07ca28230ede9d41e4e840:
    Integrate with 0.21-branch versions of DBInputFormat
    
    Description: In 0.21 there is now a DBInputFormat in the mapred/lib/ package
    as well as mapreduce/lib/db. This patch backports the new API edition of
    DBInputFormat to CDH
    Reason: Cross-branch compatibility improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:50:05 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 51b650554e3bc8054e8ca966f5f552c522f7483d:
    HADOOP-5170. Set max map/reduce tasks on a per-job basis, either per-node or cluster-wide
    
    Description: There are a number of use cases for being able to do this.  The focus of this jira should be on finding what would be the simplest to implement that would satisfy the most use cases.
    
    <p>This could be implemented as either a per-node maximum or a cluster-wide maximum.  It seems that for most uses, the former is preferable however either would fulfill the requirements of this jira.</p>
    
    <p>Some of the reasons for allowing this feature (mine and from others on list):</p>
    <ul class="alternate" type="square">
    	<li>I have some very large CPU-bound jobs.  I am forced to keep the max map/node limit at 2 or 3 (on a 4 core node) so that I do not starve the Datanode and Regionserver.  I have other jobs that are network latency bound and would like to be able to run high numbers of them concurrently on each node.  Though I can thread some jobs, there are some use cases that are difficult to thread (scanning from hbase) and there's significant complexity added to the job rather than letting hadoop handle the concurrency.</li>
    	<li>Poor assignment of tasks to nodes creates some situations where you have multiple reducers on a single node but other nodes that received none.  A limit of 1 reducer per node for that job would prevent that from happening. (only works with per-node limit)</li>
    	<li>Poor mans MR job virtualization.  Since we can limit a jobs resources, this gives much more control in allocating and dividing up resources of a large cluster.  (makes most sense w/ cluster-wide limit)</li>
    </ul>
    
    Reason: Configuration improvement
    Author: Matei Zaharia
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:49:52 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 99e25a93542251debd248ed71cb380858ca8c9bd:
    HADOOP-6166. Improve PureJavaCrc32
    
    Description: Got some ideas to improve CRC32 calculation.
    Reason: Performance Improvement
    Author: Tsz Wo (Nicholas), SZE
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:49:40 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2d0a97cefa559ab9059d976bda66f9dbcf051e79:
    MAPREDUCE-782. Use PureJavaCrc32 in mapreduce spills
    
    Description: <a href="http://issues.apache.org/jira/browse/HADOOP-6148" title="Implement a pure Java CRC32 calculator"><del>HADOOP-6148</del></a> implemented a Pure Java implementation of CRC32 which performs better than the built-in one. This issue is to make use of it in the mapred package
    Reason: Performance improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:49:28 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bb65cb649c2924b5a20f06deb9ecd66fc219eeeb:
    HDFS-496. Use PureJavaCrc32 in HDFS
    
    Description: Common now has a pure java CRC32 implementation which is more efficient than java.util.zip.CRC32. This issue is to make use of it.
    Reason: Performance improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:49:12 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ac73e6d51d5ad1df993097349602e5f3199b952a:
    HADOOP-6148. Implement a pure Java CRC32 calculator
    
    Description: We've seen a reducer writing 200MB to HDFS with replication = 1 spending a long time in crc calculation. In particular, it was spending 5 seconds in crc calculation out of a total of 6 for the write. I suspect that it is the java-jni border that is causing us grief.
    
    This outperforms java.util.zip.CRC32.
    Reason: Performance improvement
    Author: Scott Carey and Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:48:40 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit e7430c8cbd2d182716ac7efb08cb2187c1edab95:
    Updated Sqoop documentation for MAPREDUCE-816, MAPREDUCE-789.
    
    Reason: Documentation improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:48:08 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit aa75ab7f749604c354dcdb0b806aca9cd140f504:
    MAPREDUCE-789. Oracle support for Sqoop
    
    Description: A separate ConnManager is needed for Oracle to support its slightly different syntax and configuration
    Reason: Compatibility improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:47:58 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6f017db468a82e336a28f451c7d90bc225130094:
    MAPREDUCE-840. DBInputFormat leaves open transaction
    
    Description: DBInputFormat.getSplits() does not call connection.commit() after the COUNT query. This can leave an open transaction against the database which interferes with other connections to the same table.
    Reason: bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:47:33 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 84b622a5f6f5bd145f19f4c08b6263759ac51756:
    MAPREDUCE-816. Rename "local" mysql import to "direct"
    
    Description: A mysqldump-based fast path known as "local mode" is used in sqoop when users pass the argument <tt>-<del>local.</tt> The restriction that this only import from localhost was based on an implementation technique that was later abandoned in favor of a more general one, which can support remote hosts as well. Thus, <tt></del><del>local</tt> is a poor name for the flag. <tt></del>-direct</tt> is more general and more descriptive. This should be used instead.
    Reason: Interface clarification
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:47:15 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ce75318a484615dc7b161a41710884f34db50c86:
    MAPREDUCE-716. org.apache.hadoop.mapred.lib.db.DBInputformat not working with oracle
    
    Description: <p>The out of the box implementation of the Hadoop is working properly with mysql/hsqldb, but NOT with oracle.<br/>
    Reason is DBInputformat is implemented with mysql/hsqldb specific query constructs like "LIMIT", "OFFSET".</p>
    
    <p>FIX:<br/>
    building a database provider specific logic based on the database providername (which we can get using connection).</p>
    
    Reason: Compatibility improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:46:34 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 338de775796c2102ce680eaa983b719b50e9f3ee:
    HADOOP-5469. Exposing Hadoop metrics via HTTP
    
    Description: Implement a "/metrics" URL on the HTTP server of Hadoop daemons, to expose metrics data to users via their web browsers, in plain-text and JSON.
    Reason: New feature
    Author: Philip Zeyliger
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:46:18 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cad421ec1c51382f81714ccafb96a6bb8bcc8aec:
    HADOOP-5469. Exposing Hadoop metrics via HTTP
    
    Description: Implement a "/metrics" URL on the HTTP server of Hadoop daemons, to expose metrics data to users via their web browsers, in plain-text and JSON.
    Reason: MISSING: Reason for inclusion
    Author: Philip Zeyliger
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:46:11 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8b09839047997a4b5461703650b5779ec86c1844:
    CLOUDERA-BUILD. Added Sqoop documentation to installation script
    
    Author: Todd Lipcon
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:45:49 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 7e77c6b13f06dec9c742bf76c81e2ec02d81c7cb:
    CLOUDERA-BUILD. Fix the hadoop/sqoop wrapper scripts
    
    Author: Matt Massie
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:45:35 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0caaf80f3a569b91f482de0dcb87f826967f5c7c:
    CLOUDERA-BUILD. Fix a bug in the hadoop/sqoop wrapper generation
    
    Author: Matt Massie
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:45:16 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bd8ddae402a876fe78cbb1482362935780b57d84:
    CLOUDERA-BUILD. Update the install hadoop script
    
    Author: Matt Massie
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:44:59 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 80cf01124877a5aebd742142b10fda45910f0328:
    CLOUDERA-BUILD. Rename the hadoop man page to be hadoop-0.20
    
    Author: Matt Massie
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:44:42 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 78cb9f21a3ddf04f8cef9e37a94f657448d0d111:
    HADOOP-5745. Allow setting the default value of maxRunningJobs for all pools
    
    Description: The &lt;pool&gt; element allows setting the maxRunningJobs for that pool. It wold be nice to be able to set a default value for all pools.
    
    <p>In out configuration, pools are autocreated.. every new uesre gets his own pool. We would like to allow each user to be able to run a max of 5 jobs at a time. For the etl pool, this limit will be set to a greater value,</p>
    Reason: Improved configuration flexibility
    Author: dhruba borthakur
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:43:51 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3c39e1fa8c3c89fc8f11f1faff46397fa82d5116:
    MAPREDUCE-906. Updated Sqoop documentation.
    
    Description: Update Sqoop documentation with user guide and manpage.
    Reason: Documentation improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:43:13 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 79a2645bc81894331721ef94c255992075ccf195:
    CLOUDERA-BUILD. Added MySQL Connector/J library for Sqoop.
    
    Description: We can ship MySQL Connector/J with CDH because the licenses
    are compatible. However, the public Apache project will not include this
    library in their source repository due to stricter licensing concerns.
    Reason: Simplifies deployment of Sqoop for mysql users
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:42:14 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4a097b35bf1264a0606f2ebe410c45f16f900f03:
    MAPREDUCE-705. User-configurable quote and delimiter characters for Sqoop records and record reparsing
    
    Description: Sqoop needs a mechanism for users to govern how fields are quoted and what delimiter characters separate fields and records. With delimiters providing an unambiguous format, a parse method can reconstitute the generated record data object from a text-based representation of the same record.
    Reason: New feature
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:42:05 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 58e23056af0e99ef611ac258719207cc9459a849:
    MAPREDUCE-710. Sqoop should read and transmit passwords in a more secure manner
    
    Description: Sqoop's current support for passwords involves reading passwords from the command line "--password foo", which makes the password visible to other users via 'ps'. An invisible-console approach should be taken.
    
    <p>Related, Sqoop transmits passwords to mysqldump in the same fashion, which is also insecure.</p>
    Reason: Security improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:41:47 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a67a0f77729fb9005b0c47872d6ba677f6434b41:
    MAPREDUCE-713. Sqoop has some superfluous imports
    
    Description: Some classes have vestigial imports that should be removed
    Reason: Code cleanup
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:41:34 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0a4dab2eac0ba8b6da5190bc53a9ce8e4344a336:
    MAPREDUCE-685. Sqoop will fail with OutOfMemory on large tables using mysql
    
    Description: The default MySQL JDBC client behavior is to buffer the entire ResultSet in the client before allowing the user to use the ResultSet object. On large SELECTs, this can cause OutOfMemory exceptions, even when the client intends to close the ResultSet after reading only a few rows. The MySQL ConnManager should configure its connection to use row-at-a-time delivery of results to the client.
    Reason: bugfix / scalability improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:41:01 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 499aa76b500136a0e8996898f468b088ca5d7ed3:
    MAPREDUCE-674. Sqoop should allow a "where" clause to avoid having to export entire tables
    
    Description: Sqoop currently only exports at the granularity of a table.  This doesn't work well on systems with large tables, where the overhead of performing a full dump each time is significant.  Allowing the user to specify a where clause is a relatively simple task which will give Sqoop a lot more flexibility.
    Reason: New feature
    Author: Kevin Weil
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:40:50 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ed4ba254d7708f363f5f1b4708e9e35061ad936c:
    MAPREDUCE-675. Sqoop should allow user-defined class and package names
    
    Description: Currently Sqoop generates a class for each table to be imported; the class names are equal to the table names and they are not part of any package.
    
    <p>This adds --class-name and --package-name parameters to Sqoop, allowing these aspects of code generation to be controlled.</p>
    Reason: New feature
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:40:37 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 16e0ca8119b99b244c9eeafd78bb9eb43e4ba639:
    MAPREDUCE-703. Sqoop requires dependency on hsqldb in ivy
    
    Description: Sqoop builds crash without explicit dependency on hsqldb.
    Reason: build system bugfix
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:40:20 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b8e54791e990328db983f070e9a04952301eda35:
    MAPREDUCE-692. Make Hudson run Sqoop unit tests
    
    Description: Running 'ant test-contrib' didn't test Sqoop because it wasn't explicitly listed in the build.xml file in src/contrib/
    Reason: Test coverage
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:40:04 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 8a3b6472ae00542dadf7f7d60991ec0f21b38177:
    HADOOP-5968. Sqoop should only print a warning about mysql import speed once
    
    Description: After <a href="http://issues.apache.org/jira/browse/HADOOP-5844" title="Use mysqldump when connecting to local mysql instance in Sqoop"><del>HADOOP-5844</del></a>, Sqoop can use mysqldump as an alternative to JDBC for importing from MySQL. If you use the JDBC mechanism, it prints a warning if you could have enabled the mysqldump path instead. But the warning is printed multiple times (every time the LocalMySQLManager is instantiated), and also when the MySQL manager is used for informational queries (e.g., listing tables) rather than true imports.
    
    <p>It should only emit the warning once per session, and only then if it's actually doing an import.</p>
    Reason: User experience improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:39:40 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 86211e3714dc5b1dbcb7a3c328336277f6657de7:
    HADOOP-5967. Sqoop should only use a single map task
    
    Description: The current DBInputFormat implementation uses SELECT ... LIMIT ... OFFSET statements to
    read from a database table. This actually results in several queries all accessing the same table at
    the same time. Most database implementations will actually use a full table scan for each such
    query, starting at row 1 and scanning down until the OFFSET is reached before emitting data to the
    client. The upshot of this is that we see O(n^2) performance in the size of the table when using a
    large number of mappers, when a single mapper would read through the table in O(n) time in the number of rows.
    
    <p>This patch sets the number of map tasks to 1 in the MapReduce job sqoop launches.</p>
    Reason: Performance improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
    commit 410db7130a8e85ceed46850f73e74f480d45994e
    Author: Aaron Kimball <aaron@cloudera.com>
    Date:   Thu Jul 23 16:10:21 2009 -0700
    
        HADOOP-5967: Sqoop should only use a single map task
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:38:44 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b8f5d1d3a30a7461936f3f92bd9f007ed2db43e8:
    HADOOP-5887. Sqoop should create tables in Hive metastore after importing to HDFS
    
    Description: Sqoop (<a href="http://issues.apache.org/jira/browse/HADOOP-5815" title="Sqoop: A database import tool for Hadoop"><del>HADOOP-5815</del></a>) imports tables into HDFS; it is a straightforward enhancement to then generate a Hive DDL statement to recreate the table definition in the Hive metastore and move the imported table into the Hive warehouse directory from its upload target.
    
    <p>This feature enhancement makes this process automatic. An import is performed with sqoop in the usual way; providing the argument "--hive-import" will cause it to then issue a CREATE TABLE .. LOAD DATA INTO statement to a Hive shell. It generates a script file and then attempts to run "$HIVE_HOME/bin/hive" on it, or failing that, any "hive" on the $PATH; $HIVE_HOME can be overridden with --hive-home. As a result, no direct linking against Hive is necessary.</p>
    
    <p>The unit tests provided with this enhancement use a mock implementation of 'bin/hive' that compares the script it's fed with one from a directory full of "expected" scripts. The exact script file referenced is controlled via an environment variable. It doesn't actually load into a proper Hive metastore, but manual testing has shown that this process works in practice, so the mock implementation is a reasonable unit testing tool.</p>
    Reason: New feature
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:38:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 50993494fdc7b2284837562b500e2840106bb3bb:
    CLOUDERA-BUILD. Address issue where docs were not properly copied through to release tarball
    
    Description:
        This was caused by some cleanup in build.xml early on in the CDH 0.20
        branch
    Reason: bugfix
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:37:48 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 3ecb9c07279302d18f7367d49bcd98c4391cbb68:
    CLOUDERA-BUILD. Decrease build time by only rebuilding the native code for each platform
    
    Reason: build system improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:37:27 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f0c6a810ba7237ec7cc570ecad8a8665768b3d06:
    CLOUDERA-BUILD. Run jdiff against vanilla Hadoop during Cloudera release build
    
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:37:07 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9cf8f0cb6ed744439d8e90e3ba376edb5d9521f3:
    MAPREDUCE-415. JobControl Job does always has an unassigned name
    
    Description: When creating and adding org.apache.hadoop.mapred.jobcontrol.Job(s) they don't use the names specified in their respective JobConf files.  Instead it's just hardcoded to "unassigned".
    Reason: bugfix
    Author: Xavier Stevens
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:36:22 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 330f009bae260ac990426a988fc56913897a50ca:
    HADOOP-5805. problem using top level s3 buckets as input/output directories
    
    Description: When I specify top level s3 buckets as input or output directories, I get the following exception.
    
    <p>hadoop jar subject-map-reduce.jar s3n://infocloud-input s3n://infocloud-output</p>
    
    <p>java.lang.IllegalArgumentException: Path must be absolute: s3n://infocloud-output<br/>
            at org.apache.hadoop.fs.s3native.NativeS3FileSystem.pathToKey(NativeS3FileSystem.java:246)<br/>
            at org.apache.hadoop.fs.s3native.NativeS3FileSystem.getFileStatus(NativeS3FileSystem.java:319)<br/>
            at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:667)<br/>
            at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:109)<br/>
            at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:738)<br/>
            at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1026)<br/>
            at com.evri.infocloud.prototype.subjectmapreduce.SubjectMRDriver.run(SubjectMRDriver.java:63)<br/>
            at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)<br/>
            at com.evri.infocloud.prototype.subjectmapreduce.SubjectMRDriver.main(SubjectMRDriver.java:25)<br/>
            at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br/>
            at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)<br/>
            at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)<br/>
            at java.lang.reflect.Method.invoke(Method.java:597)<br/>
            at org.apache.hadoop.util.RunJar.main(RunJar.java:155)<br/>
            at org.apache.hadoop.mapred.JobShell.run(JobShell.java:54)<br/>
            at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)<br/>
            at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:79)<br/>
            at org.apache.hadoop.mapred.JobShell.main(JobShell.java:68)</p>
    
    <p>The workaround is to specify input/output buckets with sub-directories:</p>
    
    <p>hadoop jar subject-map-reduce.jar s3n://infocloud-input/input-subdir  s3n://infocloud-output/output-subdir</p>
    
    Reason: bugfix
    Author: Ian Nowland
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:35:03 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 35fa82b5c743e34d62449e0f4abffd885e0dfe4c:
    HADOOP-5656. Counter for S3N Read Bytes does not work
    
    Description: Counter for S3N Read Bytes does not work on trunk. On 0.18 branch neither read nor write byte counters work.
    Reason: Bugfix
    Author: Ian Nowland
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:34:42 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a6670de0a1c4b03c293ae47d1595e8c33764aaa5:
    HADOOP-5613. change S3Exception to checked exception
    
    Description: Currently the S3 filesystems can throw unchecked exceptions (S3Exception) which are not declared in the interface of FileSystem. These aren't caught by the various callers and can cause unpredictable behavior. IOExceptions are caught by most users of FileSystem since it is declared in the interface and hence is handled better.
    
    S3Exception now extends IOException.
    Reason: Improved error-checking at compile time for user applications.
    Author: Andrew Hitchcock
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:33:43 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 1f11b63a42ae441eb8d0693ed0e4e01aca553e42:
    HADOOP-5528. Binary partitioner
    
    Description: It would be useful to have a <tt>BinaryPartitioner</tt> that partitions <tt>BinaryComparable</tt> keys by hashing a configurable part of the bytes array corresponding to each key.
    Reason: New feature
    Author: Klaas Bosteels
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:33:09 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 716d3598e5a4a18cdfcfcf0dc800e263ef7c7685:
    HADOOP-5240. 'ant javadoc' does not check whether outputs are up to date and always rebuilds
    
    Description: Running 'ant javadoc' twice in a row calls the javadoc program both times; it doesn't check to see whether this is redundant work.
    Reason: Build system improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:32:47 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 2bb607d29d9080a7ca3bce72739ccef654d5392d:
    HADOOP-5175. Option to prohibit jars unpacking
    
    Description: The task tracker moves all unpacked jars into
    ${hadoop.tmp.dir}/mapred/local/taskTracker. When using a lot of external
    libraries via -libjars, this results in several thousand unpacked files.
    The amount of time needed to `du` these directories can increase to the point
    where tasks time out before starting. This patch provides an option to
    suppress jar unpacking.
    Reason: Scalability improvement
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:30:46 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 349281bfa0243f5adbbd459266f4a9ac7ac8c1cc:
    CLOUDERA-BUILD. Fix scribe-log4j's ivy.xml to properly get log4j on the compile classpath
    
    Author: Todd Lipcon
    Reason: bugfix to build system
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:30:16 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b07aec5129e618bfeda8ba753fb5138e612b1a8b:
    HADOOP-4829. Allow FileSystem shutdown hook to be disabled
    
    Description: FileSystem sets a JVM shutdown hook so that it can clean up the FileSystem cache. This is great behavior when you are writing a client application, but when you're writing a server application, like the Collector or an HBase RegionServer, you need to control the shutdown of the application and HDFS much more closely. If you set your own shutdown hook, there's no guarantee that your hook will run before the HDFS one, preventing you from taking some shutdown actions.
    Reason: Integration improvement.
    Author: Todd Lipcon
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:29:33 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 154c6a6474b02e68c3418fddf9a8ee5d476a8b7d:
    HADOOP-3327. Shuffling fetchers waited too long between map output fetch re-tries
    
    Description: Improves handling of READ_TIMEOUT during map output copying.
    Author: Amareshwari Sriramadasu
    Reason: bugfix
    Ref: UNKNOWN
    
    commit 8a6293fc5c3733035dde8e4d3a68c414a1f800f8
    Author: Devaraj Das <ddas@apache.org>
    Date:   Thu Feb 5 05:35:09 2009 +0000
    
        HADOOP-3327. Improves handling of READ_TIMEOUT during map output copying. Contributed by Amareshwari Sriramadasu.
    
        git-svn-id: https://svn.apache.org/repos/asf/hadoop/core/trunk@741009 13f79535-47bb-0310-9956-ffa450edef68
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:28:14 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 4ee0ecf4760d7adb3e1a81e018a3b5cd6d2e9775:
    MAPREDUCE-680. Reuse of Writable objects is improperly handled by MRUnit
    
    Description: As written, MRUnit's MockOutputCollector simply stores references to the objects passed in to its collect() method. Thus if the same Text (or other Writable) object is reused as an output containiner multiple times with different values, these separate values will not all be collected. MockOutputCollector needs to properly use io.serializations to deep copy the objects sent in.
    Reason: Bugfix; see description.
    Author: Aaron Kimball
    Ref: UNKNOWN
    
    commit 51bdfdcf947bc8447aa36d68ae802f154516b0b6
    Author: Aaron Kimball <aaron@cloudera.com>
    Date:   Wed Jul 15 10:40:47 2009 -0700
    
        MAPREDUCE-680. Reuse of Writable objects is improperly handled by MRUnit.
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:27:44 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c2026460d4cf7049c67da65d3a2db2e9bcd9c848:
    HADOOP-5518. MRUnit unit test library
    
    Description: MRUnit is a tool to help authors of MapReduce programs write unit tests.
    
    Testing map() and reduce() methods requires some repeated work to mock the inputs and outputs of a Mapper or Reducer class, and ensure that the correct values are emitted to the OutputCollector based on inputs. Also, testing a mapper and reducer together requires running them with the sorted ordering guarantees made by the shuffle process.
    
    This library provides the above functionality to authors of maps and reduces; it allows you to test maps, reduces, and map-reduce pairs without needing to perform all the setup and teardown work associated with running a job.
    
    Reason: New feature
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:27:14 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 6991a0eb635953bf3729bce330c426ed7d8b996a:
    CLOUDERA-BUILD. Add sqoop wrapper to bin
    
    Description: Adds a '/usr/bin/sqoop' wrapper script for users
    Reason: User-experience improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:26:29 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit c365162d7db1ee70c8607ad84a11e4aa594224e7:
    HADOOP-5844. Use mysqldump when connecting to local mysql instance in Sqoop
    
    Description: Sqoop uses MapReduce + DBInputFormat to read the contents of a table into HDFS. On many databases, this implementation is O(N^2) in the number of rows. Also, the use of multiple mappers has low value in terms of throughput, because the database itself is inherently singlethreaded. While DBInputFormat/JDBC provides a useful fallback mechanism for importing from databases, db-specific dump utilities will nearly always provide faster throughput, and should be selected when available. This patch allows users to use mysqldump to read from local mysql instances instead of the MapReduce-based input.
    Reason: Performance improvement
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:25:56 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit eddbfbca420bfb81a3a565e4324f6189bfd97e41:
    HADOOP-5815. Sqoop: A database import tool for Hadoop
    
    Description:
    Sqoop is a tool designed to help users import existing relational databases into their Hadoop clusters. Sqoop uses JDBC to connect to a database, examine the schema for tables, and auto-generate the necessary classes to import data into HDFS. It then instantiates a MapReduce job to read the table from the database via the DBInputFormat (JDBC-based InputFormat). The table is read into a set of files loaded into HDFS. Both SequenceFile and text-based targets are supported.
    Reason: New feature
    Author: Aaron Kimball
    Ref: UNKNOWN
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:24:58 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit b33265ff77c71af61899a4b3add1e82cc195fdb7:
    MAPREDUCE-714. JobConf.findContainingJar unescapes unnecessarily on Linux
    
    Description: In JobConf.findContainingJar, the path name is decoded using URLDecoder.decode(...). This was done by Doug in r381794 (commit msg "Un-escape containing jar's path, which is URL-encoded.  This fixes things primarily on Windows, where paths are likely to contain spaces.") Unfortunately, jar paths do not appear to be URL encoded on Linux. If you try to use "hadoop jar" on a jar with a "+" in it, this function decodes it to a space and then the job cannot be submitted.
    Reason: Cloudera-based packages include a '+' in the filename; Hadoop's URL escaper will not
    properly handle jar filenames with a '+' without this patch.
    Author: Todd Lipcon
    Ref: UNKNOWN
    
    commit d9767d2cefab288e581732f71779f3ce8e3267e4
    Author: Todd Lipcon <todd@cloudera.com>
    Date:   Mon Jul 6 19:36:11 2009 -0700
    
        MAPREDUCE-714: Fix JobConf.findContainingJars to work with jars with + in the name
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:23:53 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit aaeb69f8dda72a2e7aecacd622e99c00bc961efa:
    CLOUDERA-BUILD. Add dependency libraries for Scribe/log4j
    
    Author: Todd Lipcon
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:23:23 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit cb7a3677942c1d2f9e0d2a75dbffa09fa6125e61:
    CLOUDERA-BUILD. Apply Scribe patches to Hadoop
    
    Description:
        scribe_hadoop_trunk.patch
        Also, add empty ivy infrastructure for scribe-log4j
    Author: Todd Lipcon
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:22:41 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit d5ead434b221076fb830308d2d112d53aa6dc59f:
    CLOUDERA-BUILD. Use cloudera's versioning info from cloudera.hash in saveVersion.sh
    
    Description:
        This should make the "hadoop version" output far more useful for
        determing exactly what code is running. The cloudera.hash property is
        set by cloudera/build.properties which is generated during the build
        process.
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:22:26 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit bf10e46e425395145dcc4b85db66d45cbf9797b0:
    CLOUDERA-BUILD. Move saveVersion.sh in build.xml to ensure build
    
    Description:
        This error is due to ant 1.7.1 not compiling package-info.java if the
        timestamp of the output class directory is newer than the package-info
        file itself. Since other compiles were happening after package-info.java
        was generated, the build dir was newer and compilation was being
        skipped.
    
        Move cloudera hooks inside the package task of build.xml
    
        Fixes an issue where the fair scheduler jar was not built before the
        hooks were run, and therefore was not included in the target lib/
        directory.
    
    Ref: CLOUDERA-436
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:21:45 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 5359a3bbd2b09644825be99fdd354ff3276a5d59:
    CLOUDERA-BUILD. New versions of cloudera packaging scripts
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:21:36 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit ee255f3909b9938b1023be6a2c59a8429227c766:
    CLOUDERA-BUILD. Change paths to point to hadoop-0.20 where necessary
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:21:27 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit a2d051bcf456fde45c0a0c3aa512872ce6059a97:
    CLOUDERA-BUILD. Add Hadoop manpage to Hadoop 0.20 repository
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:21:08 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 9600765ec5d6c3cef9ab34ecb573cbb876acf7ee:
    CLOUDERA-BUILD. Move install_hadoop.sh into hadoop repo
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:21:01 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 77ac6923ad6e63874a429e7dd13c4a084b6a9556:
    CLOUDERA-BUILD. Add example-confs directory for storing configuration of conf.pseudo
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:20:52 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 14256386d4cb155fea0f5745dd6c49fba74ff40f:
    CLOUDERA-BUILD. Replace hadoop-config.sh with Cloudera version
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:20:43 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit f7d0a20e0d74f1aac1fb96f3c08ce31e9b9ca5d9:
    CLOUDERA-BUILD. Remove redundant code in build.xml between package and bin-package
    
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:20:25 -0800


hadoop-0.20 (0.20.2+890-1) cloudera; urgency=low

  Commit 0fa65091ecd9dd150d6afb93845d3fb10d80e115:
    CLOUDERA-BUILD. Hook build.xml to enable contrib modules
 -- Aaron Kimball <aaron@cloudera.com>  Fri, 12 Mar 2010 14:16:59 -0800

